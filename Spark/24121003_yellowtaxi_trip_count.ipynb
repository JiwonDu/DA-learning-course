{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd220a1-b84b-49ec-8296-2434b49be8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/10 15:53:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/10 15:53:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"24121003_yellowtaxi_trip_count\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc59635-6d32-4c23-8a91-8eaf94c94e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "trip_files = '/trips/*'\n",
    "zone_file = 'taxi+_zone_lookup.csv'\n",
    "directory = os.path.join(os.getcwd(), 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "028366ed-43c8-47f9-9e64-ae4ea9213e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_df = spark.read.csv(f'file:///{directory}/{zone_file}', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73f02b1f-ee42-463d-968b-6383e21dae78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2461645a-848d-49fd-bd22-96c876e5a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.createOrReplaceTempView('trips')\n",
    "zone_df.createOrReplaceTempView('zone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a241de-b9ac-4b32-89c5-3016c6fb98f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "select\n",
    "t.VendorID,\n",
    "TO_DATE(t.tpep_pickup_datetime) as pickup_date,\n",
    "TO_DATE(t.tpep_dropoff_datetime) as dropoff_date,\n",
    "HOUR(t.tpep_pickup_datetime)  as pickup_time,\n",
    "HOUR(t.tpep_dropoff_datetime) as dropoff_time,\n",
    "t.passenger_count,\n",
    "t.trip_distance,\n",
    "t.tip_amount,\n",
    "t.total_amount,\n",
    "t.payment_type,\n",
    "pz.Zone as pickup_zone,\n",
    "dz.Zone as dropoff_zone\n",
    "from trips t\n",
    "LEFT JOIN zone pz ON t.PULocationID = pz.LocationID\n",
    "LEFT JOIN zone dz ON t.DOLocationID = dz.LocationID\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1150270f-c54e-4fef-99f6-232b8d418ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1d12f58-a343-4c74-8ea3-0d61c1e31107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "15000700"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02ea24c9-b019-47a8-a071-d95e4073881c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------------+-----------+------------+---------------+-------------+----------+------------+------------+-----------------+--------------+\n",
      "|VendorID|pickup_date|dropoff_date|pickup_time|dropoff_time|passenger_count|trip_distance|tip_amount|total_amount|payment_type|      pickup_zone|  dropoff_zone|\n",
      "+--------+-----------+------------+-----------+------------+---------------+-------------+----------+------------+------------+-----------------+--------------+\n",
      "|       2| 2021-03-01|  2021-03-01|          0|           0|              1|          0.0|       0.0|         4.3|           2|               NV|            NV|\n",
      "|       2| 2021-03-01|  2021-03-01|          0|           0|              1|          0.0|       0.0|         3.8|           2|   Manhattanville|Manhattanville|\n",
      "|       2| 2021-03-01|  2021-03-01|          0|           0|              1|          0.0|       0.0|         4.8|           2|   Manhattanville|Manhattanville|\n",
      "|       1| 2021-03-01|  2021-03-01|          0|           0|              0|         16.5|     11.65|       70.07|           1|LaGuardia Airport|            NA|\n",
      "|       2| 2021-03-01|  2021-03-01|          0|           0|              1|         1.13|      1.86|       11.16|           1|     East Chelsea|            NV|\n",
      "+--------+-----------+------------+-----------+------------+---------------+-------------+----------+------------+------------+-----------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comb_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02c85c25-0fe1-4ca6-b23f-f31dd8875742",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df.createOrReplaceTempView('comb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12608a13-efc8-47d0-89a2-d8424dce536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "select pickup_date, pickup_time \n",
    "from comb \n",
    "where pickup_time>0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1796b96-edb3-40e2-8efd-5acabf85a181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|pickup_date|pickup_time|\n",
      "+-----------+-----------+\n",
      "| 2021-02-28|         23|\n",
      "| 2021-02-28|         23|\n",
      "| 2021-02-28|         23|\n",
      "| 2021-02-28|         23|\n",
      "| 2021-02-28|         23|\n",
      "| 2021-02-28|         23|\n",
      "| 2021-02-28|         23|\n",
      "| 2021-03-01|         22|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5df1ab94-42d3-48ca-9ec5-8d7b58bcc3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:=============================>                            (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|pickup_date|pickup_time|\n",
      "+-----------+-----------+\n",
      "| 2009-01-01|          0|\n",
      "| 2008-12-31|         23|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          1|\n",
      "| 2009-01-01|          0|\n",
      "| 2008-12-31|         23|\n",
      "| 2008-12-31|         23|\n",
      "| 2008-12-31|         23|\n",
      "| 2008-12-31|         23|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|         16|\n",
      "| 2009-01-01|         16|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select pickup_date, pickup_time \n",
    "from comb \n",
    "where pickup_date<'2020-12-31'\n",
    "'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "098f75f7-3ddf-4d40-9666-83826813799d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, VendorID: string, pickup_time: string, dropoff_time: string, passenger_count: string, trip_distance: string, tip_amount: string, total_amount: string, payment_type: string, pickup_zone: string, dropoff_zone: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b0078e5-b9cc-476d-b8ca-b5d6f6d6f2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Project [cast(tpep_pickup_datetime#17 as date) AS pickup_date#76, hour(cast(tpep_pickup_datetime#17 as timestamp), Some(Asia/Seoul)) AS pickup_time#78]\n",
      "+- *(3) BroadcastHashJoin [DOLocationID#24], [LocationID#82], LeftOuter, BuildRight, false\n",
      "   :- *(3) Project [tpep_pickup_datetime#17, DOLocationID#24]\n",
      "   :  +- *(3) BroadcastHashJoin [PULocationID#23], [LocationID#68], LeftOuter, BuildRight, false\n",
      "   :     :- *(3) Filter (isnotnull(tpep_pickup_datetime#17) AND (cast(tpep_pickup_datetime#17 as date) < 18627))\n",
      "   :     :  +- FileScan csv [tpep_pickup_datetime#17,PULocationID#23,DOLocationID#24] Batched: false, DataFilters: [isnotnull(tpep_pickup_datetime#17), (cast(tpep_pickup_datetime#17 as date) < 18627)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab06/src/DA-learning-course/Spark/data/trips/yellow_tripdata_2021-0..., PartitionFilters: [], PushedFilters: [IsNotNull(tpep_pickup_datetime)], ReadSchema: struct<tpep_pickup_datetime:string,PULocationID:int,DOLocationID:int>\n",
      "   :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#570]\n",
      "   :        +- *(1) Filter isnotnull(LocationID#68)\n",
      "   :           +- FileScan csv [LocationID#68] Batched: false, DataFilters: [isnotnull(LocationID#68)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab06/src/DA-learning-course/Spark/data/taxi+_zone_lookup.csv], PartitionFilters: [], PushedFilters: [IsNotNull(LocationID)], ReadSchema: struct<LocationID:int>\n",
      "   +- ReusedExchange [LocationID#82], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#570]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b93861b4-e1a1-4e03-abf5-bf03ebf8a853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|pickup_date|pickup_time|\n",
      "+-----------+-----------+\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#실행계획, 실행결과(4040)\n",
    "\n",
    "query2 = '''\n",
    "select pickup_date, pickup_time \n",
    "from comb \n",
    "where pickup_time > 0 and pickup_time<=12\n",
    "'''\n",
    "spark.sql(query2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a68330f-e89a-469b-9274-0df19d36ec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:=================================================>    (185 + 2) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|pickup_date|pickup_time|\n",
      "+-----------+-----------+\n",
      "| 2002-12-31|         23|\n",
      "| 2003-01-05|          7|\n",
      "| 2004-04-04|          4|\n",
      "| 2008-12-31|         22|\n",
      "| 2008-12-31|         23|\n",
      "| 2009-01-01|          5|\n",
      "| 2009-01-01|         20|\n",
      "| 2009-01-01|         11|\n",
      "| 2009-01-01|          1|\n",
      "| 2009-01-01|         19|\n",
      "| 2009-01-01|         17|\n",
      "| 2009-01-01|         18|\n",
      "| 2009-01-01|         23|\n",
      "| 2009-01-01|          4|\n",
      "| 2009-01-01|          3|\n",
      "| 2009-01-01|         21|\n",
      "| 2009-01-01|         12|\n",
      "| 2009-01-01|         16|\n",
      "| 2009-01-01|          2|\n",
      "| 2009-01-01|         10|\n",
      "+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "query3 = '''\n",
    "select pickup_date, pickup_time \n",
    "from comb \n",
    "where pickup_time > 0\n",
    "group by pickup_date, pickup_time\n",
    "order by pickup_date\n",
    "'''\n",
    "spark.sql(query3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bce5e29-81fb-4afe-9e27-7821ee7bc30c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
