{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e4404c4-7b19-4359-9cfb-3f64a8482f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/10 14:54:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"24121002_SparkSQL_execution_plan\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11228f56-da17-42d8-bdf7-c0a069f37071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", 'true')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load('data/emp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "addb6fcf-3549-483c-a2d6-c7c43b686a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|null|    20|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|null|    20|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|null|    30|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|null|    20|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|null|    20|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|null|    30|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|null|    20|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|null|    70|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cee30575-277a-4314-8500-f9b6e0f0376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", 'true')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load('data/dept.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "164e4e3b-8332-402b-992f-939739af3d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- deptno: integer (nullable = true)\n",
      " |-- dname: string (nullable = true)\n",
      " |-- loc: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abc2db18-1df3-4fee-ae01-9d9aafc0ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('emp_df_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c69b345f-0bcb-446a-bbf0-640969ad54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_df.createOrReplaceTempView('dept_df_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "899e1e86-9fd0-43ab-9394-fbdf8e4f50c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#뷰에서 조인\n",
    "join_query = '''\n",
    "select *\n",
    "from emp_df_view join dept_df_view on emp_df_view.deptno = dept_df_view.deptno\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a949a17-9328-4302-8086-a9fffd3a1508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|deptno|     dname|     loc|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|    30|     SALES| CHICAGO|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|    30|     SALES| CHICAGO|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|    30|     SALES| CHICAGO|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|null|    30|    30|     SALES| CHICAGO|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|    30|     SALES| CHICAGO|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|null|    30|    30|     SALES| CHICAGO|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "viewEmpDept = spark.sql(join_query)\n",
    "viewEmpDept.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19cf4088-2993-4ba1-8a19-62c3db288821",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewEmpDept.createOrReplaceTempView('viewEmpDept')\n",
    "\n",
    "v_query = '''\n",
    "select * \n",
    "from viewEmpDept\n",
    "where loc = 'NEW YORK'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5027c4a7-f937-4cc1-9bfc-4565e86448eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|deptno|     dname|     loc|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# case 1\n",
    "spark.sql(v_query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed7e8184-d8e4-4375-87cd-3223b1a6bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subquery\n",
    "\n",
    "q2 = '''\n",
    "select *\n",
    "from emp_df_view\n",
    "where deptno = (\n",
    "    select deptno\n",
    "    from dept_df_view\n",
    "    where loc='NEW YORK'\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "846e1d1d-9ab0-41b3-85db-8ba4f83e4c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# case 2\n",
    "spark.sql(q2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e34a587c-1d0d-402a-88b0-c97a7d217a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [deptno#23], [deptno#89], Inner, BuildRight, false\n",
      ":- *(2) Filter isnotnull(deptno#23)\n",
      ":  +- FileScan csv [empno#16,ename#17,job#18,mgr#19,hiredate#20,sal#21,comm#22,deptno#23] Batched: false, DataFilters: [isnotnull(deptno#23)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab06/src/DA-learning-course/Spark/data/emp.csv], PartitionFilters: [], PushedFilters: [IsNotNull(deptno)], ReadSchema: struct<empno:int,ename:string,job:string,mgr:int,hiredate:string,sal:int,comm:int,deptno:int>\n",
      "+- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#369]\n",
      "   +- *(1) Filter ((isnotnull(loc#91) AND (loc#91 = NEW YORK)) AND isnotnull(deptno#89))\n",
      "      +- FileScan csv [deptno#89,dname#90,loc#91] Batched: false, DataFilters: [isnotnull(loc#91), (loc#91 = NEW YORK), isnotnull(deptno#89)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab06/src/DA-learning-course/Spark/data/dept.csv], PartitionFilters: [], PushedFilters: [IsNotNull(loc), EqualTo(loc,NEW YORK), IsNotNull(deptno)], ReadSchema: struct<deptno:int,dname:string,loc:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# case1의 실행계획 - JOIN\n",
    "spark.sql(v_query).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8e7df78-6b20-4064-b36a-4cd66046602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Filter (isnotnull(deptno#23) AND (deptno#23 = Subquery scalar-subquery#534, [id=#336]))\n",
      ":  +- Subquery scalar-subquery#534, [id=#336]\n",
      ":     +- *(1) Project [deptno#89]\n",
      ":        +- *(1) Filter (isnotnull(loc#91) AND (loc#91 = NEW YORK))\n",
      ":           +- FileScan csv [deptno#89,loc#91] Batched: false, DataFilters: [isnotnull(loc#91), (loc#91 = NEW YORK)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab06/src/DA-learning-course/Spark/data/dept.csv], PartitionFilters: [], PushedFilters: [IsNotNull(loc), EqualTo(loc,NEW YORK)], ReadSchema: struct<deptno:int,loc:string>\n",
      "+- FileScan csv [empno#16,ename#17,job#18,mgr#19,hiredate#20,sal#21,comm#22,deptno#23] Batched: false, DataFilters: [isnotnull(deptno#23)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab06/src/DA-learning-course/Spark/data/emp.csv], PartitionFilters: [], PushedFilters: [IsNotNull(deptno)], ReadSchema: struct<empno:int,ename:string,job:string,mgr:int,hiredate:string,sal:int,comm:int,deptno:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# case2의 실행계획 - SUBQUERY\n",
    "spark.sql(q2).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250527d3-7849-4c6f-8f96-4d4e0d86201a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
