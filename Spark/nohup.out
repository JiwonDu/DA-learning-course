[I 10:04:10.540 NotebookApp] Serving notebooks from local directory: /home/lab06/src
[I 10:04:10.540 NotebookApp] Jupyter Notebook 6.4.10 is running at:
[I 10:04:10.540 NotebookApp] http://ip-172-31-13-94:8906/
[I 10:04:10.540 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[W 10:04:10.777 NotebookApp] 404 GET /api/kernels/79bc5632-7bba-4375-a052-f098bb69529d/channels?session_id=b83ae907700945878ca8829a0c621e36 (211.231.29.166): Kernel does not exist: 79bc5632-7bba-4375-a052-f098bb69529d
[W 10:04:10.798 NotebookApp] 404 GET /api/kernels/79bc5632-7bba-4375-a052-f098bb69529d/channels?session_id=b83ae907700945878ca8829a0c621e36 (211.231.29.166) 22.990000ms referer=None
[W 10:04:18.340 NotebookApp] 404 GET /api/contents/src?type=directory&_=1733187208903 (211.231.29.166): No such file or directory: src
[W 10:04:18.340 NotebookApp] No such file or directory: src
[W 10:04:18.341 NotebookApp] 404 GET /api/contents/src?type=directory&_=1733187208903 (211.231.29.166) 0.700000ms referer=http://13.208.159.5:8906/tree/src
[I 10:04:29.306 NotebookApp] 302 GET / (211.231.29.166) 0.460000ms
[I 10:16:34.479 NotebookApp] Kernel started: 6ec2af41-a5bc-47ab-921c-ded953c80961, name: spark_start
24/12/03 10:16:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 10:18:34.516 NotebookApp] Saving file at /Spark 환경설정_241202.ipynb
[I 10:23:56.669 NotebookApp] Starting buffering for 6ec2af41-a5bc-47ab-921c-ded953c80961:4f0d1d92a2274c9fb71d7d6e5a702f2d
[I 10:24:07.931 NotebookApp] Creating new notebook in 
[I 10:24:10.421 NotebookApp] Kernel started: 2877fcac-4a85-432f-b6c6-45cac09da33d, name: spark_start
[I 10:26:10.462 NotebookApp] Saving file at /20241203_p10_exam.ipynb
24/12/03 10:27:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 10:28:10.459 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 10:30:10.940 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 10:30:48.667 NotebookApp] Starting buffering for 6ec2af41-a5bc-47ab-921c-ded953c80961:272390ab394343978ff66d7733236f43
[I 10:32:10.452 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 10:34:10.460 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 10:40:10.785 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 10:41:12.948 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 10:42:10.455 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[W 10:43:54.623 NotebookApp] 404 GET /3591 (211.231.29.166) 1.740000ms referer=None
[I 10:44:10.461 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 10:46:10.449 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 10:48:10.465 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 10:50:10.572 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 10:52:10.543 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 10:54:10.507 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 10:55:36.413 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 10:56:10.451 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 11:00:10.448 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 11:02:10.447 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 11:04:10.444 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 11:06:10.444 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 11:24:10.970 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 11:26:10.432 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 11:28:10.467 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 11:30:10.434 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 11:32:10.950 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 11:34:10.434 NotebookApp] Saving file at /20241203_p10_exam.ipynb
24/12/03 11:34:11 WARN Instrumentation: [3355206a] regParam is zero, which might cause numerical instability and overfitting.
24/12/03 11:34:11 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
24/12/03 11:34:11 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
24/12/03 11:34:11 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
24/12/03 11:34:11 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
[I 11:34:27.186 NotebookApp] Starting buffering for 6ec2af41-a5bc-47ab-921c-ded953c80961:1ebc660e9817445885458326e548f447
[I 11:36:10.427 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 11:52:10.456 NotebookApp] Saving file at /20241203_p10_exam.ipynb
[I 13:15:33.288 NotebookApp] Creating new directory in 
[I 13:23:00.448 NotebookApp] Starting buffering for 2877fcac-4a85-432f-b6c6-45cac09da33d:f286102eb3ea4ec68e79300643e29ee5
[I 13:23:06.892 NotebookApp] Creating new notebook in 
[I 13:23:09.046 NotebookApp] Kernel started: cf46bb93-fc7f-435f-8282-dbfadea66446, name: spark_start
[I 13:25:09.275 NotebookApp] Saving file at /241203_01_학생수세기.ipynb
[I 13:29:09.095 NotebookApp] Saving file at /241203_01_학생수세기.ipynb
24/12/03 13:30:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 13:31:09.080 NotebookApp] Saving file at /241203_01_학생수세기.ipynb
[I 13:39:09.089 NotebookApp] Saving file at /241203_01_학생수세기.ipynb
[I 13:41:09.256 NotebookApp] Saving file at /241203_01_학생수세기.ipynb
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 13:43:09.119 NotebookApp] Saving file at /241203_01_학생수세기.ipynb
[I 13:45:09.085 NotebookApp] Saving file at /241203_01_학생수세기.ipynb
[I 13:47:09.108 NotebookApp] Saving file at /241203_01_학생수세기.ipynb
[I 13:49:09.132 NotebookApp] Saving file at /241203_01_학생수세기.ipynb
[I 13:51:09.324 NotebookApp] Saving file at /241203_01_학생수세기.ipynb
[I 13:55:09.134 NotebookApp] Saving file at /241203_01_학생수세기.ipynb
[I 13:57:09.087 NotebookApp] Saving file at /241203_01_학생수세기.ipynb
[I 14:25:59.223 NotebookApp] Creating new notebook in 
[I 14:26:03.760 NotebookApp] Kernel started: 13cf62bc-b29b-4dc5-9f26-7aaf7f6a3cd0, name: spark_start
[I 14:28:03.797 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
24/12/03 14:29:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
24/12/03 14:29:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[I 14:30:04.068 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[I 14:32:03.803 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[I 14:34:03.886 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 14:36:03.801 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[I 14:38:04.123 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[I 14:44:03.837 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[I 14:46:03.826 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[I 14:48:03.816 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[I 14:50:03.793 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[I 14:52:03.785 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[I 14:54:03.787 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[I 14:56:03.778 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[I 14:58:03.775 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[I 15:00:03.836 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[I 15:04:03.812 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[I 15:06:03.797 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[I 15:08:04.089 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[I 15:29:09.876 NotebookApp] Creating new notebook in 
[I 15:29:12.047 NotebookApp] Kernel started: fe6582a1-8570-4a2d-b4d2-dde44732420b, name: spark_start
[I 15:31:12.037 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[I 15:33:12.376 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
24/12/03 15:33:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
24/12/03 15:33:25 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
24/12/03 15:33:25 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[I 15:35:12.032 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 15:37:12.056 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[I 15:39:12.056 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[I 15:41:12.106 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[I 15:43:12.135 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
24/12/03 15:44:17 ERROR Executor: Exception in task 0.0 in stage 4.0 (TID 4)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 604, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 596, in process
    serializer.dump_stream(out_iter, outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 259, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/opt/spark/python/lib/pyspark.zip/pyspark/util.py", line 73, in wrapper
    return f(*args, **kwargs)
  File "/tmp/ipykernel_5681/3738455784.py", line 2, in parse
NameError: name 'line' is not defined

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
24/12/03 15:44:17 WARN TaskSetManager: Lost task 0.0 in stage 4.0 (TID 4) (ip-172-31-13-94.ap-northeast-3.compute.internal executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 604, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 596, in process
    serializer.dump_stream(out_iter, outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 259, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/opt/spark/python/lib/pyspark.zip/pyspark/util.py", line 73, in wrapper
    return f(*args, **kwargs)
  File "/tmp/ipykernel_5681/3738455784.py", line 2, in parse
NameError: name 'line' is not defined

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

24/12/03 15:44:17 ERROR TaskSetManager: Task 0 in stage 4.0 failed 1 times; aborting job
[I 15:45:12.342 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[I 15:47:12.088 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
24/12/03 15:48:48 ERROR Executor: Exception in task 0.0 in stage 5.0 (TID 5)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 604, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 596, in process
    serializer.dump_stream(out_iter, outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 259, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/opt/spark/python/lib/pyspark.zip/pyspark/util.py", line 73, in wrapper
    return f(*args, **kwargs)
  File "/tmp/ipykernel_5681/3738455784.py", line 2, in parse
NameError: name 'line' is not defined

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
24/12/03 15:48:48 WARN TaskSetManager: Lost task 0.0 in stage 5.0 (TID 5) (ip-172-31-13-94.ap-northeast-3.compute.internal executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 604, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 596, in process
    serializer.dump_stream(out_iter, outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 259, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/opt/spark/python/lib/pyspark.zip/pyspark/util.py", line 73, in wrapper
    return f(*args, **kwargs)
  File "/tmp/ipykernel_5681/3738455784.py", line 2, in parse
NameError: name 'line' is not defined

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

24/12/03 15:48:48 ERROR TaskSetManager: Task 0 in stage 5.0 failed 1 times; aborting job
[I 15:49:12.267 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
24/12/03 16:00:10 ERROR Executor: Exception in task 0.0 in stage 6.0 (TID 6)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 604, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 596, in process
    serializer.dump_stream(out_iter, outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 259, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/opt/spark/python/lib/pyspark.zip/pyspark/util.py", line 73, in wrapper
    return f(*args, **kwargs)
  File "/tmp/ipykernel_5681/3738455784.py", line 2, in parse
NameError: name 'line' is not defined

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
24/12/03 16:00:10 WARN TaskSetManager: Lost task 0.0 in stage 6.0 (TID 6) (ip-172-31-13-94.ap-northeast-3.compute.internal executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 604, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 596, in process
    serializer.dump_stream(out_iter, outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 259, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/opt/spark/python/lib/pyspark.zip/pyspark/util.py", line 73, in wrapper
    return f(*args, **kwargs)
  File "/tmp/ipykernel_5681/3738455784.py", line 2, in parse
NameError: name 'line' is not defined

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

24/12/03 16:00:10 ERROR TaskSetManager: Task 0 in stage 6.0 failed 1 times; aborting job
[I 16:01:12.293 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[I 16:03:12.160 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[Stage 9:>                                                          (0 + 1) / 1]                                                                                [I 16:05:12.234 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[I 16:07:12.400 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[I 16:11:12.151 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[I 16:11:27.446 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[I 16:15:12.179 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[I 16:16:38.648 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[I 16:19:12.193 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[I 16:21:12.354 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[I 16:23:12.231 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[I 16:24:21.273 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[I 16:57:13.101 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[I 17:52:24.061 NotebookApp] Saving file at /241203_03_mnms숫자세기.ipynb
[I 17:52:24.596 NotebookApp] Starting buffering for fe6582a1-8570-4a2d-b4d2-dde44732420b:5768fc4fe3424ba7bc48e3ff8a52624f
[I 17:52:36.982 NotebookApp] Starting buffering for 13cf62bc-b29b-4dc5-9f26-7aaf7f6a3cd0:62334f31d63a4b2d81453fc72de8ee73
[I 17:52:45.076 NotebookApp] Starting buffering for cf46bb93-fc7f-435f-8282-dbfadea66446:a42c990f2db147a9804a17be41b1ecc8
[C 17:53:51.620 NotebookApp] received signal 15, stopping
[I 17:53:51.630 NotebookApp] Shutting down 5 kernels
[I 17:53:51.671 NotebookApp] Kernel shutdown: 2877fcac-4a85-432f-b6c6-45cac09da33d
[I 17:53:51.671 NotebookApp] Kernel shutdown: 13cf62bc-b29b-4dc5-9f26-7aaf7f6a3cd0
[I 17:53:51.671 NotebookApp] Kernel shutdown: cf46bb93-fc7f-435f-8282-dbfadea66446
[I 17:53:51.671 NotebookApp] Kernel shutdown: fe6582a1-8570-4a2d-b4d2-dde44732420b
[I 17:53:51.671 NotebookApp] Kernel shutdown: 6ec2af41-a5bc-47ab-921c-ded953c80961
[I 17:53:51.912 NotebookApp] Shutting down 0 terminals
[I 15:17:50.974 NotebookApp] Serving notebooks from local directory: /home/lab06/src
[I 15:17:50.976 NotebookApp] Jupyter Notebook 6.4.10 is running at:
[I 15:17:50.976 NotebookApp] http://ip-172-31-13-94:8906/
[I 15:17:50.976 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[W 15:18:01.018 NotebookApp] 404 GET /api/contents/src?type=directory&_=1733277047469 (211.231.29.166): No such file or directory: src
[W 15:18:01.019 NotebookApp] No such file or directory: src
[W 15:18:01.019 NotebookApp] 404 GET /api/contents/src?type=directory&_=1733277047469 (211.231.29.166) 0.860000ms referer=http://13.208.159.5:8906/tree/src
[I 15:18:07.726 NotebookApp] 302 GET / (211.231.29.166) 0.420000ms
[W 15:18:14.542 NotebookApp] Notebook 241204_02_MovieLens_영화별점카운트.ipynb is not trusted
[I 15:18:15.414 NotebookApp] Kernel started: dc902c7d-fde4-48c8-a3be-11f27aef7399, name: spark_start
24/12/04 15:18:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[W 15:18:46.358 NotebookApp] Notebook 241203_02_KVRDD.ipynb is not trusted
[I 15:18:47.234 NotebookApp] Kernel started: 9f60afc1-5456-46bf-99e4-1489926a4134, name: spark_start
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 15:20:15.519 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
[I 15:22:15.464 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
[Stage 1:>                                                          (0 + 1) / 1]                                                                                [I 15:22:47.663 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
[I 15:29:34.214 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
[I 15:42:15.503 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
[I 15:44:15.570 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
24/12/04 15:46:14 ERROR Executor: Exception in task 0.0 in stage 10.0 (TID 10)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 604, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 596, in process
    serializer.dump_stream(out_iter, outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 259, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/opt/spark/python/lib/pyspark.zip/pyspark/util.py", line 73, in wrapper
    return f(*args, **kwargs)
  File "/tmp/ipykernel_4505/646040827.py", line 4, in <lambda>
TypeError: unsupported operand type(s) for /: 'str' and 'int'

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
24/12/04 15:46:14 WARN TaskSetManager: Lost task 0.0 in stage 10.0 (TID 10) (ip-172-31-13-94.ap-northeast-3.compute.internal executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 604, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 596, in process
    serializer.dump_stream(out_iter, outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 259, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/opt/spark/python/lib/pyspark.zip/pyspark/util.py", line 73, in wrapper
    return f(*args, **kwargs)
  File "/tmp/ipykernel_4505/646040827.py", line 4, in <lambda>
TypeError: unsupported operand type(s) for /: 'str' and 'int'

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

24/12/04 15:46:14 ERROR TaskSetManager: Task 0 in stage 10.0 failed 1 times; aborting job
[I 15:46:15.459 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
24/12/04 15:48:08 ERROR Executor: Exception in task 0.0 in stage 23.0 (TID 23)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 604, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 594, in process
    out_iter = func(split_index, iterator)
  File "/opt/spark/python/pyspark/rdd.py", line 2916, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/opt/spark/python/pyspark/rdd.py", line 2916, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/opt/spark/python/pyspark/rdd.py", line 418, in func
    return f(iterator)
  File "/opt/spark/python/pyspark/rdd.py", line 2144, in combineLocally
    merger.mergeValues(iterator)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/shuffle.py", line 240, in mergeValues
    for k, v in iterator:
  File "/opt/spark/python/lib/pyspark.zip/pyspark/util.py", line 73, in wrapper
    return f(*args, **kwargs)
  File "/tmp/ipykernel_4505/2549108640.py", line 2, in <lambda>
TypeError: '>=' not supported between instances of 'str' and 'int'

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1209)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1215)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
24/12/04 15:48:08 WARN TaskSetManager: Lost task 0.0 in stage 23.0 (TID 23) (ip-172-31-13-94.ap-northeast-3.compute.internal executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 604, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 594, in process
    out_iter = func(split_index, iterator)
  File "/opt/spark/python/pyspark/rdd.py", line 2916, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/opt/spark/python/pyspark/rdd.py", line 2916, in pipeline_func
    return func(split, prev_func(split, iterator))
  File "/opt/spark/python/pyspark/rdd.py", line 418, in func
    return f(iterator)
  File "/opt/spark/python/pyspark/rdd.py", line 2144, in combineLocally
    merger.mergeValues(iterator)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/shuffle.py", line 240, in mergeValues
    for k, v in iterator:
  File "/opt/spark/python/lib/pyspark.zip/pyspark/util.py", line 73, in wrapper
    return f(*args, **kwargs)
  File "/tmp/ipykernel_4505/2549108640.py", line 2, in <lambda>
TypeError: '>=' not supported between instances of 'str' and 'int'

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1209)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1215)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

24/12/04 15:48:08 ERROR TaskSetManager: Task 0 in stage 23.0 failed 1 times; aborting job
[I 15:48:15.471 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
[I 15:50:15.451 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
[I 15:50:26.311 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
[I 15:54:15.475 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
[I 16:01:28.190 NotebookApp] 302 GET / (221.155.17.253) 1.330000ms
[I 16:01:28.222 NotebookApp] 302 GET /tree? (221.155.17.253) 0.470000ms
[I 16:01:33.324 NotebookApp] 302 POST /login?next=%2Ftree%3F (221.155.17.253) 83.730000ms
[W 16:01:39.889 NotebookApp] Notebook 241204_02_MovieLens_영화별점카운트.ipynb is not trusted
[I 16:04:15.491 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
[W 16:18:22.004 NotebookApp] Notebook 241204_01_RDD_API.ipynb is not trusted
[I 16:18:23.458 NotebookApp] Kernel started: 5d225b77-0888-4e09-991a-f72aeed7e06c, name: spark_start
[I 16:20:05.768 NotebookApp] Starting buffering for 5d225b77-0888-4e09-991a-f72aeed7e06c:d21c7a1282714f2db35d8ee0289aaf51
[I 16:20:07.408 NotebookApp] Starting buffering for 9f60afc1-5456-46bf-99e4-1489926a4134:d4232620e2e84951bcd140228ec211be
[I 16:22:15.469 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
[I 16:26:15.437 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
[I 16:28:15.492 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
[I 16:28:37.812 NotebookApp] 302 GET / (211.231.29.166) 0.460000ms
[I 16:30:15.496 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
[I 16:32:15.570 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
[I 16:34:15.497 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
[I 16:34:36.197 NotebookApp] Malformed HTTP message from 220.88.49.118: Malformed HTTP version in HTTP Request-Line: ''
[I 16:34:39.180 NotebookApp] 302 GET / (220.88.49.118) 0.440000ms
[I 16:34:39.216 NotebookApp] 302 GET /tree? (220.88.49.118) 0.500000ms
[I 16:34:44.046 NotebookApp] 302 POST /login?next=%2Ftree%3F (220.88.49.118) 67.010000ms
[W 16:34:49.938 NotebookApp] Notebook 241204_02_MovieLens_영화별점카운트.ipynb is not trusted
[I 16:52:15.643 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
[I 16:55:05.762 NotebookApp] Starting buffering for dc902c7d-fde4-48c8-a3be-11f27aef7399:37fa8c59fc0149dd96ecdd530299e7b7
[I 16:56:09.140 NotebookApp] 302 GET / (211.231.29.166) 0.440000ms
[W 16:56:24.809 NotebookApp] Notebook 241204_02_MovieLens_영화별점카운트.ipynb is not trusted
[I 16:56:39.500 NotebookApp] Saving file at /241204_02_MovieLens_영화별점카운트.ipynb
[W 16:56:39.500 NotebookApp] Notebook 241204_02_MovieLens_영화별점카운트.ipynb is not trusted
[I 16:56:40.513 NotebookApp] Starting buffering for dc902c7d-fde4-48c8-a3be-11f27aef7399:18a1134fa6694a94877186969b5941f3
[C 19:00:01.824 NotebookApp] received signal 15, stopping
[I 19:00:01.831 NotebookApp] Shutting down 3 kernels
[I 19:00:01.845 NotebookApp] Kernel shutdown: 9f60afc1-5456-46bf-99e4-1489926a4134
[I 19:00:01.845 NotebookApp] Kernel shutdown: 5d225b77-0888-4e09-991a-f72aeed7e06c
[I 19:00:01.845 NotebookApp] Kernel shutdown: dc902c7d-fde4-48c8-a3be-11f27aef7399
[I 19:00:01.968 NotebookApp] Shutting down 0 terminals
usage: jupyter-notebook [-h] [--debug] [--show-config] [--show-config-json]
                        [--generate-config] [-y] [--no-browser] [--no-mathjax]
                        [--allow-root] [--autoreload] [--script] [--no-script]
                        [--log-level NotebookApp.log_level]
                        [--config NotebookApp.config_file]
                        [--ip NotebookApp.ip] [--port NotebookApp.port]
                        [--port-retries NotebookApp.port_retries]
                        [--sock NotebookApp.sock]
                        [--sock-mode NotebookApp.sock_mode]
                        [--transport KernelManager.transport]
                        [--keyfile NotebookApp.keyfile]
                        [--certfile NotebookApp.certfile]
                        [--client-ca NotebookApp.client_ca]
                        [--notebook-dir NotebookApp.notebook_dir]
                        [--browser NotebookApp.browser]
                        [--pylab [NotebookApp.pylab]]
                        [--gateway-url GatewayClient.url]
                        [extra_args [extra_args ...]]
jupyter-notebook: error: argument --nobrowser: expected one argument
[W 2024-12-05 09:13:55.858 LabApp] 'ip' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2024-12-05 09:13:55.858 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2024-12-05 09:13:55.858 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2024-12-05 09:13:55.858 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2024-12-05 09:13:55.858 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[I 2024-12-05 09:13:55.866 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/lib/python3.7/site-packages/jupyterlab
[I 2024-12-05 09:13:55.866 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/share/jupyter/lab
[I 09:13:55.870 NotebookApp] Serving notebooks from local directory: /home/lab06/src
[I 09:13:55.870 NotebookApp] Jupyter Notebook 6.4.11 is running at:
[I 09:13:55.870 NotebookApp] http://ip-172-31-13-94:8906/
[I 09:13:55.870 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 09:14:16.291 NotebookApp] 302 GET / (211.231.29.166) 1.310000ms
[W 09:55:41.776 NotebookApp] Notebook 241204_01_RDD_API.ipynb is not trusted
[I 09:55:43.472 NotebookApp] Kernel started: 18bd90f6-8ddf-4346-9e1b-522df1d76e3b, name: spark_start
[I 10:14:18.238 NotebookApp] Creating new notebook in 
[I 10:14:21.910 NotebookApp] Kernel started: 33d474a5-06e3-4953-b133-6063669548e3, name: spark_start
[I 10:14:26.560 NotebookApp] Starting buffering for 18bd90f6-8ddf-4346-9e1b-522df1d76e3b:71e66296ec1444ba86cccaa620bcf509
[I 10:16:22.556 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
[W 10:16:34.015 NotebookApp] Notebook 241203_02_KVRDD.ipynb is not trusted
[I 10:16:35.579 NotebookApp] Kernel started: 8bd17a13-5817-4a8c-a3e1-fa763add82c1, name: spark_start
24/12/05 10:16:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 10:18:22.502 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
[Stage 0:>                                                          (0 + 1) / 1]24/12/05 10:20:31 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 477, in main
    ("%d.%d" % sys.version_info[:2], version))
Exception: Python in worker has different version 3.7 than that in driver 3.8, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:166)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
24/12/05 10:20:31 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (ip-172-31-13-94.ap-northeast-3.compute.internal executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 477, in main
    ("%d.%d" % sys.version_info[:2], version))
Exception: Python in worker has different version 3.7 than that in driver 3.8, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:166)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

24/12/05 10:20:31 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job
[I 10:22:22.623 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
[I 10:22:35.642 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[W 10:22:35.643 NotebookApp] Notebook 241203_02_KVRDD.ipynb is not trusted
[I 10:24:22.012 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
[I 10:28:13.690 NotebookApp] Starting buffering for 33d474a5-06e3-4953-b133-6063669548e3:ff1e6843198d4a0dbe8d3c15221332ec
[I 10:28:16.428 NotebookApp] Kernel restarted: 33d474a5-06e3-4953-b133-6063669548e3
[I 10:28:16.552 NotebookApp] Restoring connection for 33d474a5-06e3-4953-b133-6063669548e3:ff1e6843198d4a0dbe8d3c15221332ec
[I 10:28:16.553 NotebookApp] Replaying 1 buffered messages
[I 10:28:21.984 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
24/12/05 10:28:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]24/12/05 10:28:33 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 477, in main
    ("%d.%d" % sys.version_info[:2], version))
Exception: Python in worker has different version 3.7 than that in driver 3.8, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:166)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
24/12/05 10:28:33 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (ip-172-31-13-94.ap-northeast-3.compute.internal executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 477, in main
    ("%d.%d" % sys.version_info[:2], version))
Exception: Python in worker has different version 3.7 than that in driver 3.8, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:166)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

24/12/05 10:28:33 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job
24/12/05 10:29:25 ERROR Executor: Exception in task 0.0 in stage 1.0 (TID 1)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 477, in main
    ("%d.%d" % sys.version_info[:2], version))
Exception: Python in worker has different version 3.7 than that in driver 3.8, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:166)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
24/12/05 10:29:25 WARN TaskSetManager: Lost task 0.0 in stage 1.0 (TID 1) (ip-172-31-13-94.ap-northeast-3.compute.internal executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 477, in main
    ("%d.%d" % sys.version_info[:2], version))
Exception: Python in worker has different version 3.7 than that in driver 3.8, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:166)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

24/12/05 10:29:25 ERROR TaskSetManager: Task 0 in stage 1.0 failed 1 times; aborting job
[I 10:30:22.063 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
[I 10:32:22.022 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
24/12/05 10:33:06 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 2)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 477, in main
    ("%d.%d" % sys.version_info[:2], version))
Exception: Python in worker has different version 3.7 than that in driver 3.8, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:166)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
24/12/05 10:33:06 WARN TaskSetManager: Lost task 0.0 in stage 2.0 (TID 2) (ip-172-31-13-94.ap-northeast-3.compute.internal executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 477, in main
    ("%d.%d" % sys.version_info[:2], version))
Exception: Python in worker has different version 3.7 than that in driver 3.8, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:166)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

24/12/05 10:33:06 ERROR TaskSetManager: Task 0 in stage 2.0 failed 1 times; aborting job
[I 10:34:21.971 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
[I 10:35:52.292 NotebookApp] Starting buffering for 8bd17a13-5817-4a8c-a3e1-fa763add82c1:c54fbacc90d545da8561d037612fe28e
[I 10:35:54.508 NotebookApp] Creating new notebook in 
[I 10:35:56.319 NotebookApp] Kernel started: accfec3a-b4c6-4e3e-a4c0-12c6ef627c4d, name: spark_start
[I 10:36:22.533 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
[I 10:37:56.392 NotebookApp] Saving file at /241205_02_partition.ipynb
24/12/05 10:38:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
24/12/05 10:38:08 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[I 10:38:22.501 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
[Stage 0:>                                                          (0 + 1) / 1]24/12/05 10:39:33 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 477, in main
    ("%d.%d" % sys.version_info[:2], version))
Exception: Python in worker has different version 3.7 than that in driver 3.8, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:166)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
24/12/05 10:39:33 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (ip-172-31-13-94.ap-northeast-3.compute.internal executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 477, in main
    ("%d.%d" % sys.version_info[:2], version))
Exception: Python in worker has different version 3.7 than that in driver 3.8, PySpark cannot run with different minor versions. Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:166)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

24/12/05 10:39:33 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job
[I 10:39:56.431 NotebookApp] Saving file at /241205_02_partition.ipynb
[I 10:41:39.008 NotebookApp] Saving file at /241205_02_partition.ipynb
[I 10:41:39.847 NotebookApp] Starting buffering for accfec3a-b4c6-4e3e-a4c0-12c6ef627c4d:d780280225d2456b9677bda6049bf75b
[I 10:41:41.255 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
[I 10:41:42.775 NotebookApp] Starting buffering for 33d474a5-06e3-4953-b133-6063669548e3:ff1e6843198d4a0dbe8d3c15221332ec
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[W 2024-12-05 10:42:43.432 LabApp] 'ip' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2024-12-05 10:42:43.432 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2024-12-05 10:42:43.432 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2024-12-05 10:42:43.432 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2024-12-05 10:42:43.432 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[I 2024-12-05 10:42:43.439 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/lib/python3.7/site-packages/jupyterlab
[I 2024-12-05 10:42:43.439 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/share/jupyter/lab
[I 10:42:43.443 NotebookApp] Serving notebooks from local directory: /home/lab06/src
[I 10:42:43.443 NotebookApp] Jupyter Notebook 6.4.11 is running at:
[I 10:42:43.444 NotebookApp] http://ip-172-31-13-94:8906/
[I 10:42:43.444 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[W 10:43:02.146 NotebookApp] Notebook 241205_02_partition.ipynb is not trusted
[I 10:43:03.197 NotebookApp] Kernel started: b20484cb-b5d0-45de-b8e8-c68e0ce111b0, name: spark_start
24/12/05 10:43:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
24/12/05 10:43:21 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
java.io.IOException: Cannot run program "/usr/bin/python3.8": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:209)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:132)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:105)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 16 more
24/12/05 10:43:22 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (ip-172-31-13-94.ap-northeast-3.compute.internal executor driver): java.io.IOException: Cannot run program "/usr/bin/python3.8": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:209)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:132)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:105)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 16 more

24/12/05 10:43:22 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job
[Stage 0:>                                                          (0 + 0) / 1][I 10:45:03.605 NotebookApp] Saving file at /241205_02_partition.ipynb
[I 10:45:10.534 NotebookApp] Starting buffering for b20484cb-b5d0-45de-b8e8-c68e0ce111b0:9b5d78dddd6d4eb08b480d9c4d3de3f1
[I 10:45:13.223 NotebookApp] Kernel restarted: b20484cb-b5d0-45de-b8e8-c68e0ce111b0
[I 10:45:13.308 NotebookApp] Restoring connection for b20484cb-b5d0-45de-b8e8-c68e0ce111b0:9b5d78dddd6d4eb08b480d9c4d3de3f1
[I 10:45:13.308 NotebookApp] Replaying 1 buffered messages
24/12/05 10:45:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
24/12/05 10:45:25 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
java.io.IOException: Cannot run program "/usr/bin/python3.8": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:209)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:132)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:105)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 16 more
24/12/05 10:45:25 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (ip-172-31-13-94.ap-northeast-3.compute.internal executor driver): java.io.IOException: Cannot run program "/usr/bin/python3.8": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:209)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:132)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:105)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 16 more

24/12/05 10:45:25 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job
[I 10:47:03.239 NotebookApp] Saving file at /241205_02_partition.ipynb
[I 10:47:57.043 NotebookApp] Starting buffering for b20484cb-b5d0-45de-b8e8-c68e0ce111b0:9b5d78dddd6d4eb08b480d9c4d3de3f1
[I 10:48:08.595 NotebookApp] Creating new notebook in 
[I 10:48:11.230 NotebookApp] Kernel started: 1c18ea15-29b9-46e8-bbd8-175138479c00, name: spark_start
[I 10:50:11.465 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 10:54:01.734 NotebookApp] delete /myenv
[I 10:54:22.109 NotebookApp] Starting buffering for 1c18ea15-29b9-46e8-bbd8-175138479c00:a240e90a1ff5488a9fa7dbdd01c1a94a
[I 11:00:54.978 NotebookApp] 302 GET / (211.231.29.166) 0.470000ms
[I 11:01:07.974 NotebookApp] Starting buffering for b20484cb-b5d0-45de-b8e8-c68e0ce111b0:b21aa23761ef496eb4502b2cb34aa562
[I 11:01:12.862 NotebookApp] Kernel shutdown: b20484cb-b5d0-45de-b8e8-c68e0ce111b0
[I 11:01:12.863 NotebookApp] Kernel shutdown: 1c18ea15-29b9-46e8-bbd8-175138479c00
[W 11:01:12.869 NotebookApp] delete /241205_02_partition.ipynb
[W 11:01:12.871 NotebookApp] delete /241205_03_reduce.ipynb
[W 11:01:22.279 NotebookApp] Notebook 241205_01_RDD_persist.ipynb is not trusted
[I 11:01:23.593 NotebookApp] Kernel started: 241d31e1-9f44-468d-8c17-651453e8d322, name: spark_start
[I 11:01:25.768 NotebookApp] Starting buffering for 241d31e1-9f44-468d-8c17-651453e8d322:7d4c10b5091347369281156cee4d7376
[W 11:01:29.621 NotebookApp] delete /241205_01_RDD_persist.ipynb
[I 11:01:29.624 NotebookApp] Kernel shutdown: 241d31e1-9f44-468d-8c17-651453e8d322
[I 11:03:37.814 NotebookApp] The port 8906 is already in use, trying another port.
[I 11:03:37.814 NotebookApp] Serving notebooks from local directory: /home/lab06/src
[I 11:03:37.814 NotebookApp] Jupyter Notebook 6.4.10 is running at:
[I 11:03:37.814 NotebookApp] http://ip-172-31-13-94:8907/
[I 11:03:37.814 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 11:04:09.929 NotebookApp] 302 GET / (211.231.29.166) 0.440000ms
[W 11:04:46.216 NotebookApp] Notebook 241205_01_RDD_persist.ipynb is not trusted
[I 11:04:47.034 NotebookApp] Kernel started: 63a278f3-1075-48d6-bd3b-26c57b1e24d8, name: spark_start
24/12/05 11:04:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]24/12/05 11:05:03 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
java.io.IOException: Cannot run program "/usr/bin/python3.8": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:209)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:132)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:105)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 16 more
24/12/05 11:05:03 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (ip-172-31-13-94.ap-northeast-3.compute.internal executor driver): java.io.IOException: Cannot run program "/usr/bin/python3.8": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:209)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:132)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:105)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 16 more

24/12/05 11:05:03 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job
[Stage 0:>                                                          (0 + 0) / 1][I 11:05:41.297 NotebookApp] Kernel started: 7a0ed083-8935-46df-9318-c3002cde8460, name: spark_start
[I 11:06:13.001 NotebookApp] Copying 241202_Spark 환경설정.ipynb to 
[I 11:06:17.051 NotebookApp] Kernel started: fe640546-4ed0-4540-b82a-17e5ee6bed43, name: spark_start
[I 11:06:47.185 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
[W 11:06:47.186 NotebookApp] Notebook 241205_01_RDD_persist.ipynb is not trusted
[I 11:07:03.758 NotebookApp] Starting buffering for fe640546-4ed0-4540-b82a-17e5ee6bed43:d83e7c4781154fbc8604956490b74002
[I 11:07:05.538 NotebookApp] Starting buffering for 7a0ed083-8935-46df-9318-c3002cde8460:9b6628add55c48bb8626727239fed201
[I 11:07:33.264 NotebookApp] Starting buffering for fe640546-4ed0-4540-b82a-17e5ee6bed43:f29e9fc9091249418278102074a46373
[I 11:08:06.478 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
[W 11:08:06.478 NotebookApp] Notebook 241205_01_RDD_persist.ipynb is not trusted
24/12/05 11:08:21 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
java.io.IOException: Cannot run program "/usr/bin/python3.8": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:209)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:132)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:105)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 16 more
24/12/05 11:08:21 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (ip-172-31-13-94.ap-northeast-3.compute.internal executor driver): java.io.IOException: Cannot run program "/usr/bin/python3.8": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:209)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:132)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:105)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 16 more

24/12/05 11:08:21 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job
[I 11:08:29.826 NotebookApp] Kernel shutdown: fe640546-4ed0-4540-b82a-17e5ee6bed43
[W 11:08:29.827 NotebookApp] delete /241202_Spark 환경설정-Copy1.ipynb
[I 11:08:36.834 NotebookApp] Kernel shutdown: 7a0ed083-8935-46df-9318-c3002cde8460
[I 11:08:41.863 NotebookApp] Kernel shutdown: 63a278f3-1075-48d6-bd3b-26c57b1e24d8
[I 11:08:47.306 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
[W 11:08:47.306 NotebookApp] Notebook 241205_01_RDD_persist.ipynb is not trusted
[W 11:11:34.907 NotebookApp] Notebook 241205_01_RDD_persist.ipynb is not trusted
[I 11:11:35.497 NotebookApp] Kernel started: e4f2b34e-dd29-436d-9bcb-fc5b857a2b7a, name: spark_start
24/12/05 11:11:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]24/12/05 11:11:50 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
java.io.IOException: Cannot run program "/usr/bin/python3.8": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:209)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:132)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:105)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 16 more
24/12/05 11:11:50 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (ip-172-31-13-94.ap-northeast-3.compute.internal executor driver): java.io.IOException: Cannot run program "/usr/bin/python3.8": error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:209)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:132)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:105)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 16 more

24/12/05 11:11:50 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job
[W 11:13:32.586 NotebookApp] Notebook 241203_01_학생수세기.ipynb is not trusted
[I 11:13:33.207 NotebookApp] Kernel started: dd06d657-2368-4c43-bffd-35e611d719a1, name: spark_start
[I 11:13:36.497 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
[W 11:13:36.497 NotebookApp] Notebook 241205_01_RDD_persist.ipynb is not trusted
[I 11:13:44.132 NotebookApp] Starting buffering for dd06d657-2368-4c43-bffd-35e611d719a1:3e73f597b8cc49648f7eb8bdfec013bf
[I 11:14:11.267 NotebookApp] Starting buffering for e4f2b34e-dd29-436d-9bcb-fc5b857a2b7a:ce30d3834c9d4409a67e230b935dc063
[I 11:14:16.331 NotebookApp] Kernel shutdown: e4f2b34e-dd29-436d-9bcb-fc5b857a2b7a
[I 11:14:19.631 NotebookApp] Kernel shutdown: dd06d657-2368-4c43-bffd-35e611d719a1
[W 11:14:22.199 NotebookApp] Notebook 241205_01_RDD_persist.ipynb is not trusted
[I 11:14:22.843 NotebookApp] Kernel started: 10da8da3-fcce-4903-ac90-8131064c4916, name: spark_start
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[I 11:20:39.275 NotebookApp] Serving notebooks from local directory: /home/lab06/src
[I 11:20:39.275 NotebookApp] Jupyter Notebook 6.4.10 is running at:
[I 11:20:39.275 NotebookApp] http://ip-172-31-13-94:8906/
[I 11:20:39.275 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 11:20:50.959 NotebookApp] 302 GET / (211.231.29.166) 0.460000ms
[W 11:20:55.416 NotebookApp] Notebook 241205_01_RDD_persist.ipynb is not trusted
[I 11:20:55.947 NotebookApp] Kernel started: 0aaa530b-fdd0-4a82-b58a-0f61a69c2b8b, name: spark_start
24/12/05 11:20:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [W 11:21:46.673 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 11:21:47.203 NotebookApp] Kernel started: b4bbfbcc-5b4d-4bea-847e-f4e64b8a5957, name: spark_start
[I 11:21:52.768 NotebookApp] Starting buffering for b4bbfbcc-5b4d-4bea-847e-f4e64b8a5957:a2c2e791e487424b862d78f7709a418a
[I 11:22:00.841 NotebookApp] Kernel shutdown: b4bbfbcc-5b4d-4bea-847e-f4e64b8a5957
[W 11:22:00.848 NotebookApp] delete /241205_03_reduce.ipynb
[I 11:22:56.659 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
[I 11:43:13.258 NotebookApp] Starting buffering for 0aaa530b-fdd0-4a82-b58a-0f61a69c2b8b:5f7186b6d86843b58166ff29c6b02f82
[W 11:43:16.324 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 11:43:17.527 NotebookApp] Kernel started: f7ce685b-64ff-4513-9516-e230c06d5fd9, name: spark_start
[I 11:45:17.595 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 11:45:17.595 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 11:46:00.217 NotebookApp] Starting buffering for f7ce685b-64ff-4513-9516-e230c06d5fd9:b5919f85143047f88f9d61730d09d02d
[I 12:36:58.654 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
[I 12:38:36.945 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
[I 12:38:37.984 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
[I 12:38:39.139 NotebookApp] Starting buffering for 0aaa530b-fdd0-4a82-b58a-0f61a69c2b8b:4771c2ddaa09457a964a4a3e8b5ca316
[W 12:38:42.302 NotebookApp] Notebook 241205_02_partition.ipynb is not trusted
[I 12:38:42.780 NotebookApp] Kernel started: 53aeafed-9117-44af-9ff7-2c1d6dc9ca53, name: spark_start
[I 12:40:42.864 NotebookApp] Saving file at /241205_02_partition.ipynb
[W 12:40:42.865 NotebookApp] Notebook 241205_02_partition.ipynb is not trusted
[W 12:40:58.688 NotebookApp] Notebook 241205_01_RDD_persist.ipynb is not trusted
[I 12:42:59.456 NotebookApp] Saving file at /241205_01_RDD_persist.ipynb
[W 12:42:59.456 NotebookApp] Notebook 241205_01_RDD_persist.ipynb is not trusted
[I 12:44:40.147 NotebookApp] Saving file at /241205_02_partition.ipynb
[W 12:44:40.147 NotebookApp] Notebook 241205_02_partition.ipynb is not trusted
[I 12:45:17.721 NotebookApp] Starting buffering for 53aeafed-9117-44af-9ff7-2c1d6dc9ca53:eed5155a5b8941e98ae4da6ade4ffc46
[I 12:45:19.103 NotebookApp] Starting buffering for 0aaa530b-fdd0-4a82-b58a-0f61a69c2b8b:cca0262457574a3896a44ec1bbf4ab90
[W 12:45:21.646 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[W 12:50:57.474 NotebookApp] Notebook 241205_01_RDD_persist.ipynb is not trusted
[I 12:51:57.645 NotebookApp] Starting buffering for 0aaa530b-fdd0-4a82-b58a-0f61a69c2b8b:2b1cf37f302545c189c5762ce9699745
[W 12:52:00.815 NotebookApp] Notebook 241205_02_partition.ipynb is not trusted
[I 12:55:03.955 NotebookApp] Saving file at /241205_02_partition.ipynb
[W 12:55:03.955 NotebookApp] Notebook 241205_02_partition.ipynb is not trusted
[I 12:55:05.614 NotebookApp] Starting buffering for 53aeafed-9117-44af-9ff7-2c1d6dc9ca53:926715c71e524b138d1575445ffdf533
[I 12:57:22.437 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 12:57:22.438 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 12:59:22.436 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 12:59:22.437 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 12:59:49.444 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 12:59:49.444 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 13:15:22.435 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 13:15:22.436 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 13:17:22.522 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 13:17:22.522 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
24/12/05 13:17:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [I 13:19:22.437 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 13:19:22.438 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 13:21:22.466 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 13:21:22.466 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 13:23:23.541 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 13:23:23.541 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 13:25:22.477 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 13:25:22.477 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 13:31:22.433 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 13:31:22.433 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 13:33:23.095 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 13:33:23.096 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 13:39:22.454 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 13:39:22.454 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 13:45:22.463 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 13:45:22.464 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 13:47:22.426 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 13:47:22.426 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 14:03:22.456 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 14:03:22.456 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 14:05:22.467 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 14:05:22.467 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 14:07:22.413 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 14:07:22.413 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 14:09:22.419 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 14:09:22.420 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 14:11:22.414 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 14:11:22.415 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 14:13:22.983 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 14:13:22.984 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 14:15:22.423 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 14:15:22.424 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 14:17:22.432 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 14:17:22.432 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 14:19:22.406 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 14:19:22.406 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 14:21:22.409 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 14:21:22.410 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 14:39:22.468 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 14:39:22.468 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[W 14:46:06.423 NotebookApp] Notebook 241203_01_학생수세기.ipynb is not trusted
[I 14:46:07.342 NotebookApp] Kernel started: c35ae2ed-88ec-492a-bf5a-1c9f05e45f42, name: spark_start
[I 14:46:12.527 NotebookApp] Starting buffering for c35ae2ed-88ec-492a-bf5a-1c9f05e45f42:b3962188aa4341d2859fbacbe4e567cd
[W 14:46:19.575 NotebookApp] Notebook 241204_02_MovieLens_영화별점카운트.ipynb is not trusted
[I 14:46:20.631 NotebookApp] Kernel started: 73b79261-594f-457c-8e47-147dcbfb32ee, name: spark_start
[I 14:46:25.864 NotebookApp] Starting buffering for 73b79261-594f-457c-8e47-147dcbfb32ee:315a97a1bea44d37957076ed22411e38
[W 14:46:31.264 NotebookApp] Notebook 241204_01_RDD_API.ipynb is not trusted
[I 14:46:32.883 NotebookApp] Kernel started: 58adab1c-70ab-49a7-b5b4-f4c62222e3b6, name: spark_start
[I 14:49:22.498 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 14:49:22.499 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 14:51:22.478 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 14:51:22.478 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 14:53:23.523 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 14:53:23.524 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 14:53:30.478 NotebookApp] Starting buffering for 58adab1c-70ab-49a7-b5b4-f4c62222e3b6:0d709dfa2cca4983a1b9d689d62161ca
[I 14:54:05.076 NotebookApp] Saving file at /241205_03_reduce.ipynb
[W 14:54:05.076 NotebookApp] Notebook 241205_03_reduce.ipynb is not trusted
[I 14:54:55.047 NotebookApp] Creating new notebook in 
[I 14:54:57.172 NotebookApp] Kernel started: c712f1c9-f369-44a2-abb9-fca1bea5a93d, name: spark_start
[I 14:56:57.207 NotebookApp] Saving file at /241205_04_fakefrieds.ipynb
[I 14:58:57.253 NotebookApp] Saving file at /241205_04_fakefrieds.ipynb
24/12/05 15:17:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[W 15:18:17.619 NotebookApp] Notebook 241204_02_MovieLens_영화별점카운트.ipynb is not trusted
[I 15:18:57.375 NotebookApp] Saving file at /241205_04_fakefriends.ipynb
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 15:20:57.245 NotebookApp] Saving file at /241205_04_fakefriends.ipynb
[W 15:22:55.594 NotebookApp] Notebook 241203_p10_exam.ipynb is not trusted
[I 15:22:57.193 NotebookApp] Kernel started: ce292f5c-6bbb-437b-a297-169326342d34, name: spark_start
[I 15:23:04.842 NotebookApp] Starting buffering for ce292f5c-6bbb-437b-a297-169326342d34:1bb5a7cc7f504927bd864c2a2bc14a03
[W 15:23:28.589 NotebookApp] Notebook 241203_03_mnms숫자세기.ipynb is not trusted
[I 15:23:31.938 NotebookApp] Kernel started: 5032f69d-e1da-4326-8527-b00a9eb6505f, name: spark_start
[I 15:24:57.258 NotebookApp] Saving file at /241205_04_fakefriends.ipynb
[I 15:28:57.200 NotebookApp] Saving file at /241205_04_fakefriends.ipynb
[Stage 6:>                                                          (0 + 1) / 1]                                                                                [I 15:30:57.231 NotebookApp] Saving file at /241205_04_fakefriends.ipynb
[I 15:36:57.324 NotebookApp] Saving file at /241205_04_fakefriends.ipynb
[I 16:00:57.257 NotebookApp] Saving file at /241205_04_fakefriends.ipynb
[I 16:04:32.510 NotebookApp] Starting buffering for 5032f69d-e1da-4326-8527-b00a9eb6505f:7d92acd7814c4e4dac9bda63d4303e56
[I 16:04:34.242 NotebookApp] Saving file at /241205_04_fakefriends.ipynb
[I 16:04:35.570 NotebookApp] Starting buffering for c712f1c9-f369-44a2-abb9-fca1bea5a93d:1168a877a1f54a059fd1e632afc5aecc
[W 16:04:41.389 NotebookApp] Notebook 241203_01_학생수세기.ipynb is not trusted
[I 16:29:32.303 NotebookApp] 302 GET / (125.129.250.60) 0.790000ms
[I 16:29:32.336 NotebookApp] 302 GET /tree? (125.129.250.60) 0.460000ms
[I 16:29:37.576 NotebookApp] 302 POST /login?next=%2Ftree%3F (125.129.250.60) 82.850000ms
[I 16:29:37.576 NotebookApp] Malformed HTTP message from 125.129.250.60: no colon in header line
[W 16:29:41.209 NotebookApp] Notebook 241205_04_fakefriends.ipynb is not trusted
[I 16:30:00.458 NotebookApp] Starting buffering for c712f1c9-f369-44a2-abb9-fca1bea5a93d:57819bcb3bdc4bc488ab7887dee17a99
[W 16:45:52.569 NotebookApp] Notebook 241205_04_fakefriends.ipynb is not trusted
[I 17:18:56.841 NotebookApp] Starting buffering for c35ae2ed-88ec-492a-bf5a-1c9f05e45f42:8935e94544bd4cf88727ca5f10fb32a2
[W 17:19:01.544 NotebookApp] Notebook 241203_02_KVRDD.ipynb is not trusted
[I 17:19:02.693 NotebookApp] Kernel started: 11e4dac5-0f20-45b3-b9e9-9957cac22db7, name: spark_start
[I 17:19:54.362 NotebookApp] Saving file at /241205_04_RDDEAM_나이별친구수카운트.ipynb
[W 17:19:54.362 NotebookApp] Notebook 241205_04_RDDEAM_나이별친구수카운트.ipynb is not trusted
[I 17:21:02.783 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[W 17:21:02.783 NotebookApp] Notebook 241203_02_KVRDD.ipynb is not trusted
[I 17:29:02.782 NotebookApp] Saving file at /241203_02_KVRDD.ipynb
[W 17:29:02.782 NotebookApp] Notebook 241203_02_KVRDD.ipynb is not trusted
[I 17:35:12.888 NotebookApp] Starting buffering for 11e4dac5-0f20-45b3-b9e9-9957cac22db7:27e762ea33d941529eddca8e50965932
[I 17:35:15.020 NotebookApp] Starting buffering for c712f1c9-f369-44a2-abb9-fca1bea5a93d:e0f0b79f818842ba89d29e5ef46b9594
[W 17:35:20.614 NotebookApp] Notebook 241203_03_mnms숫자세기.ipynb is not trusted
[W 17:41:18.421 NotebookApp] Notebook 241203_01_학생수세기.ipynb is not trusted
[I 17:41:32.024 NotebookApp] Starting buffering for c35ae2ed-88ec-492a-bf5a-1c9f05e45f42:b2356fa955f649778d1c04a5218cf45c
[W 17:41:34.956 NotebookApp] Notebook 241203_02_KVRDD.ipynb is not trusted
[I 18:15:30.546 NotebookApp] Starting buffering for 5032f69d-e1da-4326-8527-b00a9eb6505f:f8310bbab06d44bca096069eeaf2293a
[I 18:15:31.570 NotebookApp] Starting buffering for 11e4dac5-0f20-45b3-b9e9-9957cac22db7:992aa33ee4fe414c803a77f4c415cc22
[I 18:15:46.601 NotebookApp] Starting buffering for 73b79261-594f-457c-8e47-147dcbfb32ee:17871b17a6564dfcbc7e552dff4a4bc7
[I 18:15:56.432 NotebookApp] Starting buffering for f7ce685b-64ff-4513-9516-e230c06d5fd9:6953f5645452423fbc873dcb6f488eb9
[C 18:16:24.731 NotebookApp] received signal 15, stopping
[I 18:16:24.734 NotebookApp] Shutting down 10 kernels
[I 18:16:24.890 NotebookApp] Kernel shutdown: c35ae2ed-88ec-492a-bf5a-1c9f05e45f42
[I 18:16:24.890 NotebookApp] Kernel shutdown: f7ce685b-64ff-4513-9516-e230c06d5fd9
[I 18:16:24.890 NotebookApp] Kernel shutdown: ce292f5c-6bbb-437b-a297-169326342d34
[I 18:16:24.890 NotebookApp] Kernel shutdown: 5032f69d-e1da-4326-8527-b00a9eb6505f
[I 18:16:24.890 NotebookApp] Kernel shutdown: 11e4dac5-0f20-45b3-b9e9-9957cac22db7
[I 18:16:24.890 NotebookApp] Kernel shutdown: 73b79261-594f-457c-8e47-147dcbfb32ee
[I 18:16:24.890 NotebookApp] Kernel shutdown: 53aeafed-9117-44af-9ff7-2c1d6dc9ca53
[I 18:16:24.891 NotebookApp] Kernel shutdown: c712f1c9-f369-44a2-abb9-fca1bea5a93d
[I 18:16:24.891 NotebookApp] Kernel shutdown: 0aaa530b-fdd0-4a82-b58a-0f61a69c2b8b
[I 18:16:24.891 NotebookApp] Kernel shutdown: 58adab1c-70ab-49a7-b5b4-f4c62222e3b6
[I 18:16:24.944 NotebookApp] KernelRestarter: restarting kernel (1/5), keep random ports
[E 18:16:24.946 NotebookApp] Cannot interrupt kernel. No kernel is running!
    Traceback (most recent call last):
      File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 71, in wrapper
        out = await method(self, *args, **kwargs)
      File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 479, in _async_shutdown_kernel
        await ensure_async(self.interrupt_kernel())
      File "/usr/local/lib/python3.6/dist-packages/jupyter_client/utils.py", line 26, in wrapped
        raise e
      File "/usr/local/lib/python3.6/dist-packages/jupyter_client/utils.py", line 23, in wrapped
        return loop.run_until_complete(future)
      File "/usr/local/lib/python3.6/dist-packages/nest_asyncio.py", line 89, in run_until_complete
        return f.result()
      File "/usr/lib/python3.6/asyncio/tasks.py", line 180, in _step
        result = coro.send(None)
      File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 587, in _async_interrupt_kernel
        raise RuntimeError("Cannot interrupt kernel. No kernel is running!")
    RuntimeError: Cannot interrupt kernel. No kernel is running!
[E 18:16:24.966 NotebookApp] Exception in callback <bound method KernelRestarter.poll of <jupyter_client.ioloop.restarter.IOLoopKernelRestarter object at 0x7f599b8f2a90>>
    Traceback (most recent call last):
      File "/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py", line 905, in _run
        return self.callback()
      File "/usr/local/lib/python3.6/dist-packages/jupyter_client/restarter.py", line 143, in poll
        self.kernel_manager.restart_kernel(now=True, newports=newports)
      File "/usr/local/lib/python3.6/dist-packages/jupyter_client/utils.py", line 26, in wrapped
        raise e
      File "/usr/local/lib/python3.6/dist-packages/jupyter_client/utils.py", line 23, in wrapped
        return loop.run_until_complete(future)
      File "/usr/local/lib/python3.6/dist-packages/nest_asyncio.py", line 89, in run_until_complete
        return f.result()
      File "/usr/lib/python3.6/asyncio/tasks.py", line 180, in _step
        result = coro.send(None)
      File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 523, in _async_restart_kernel
        await ensure_async(self.shutdown_kernel(now=now, restart=True))
      File "/usr/local/lib/python3.6/dist-packages/jupyter_client/utils.py", line 26, in wrapped
        raise e
      File "/usr/local/lib/python3.6/dist-packages/jupyter_client/utils.py", line 23, in wrapped
        return loop.run_until_complete(future)
      File "/usr/local/lib/python3.6/dist-packages/nest_asyncio.py", line 89, in run_until_complete
        return f.result()
      File "/usr/lib/python3.6/asyncio/tasks.py", line 180, in _step
        result = coro.send(None)
      File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 79, in wrapper
        raise e
      File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 71, in wrapper
        out = await method(self, *args, **kwargs)
      File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 479, in _async_shutdown_kernel
        await ensure_async(self.interrupt_kernel())
      File "/usr/local/lib/python3.6/dist-packages/jupyter_client/utils.py", line 26, in wrapped
        raise e
      File "/usr/local/lib/python3.6/dist-packages/jupyter_client/utils.py", line 23, in wrapped
        return loop.run_until_complete(future)
      File "/usr/local/lib/python3.6/dist-packages/nest_asyncio.py", line 89, in run_until_complete
        return f.result()
      File "/usr/lib/python3.6/asyncio/tasks.py", line 180, in _step
        result = coro.send(None)
      File "/usr/local/lib/python3.6/dist-packages/jupyter_client/manager.py", line 587, in _async_interrupt_kernel
        raise RuntimeError("Cannot interrupt kernel. No kernel is running!")
    RuntimeError: Cannot interrupt kernel. No kernel is running!
[I 18:16:24.986 NotebookApp] Shutting down 0 terminals
[I 09:08:25.375 NotebookApp] Serving notebooks from local directory: /home/lab06/src
[I 09:08:25.375 NotebookApp] Jupyter Notebook 6.4.10 is running at:
[I 09:08:25.375 NotebookApp] http://ip-172-31-13-94:8906/
[I 09:08:25.376 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 09:12:18.911 NotebookApp] 302 GET / (211.231.29.166) 0.520000ms
[I 11:33:40.247 NotebookApp] Creating new notebook in 
[I 11:33:43.086 NotebookApp] Kernel started: 37c6d859-f9f1-42c4-9bc9-60bb2109fe32, name: spark_start
[I 11:35:43.132 NotebookApp] Saving file at /241206_01_RDD_단어수세기.ipynb
24/12/06 11:40:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 11:41:43.122 NotebookApp] Saving file at /241206_01_RDD_단어수세기.ipynb
[I 11:47:43.169 NotebookApp] Saving file at /241206_01_RDD_단어수세기.ipynb
[I 13:13:43.169 NotebookApp] Saving file at /241206_01_RDD_단어수세기.ipynb
[I 13:15:43.193 NotebookApp] Saving file at /241206_01_RDD_단어수세기.ipynb
[I 13:17:43.202 NotebookApp] Saving file at /241206_01_RDD_단어수세기.ipynb
[I 13:19:43.247 NotebookApp] Saving file at /241206_01_RDD_단어수세기.ipynb
[I 13:21:43.253 NotebookApp] Saving file at /241206_01_RDD_단어수세기.ipynb
[I 13:23:43.133 NotebookApp] Saving file at /241206_01_RDD_단어수세기.ipynb
[I 13:25:43.130 NotebookApp] Saving file at /241206_01_RDD_단어수세기.ipynb
[I 13:27:43.126 NotebookApp] Saving file at /241206_01_RDD_단어수세기.ipynb
[I 13:29:43.129 NotebookApp] Saving file at /241206_01_RDD_단어수세기.ipynb
[I 13:31:43.191 NotebookApp] Saving file at /241206_01_RDD_단어수세기.ipynb
[I 13:33:36.500 NotebookApp] Saving file at /241206_01_RDD_단어수세기.ipynb
[I 13:33:51.382 NotebookApp] Saving file at /241206_01_RDD_단어수세기.ipynb
[I 13:34:22.142 NotebookApp] Starting buffering for 37c6d859-f9f1-42c4-9bc9-60bb2109fe32:a9e55c9e740741658f76d8f692e0db7d
[I 13:40:51.957 NotebookApp] Creating new notebook in 
[I 13:40:53.891 NotebookApp] Kernel started: d922a7ce-913b-4e20-a7f9-74c9f441956b, name: spark_start
[I 13:42:53.935 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[I 13:44:53.948 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
24/12/06 13:45:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[W 13:46:16.143 NotebookApp] Notebook 241206_01_RDD_단어수세기.ipynb is not trusted
[I 13:46:53.987 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 13:48:53.948 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[I 13:50:53.967 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[Stage 1:>                                                          (0 + 1) / 1]                                                                                [I 13:52:53.956 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[I 13:54:53.927 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[I 13:56:53.918 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[I 14:12:53.953 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[I 14:16:53.921 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[I 14:20:53.910 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[I 14:22:53.917 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[I 14:24:53.934 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[I 14:26:53.928 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[I 14:30:53.966 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[I 14:32:53.935 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[I 14:34:53.917 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[I 14:36:53.948 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[I 15:15:19.799 NotebookApp] Starting buffering for d922a7ce-913b-4e20-a7f9-74c9f441956b:9e3a7f5128a54c9c80f5844e03d226d8
[I 15:15:23.350 NotebookApp] Starting buffering for 37c6d859-f9f1-42c4-9bc9-60bb2109fe32:1eb411f27725490a8589d50f74b4ca05
[I 15:15:33.736 NotebookApp] Creating new notebook in 
[I 15:15:36.138 NotebookApp] Kernel started: cab6b1a5-cfb8-40d1-9002-03072db2b4f2, name: spark_start
[I 15:17:37.194 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[W 15:18:41.166 NotebookApp] Notebook 241206_02_DataFrameStart.ipynb is not trusted
[I 15:18:51.105 NotebookApp] Starting buffering for d922a7ce-913b-4e20-a7f9-74c9f441956b:6143cf4dfb604a7996078e4780d64c58
[I 15:19:36.191 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
24/12/06 15:20:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 15:21:36.194 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[I 15:23:36.178 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[I 15:25:36.182 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[I 15:27:36.184 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[I 15:35:36.303 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[Stage 15:===============>                                       (55 + 2) / 200][Stage 15:====================>                                  (75 + 2) / 200][Stage 15:===========================>                          (101 + 2) / 200][Stage 15:==================================>                   (126 + 2) / 200][Stage 15:=========================================>            (154 + 2) / 200][Stage 15:=================================================>    (185 + 2) / 200]                                                                                [Stage 18:==========================>                            (97 + 2) / 200][Stage 18:====================================>                 (134 + 2) / 200][Stage 18:=============================================>        (170 + 2) / 200][Stage 18:=====================================================>(197 + 2) / 200]                                                                                [Stage 21:====================>                                  (75 + 2) / 200][Stage 21:============================>                         (106 + 2) / 200][Stage 21:======================================>               (143 + 2) / 200][Stage 21:================================================>     (179 + 3) / 200]                                                                                [I 15:37:36.185 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[Stage 24:===========================>                           (99 + 2) / 200][Stage 24:====================================>                 (137 + 2) / 200][Stage 24:==============================================>       (172 + 2) / 200]                                                                                [I 15:39:36.181 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[I 16:36:46.427 NotebookApp] Starting buffering for cab6b1a5-cfb8-40d1-9002-03072db2b4f2:8abe0556ad6247af85efb4018c3c207e
[I 16:36:53.624 NotebookApp] Kernel shutdown: d922a7ce-913b-4e20-a7f9-74c9f441956b
[I 16:36:53.627 NotebookApp] Kernel shutdown: cab6b1a5-cfb8-40d1-9002-03072db2b4f2
[W 16:36:53.660 NotebookApp] delete /241206_02_DataFrameStart.ipynb
[W 16:36:53.670 NotebookApp] delete /241206_03_DataFrameAPI.ipynb
[W 16:36:58.686 NotebookApp] Notebook 24120602_DataFrameStart.ipynb is not trusted
[I 16:37:00.512 NotebookApp] Kernel started: f194cf38-09f9-46ce-a11f-dfe65e0a1b48, name: spark_start
[I 16:37:13.486 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[W 16:37:13.487 NotebookApp] Notebook 241206_02_DataFrameStart.ipynb is not trusted
[I 16:37:15.259 NotebookApp] Starting buffering for f194cf38-09f9-46ce-a11f-dfe65e0a1b48:a76ca4b83823497d9ae676bf2a15da20
[W 16:37:20.989 NotebookApp] Notebook 24120603_DataFrameAPI.ipynb is not trusted
[I 16:37:22.356 NotebookApp] Kernel started: 80edfb0f-2c86-434a-b84a-1db4ba680e1f, name: spark_start
24/12/06 16:37:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 16:39:22.417 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[W 16:39:22.418 NotebookApp] Notebook 241206_03_DataFrameAPI.ipynb is not trusted
[I 16:41:22.434 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[W 16:41:22.434 NotebookApp] Notebook 241206_03_DataFrameAPI.ipynb is not trusted
[I 16:43:22.383 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[W 16:43:22.383 NotebookApp] Notebook 241206_03_DataFrameAPI.ipynb is not trusted
[I 16:44:15.891 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[W 16:44:15.892 NotebookApp] Notebook 241206_03_DataFrameAPI.ipynb is not trusted
[I 16:45:22.425 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[W 16:45:22.425 NotebookApp] Notebook 241206_03_DataFrameAPI.ipynb is not trusted
[I 16:46:24.194 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[W 16:46:24.195 NotebookApp] Notebook 241206_03_DataFrameAPI.ipynb is not trusted
[W 17:17:07.445 NotebookApp] Notebook 241206_01_RDD_단어수세기.ipynb is not trusted
[I 17:17:28.690 NotebookApp] Starting buffering for 37c6d859-f9f1-42c4-9bc9-60bb2109fe32:bbae0f8b1d96450ea8eb53f3997ba573
[W 17:17:32.010 NotebookApp] Notebook 241206_02_DataFrameStart.ipynb is not trusted
[I 17:35:33.567 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[W 17:35:33.568 NotebookApp] Notebook 241206_02_DataFrameStart.ipynb is not trusted
[I 17:41:26.611 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[W 17:41:26.611 NotebookApp] Notebook 241206_02_DataFrameStart.ipynb is not trusted
[I 17:49:35.255 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[W 17:49:35.256 NotebookApp] Notebook 241206_02_DataFrameStart.ipynb is not trusted
[I 17:51:33.539 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[W 17:51:33.540 NotebookApp] Notebook 241206_02_DataFrameStart.ipynb is not trusted
[I 17:53:33.550 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[W 17:53:33.551 NotebookApp] Notebook 241206_02_DataFrameStart.ipynb is not trusted
[I 17:55:20.191 NotebookApp] Saving file at /241206_02_DataFrameStart.ipynb
[W 17:55:20.191 NotebookApp] Notebook 241206_02_DataFrameStart.ipynb is not trusted
[I 17:55:27.128 NotebookApp] Starting buffering for f194cf38-09f9-46ce-a11f-dfe65e0a1b48:643c6a6e37e9466f8de913868aec1741
[I 17:55:27.728 NotebookApp] Starting buffering for 80edfb0f-2c86-434a-b84a-1db4ba680e1f:92e58785c87e47aaac4bf930af8f1464
[C 17:55:46.019 NotebookApp] received signal 15, stopping
[I 17:55:46.035 NotebookApp] Shutting down 3 kernels
[I 17:55:46.047 NotebookApp] Kernel shutdown: f194cf38-09f9-46ce-a11f-dfe65e0a1b48
[I 17:55:46.047 NotebookApp] Kernel shutdown: 80edfb0f-2c86-434a-b84a-1db4ba680e1f
[I 17:55:46.048 NotebookApp] Kernel shutdown: 37c6d859-f9f1-42c4-9bc9-60bb2109fe32
[I 17:55:46.097 NotebookApp] Shutting down 0 terminals
[I 09:08:08.499 NotebookApp] Serving notebooks from local directory: /home/lab06/src
[I 09:08:08.500 NotebookApp] Jupyter Notebook 6.4.10 is running at:
[I 09:08:08.500 NotebookApp] http://ip-172-31-13-94:8906/
[I 09:08:08.500 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 09:08:15.063 NotebookApp] 302 GET / (211.231.29.166) 0.510000ms
[W 10:13:08.433 NotebookApp] Notebook 241206_03_DataFrameAPI.ipynb is not trusted
[I 10:13:10.766 NotebookApp] Kernel started: bc999555-af88-4e00-80d3-bfe142ab97ef, name: spark_start
24/12/09 10:13:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 31:=======================>                               (87 + 2) / 200][Stage 31:===============================>                      (117 + 2) / 200][Stage 31:=======================================>              (145 + 2) / 200][Stage 31:================================================>     (178 + 2) / 200]                                                                                [I 10:15:10.847 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[I 10:17:11.043 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[I 10:17:21.641 NotebookApp] Starting buffering for bc999555-af88-4e00-80d3-bfe142ab97ef:702d28c9619f47f2923e8d68abb46a27
[I 10:22:17.775 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[I 10:25:53.022 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[I 10:27:53.024 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[I 10:29:53.009 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[I 10:31:54.321 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[I 10:33:53.037 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[I 10:35:53.042 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[I 10:37:53.783 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[I 10:39:53.008 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[I 10:40:25.868 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[I 10:45:53.069 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[I 10:59:36.088 NotebookApp] Starting buffering for bc999555-af88-4e00-80d3-bfe142ab97ef:5fe85adee3564beb80438b15dd0c7be9
[I 11:41:24.850 NotebookApp] Kernel shutdown: bc999555-af88-4e00-80d3-bfe142ab97ef
[W 11:41:31.068 NotebookApp] delete /241206_03_DataFrameAPI.ipynb
[W 11:42:17.408 NotebookApp] Notebook 24120603_DataFrameAPI.ipynb is not trusted
[I 11:42:20.226 NotebookApp] Kernel started: c3b573e4-1f89-4aca-a230-07f5731ec0bd, name: spark_start
[I 11:42:31.460 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[W 11:42:31.460 NotebookApp] Notebook 241206_03_DataFrameAPI.ipynb is not trusted
[I 11:42:32.055 NotebookApp] Saving file at /241206_03_DataFrameAPI.ipynb
[W 11:42:32.056 NotebookApp] Notebook 241206_03_DataFrameAPI.ipynb is not trusted
[I 11:42:35.105 NotebookApp] Starting buffering for c3b573e4-1f89-4aca-a230-07f5731ec0bd:7a31e67093f54a738b64779c76793988
[W 11:50:58.922 NotebookApp] 404 GET /api/contents/data?type=directory&_=1733712655813 (211.231.29.166): No such file or directory: data
[W 11:50:58.922 NotebookApp] No such file or directory: data
[W 11:50:58.923 NotebookApp] 404 GET /api/contents/data?type=directory&_=1733712655813 (211.231.29.166) 1.000000ms referer=http://13.208.159.5:8906/tree/data
[W 11:51:00.043 NotebookApp] 404 GET /api/contents/data?type=directory&_=1733712655814 (211.231.29.166): No such file or directory: data
[W 11:51:00.044 NotebookApp] No such file or directory: data
[W 11:51:00.044 NotebookApp] 404 GET /api/contents/data?type=directory&_=1733712655814 (211.231.29.166) 0.980000ms referer=http://13.208.159.5:8906/tree/data
[W 11:53:26.055 NotebookApp] 404 GET /api/contents/data?type=directory&_=1733712741715 (211.231.29.166): No such file or directory: data
[W 11:53:26.055 NotebookApp] No such file or directory: data
[W 11:53:26.057 NotebookApp] 404 GET /api/contents/data?type=directory&_=1733712741715 (211.231.29.166) 2.040000ms referer=http://13.208.159.5:8906/tree/data
[W 11:53:26.724 NotebookApp] 404 GET /api/contents/data?type=directory&_=1733712741716 (211.231.29.166): No such file or directory: data
[W 11:53:26.724 NotebookApp] No such file or directory: data
[W 11:53:26.725 NotebookApp] 404 GET /api/contents/data?type=directory&_=1733712741716 (211.231.29.166) 1.390000ms referer=http://13.208.159.5:8906/tree/data
[W 11:53:28.279 NotebookApp] 404 GET /api/contents/data?type=directory&_=1733712741717 (211.231.29.166): No such file or directory: data
[W 11:53:28.279 NotebookApp] No such file or directory: data
[W 11:53:28.280 NotebookApp] 404 GET /api/contents/data?type=directory&_=1733712741717 (211.231.29.166) 1.370000ms referer=http://13.208.159.5:8906/tree/data
[W 11:53:34.453 NotebookApp] 404 GET /api/contents/data?type=directory&_=1733712741720 (211.231.29.166): No such file or directory: data
[W 11:53:34.453 NotebookApp] No such file or directory: data
[W 11:53:34.453 NotebookApp] 404 GET /api/contents/data?type=directory&_=1733712741720 (211.231.29.166) 1.280000ms referer=http://13.208.159.5:8906/tree/data
[I 11:56:17.370 NotebookApp] Kernel shutdown: c3b573e4-1f89-4aca-a230-07f5731ec0bd
[W 11:56:17.386 NotebookApp] delete /241202_Spark 환경설정-Copy1.ipynb
[W 11:56:17.422 NotebookApp] delete /241205_02_partition.ipynb
[W 11:56:17.424 NotebookApp] delete /241205_01_RDD_persist.ipynb
[W 11:56:17.425 NotebookApp] delete /241205_03_reduce.2.ipynb
[W 11:56:17.429 NotebookApp] delete /241205_03_reduce.ipynb
[W 11:56:17.429 NotebookApp] delete /241206_02_DataFrameStart.ipynb
[W 11:56:17.457 NotebookApp] delete /241206_03_DataFrameAPI.2.ipynb
[W 11:56:17.459 NotebookApp] delete /241206_03_DataFrameAPI.ipynb
[W 11:56:17.463 NotebookApp] delete /Untitled.ipynb
[W 11:57:38.546 NotebookApp] 404 GET /tree/data (211.231.29.166) 7.970000ms referer=http://13.208.159.5:8906/tree/data
[W 11:58:10.124 NotebookApp] Notebook DA-learning-course/Spark/241203_01_학생수세기.ipynb is not trusted
[I 11:58:10.533 NotebookApp] Kernel started: 5cd4c4f7-7102-4c8f-8d22-cb9659cdb2fc, name: spark_start
[I 11:58:14.226 NotebookApp] Starting buffering for 5cd4c4f7-7102-4c8f-8d22-cb9659cdb2fc:f3471296fa8b42338c2e84e0cd7b0541
[I 11:58:18.775 NotebookApp] Kernel started: 14a91815-9d30-43ff-a4e6-40321dd7a43c, name: spark_start
[I 11:58:31.279 NotebookApp] Starting buffering for 14a91815-9d30-43ff-a4e6-40321dd7a43c:e65a9250a3114d49b9d27918cfa99345
[I 12:17:01.829 NotebookApp] 302 GET / (211.231.29.166) 0.410000ms
[W 13:27:39.216 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[I 13:27:41.872 NotebookApp] Kernel started: a89bff14-39b8-433a-ba8d-f26472851227, name: spark_start
[W 13:35:12.829 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[W 13:35:12.860 NotebookApp] Trusting notebook /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 13:35:13.311 NotebookApp] Starting buffering for a89bff14-39b8-433a-ba8d-f26472851227:03a1f82049f9479396a8ea86d071bfd2
[I 13:41:17.886 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 13:41:39.181 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 13:41:40.216 NotebookApp] Starting buffering for a89bff14-39b8-433a-ba8d-f26472851227:95160d6eb01342bdbd5718932b7600a7
[W 13:41:58.002 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
24/12/09 13:53:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 13:54:01.051 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[W 13:54:01.052 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[Stage 31:===================>                                   (72 + 3) / 200][Stage 31:===========================>                           (99 + 2) / 200][Stage 31:================================>                     (122 + 2) / 200][Stage 31:=========================================>            (153 + 3) / 200][Stage 31:=================================================>    (182 + 2) / 200]                                                                                [Stage 20:============================================>         (163 + 2) / 200]                                                                                [Stage 23:======================================>               (144 + 2) / 200][Stage 23:===================================================>  (191 + 2) / 200]                                                                                [Stage 36:=============================================>        (169 + 2) / 200]                                                                                24/12/09 13:55:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
24/12/09 13:55:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[I 13:56:00.940 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 14:02:01.006 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 14:04:01.018 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[Stage 95:===============================>                      (117 + 2) / 200][Stage 95:===========================================>          (161 + 2) / 200]                                                                                [I 14:12:00.981 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 14:14:00.934 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 14:16:01.736 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 14:18:01.805 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 14:20:00.954 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 14:24:03.290 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 14:26:01.089 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 14:28:01.036 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 14:30:01.953 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 14:32:01.029 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 14:36:01.627 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 14:38:02.360 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 14:42:00.941 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 14:48:01.001 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 14:50:00.979 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 14:51:14.551 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[I 14:52:58.237 NotebookApp] Starting buffering for a89bff14-39b8-433a-ba8d-f26472851227:b3241a5851424016860f19023d08182b
[W 14:53:01.019 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[I 14:57:57.445 NotebookApp] Starting buffering for a89bff14-39b8-433a-ba8d-f26472851227:56bbd6a5c30c43da8819c6a0447a95c8
[W 14:57:59.048 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[I 14:59:37.472 NotebookApp] Starting buffering for a89bff14-39b8-433a-ba8d-f26472851227:881f69c56a3741febcf8b5fb43a2823b
[W 15:00:34.702 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[I 15:02:37.309 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[W 15:02:37.311 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[I 15:06:37.785 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[W 15:06:37.786 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[I 15:08:37.396 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[W 15:08:37.398 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[I 15:10:37.275 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[W 15:10:37.276 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[Stage 177:==========================================>          (159 + 3) / 200]                                                                                [Stage 179:==================================>                  (131 + 2) / 200][Stage 179:===================================================> (194 + 2) / 200]                                                                                [I 15:24:41.105 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[W 15:24:41.106 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[I 15:24:41.199 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[W 15:24:41.200 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[I 15:24:45.423 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[W 15:24:45.424 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[Stage 181:================================================>    (183 + 2) / 200]                                                                                [I 15:26:37.438 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[W 15:26:37.440 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[I 15:28:37.351 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[W 15:28:37.352 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[Stage 183:=====================================>               (143 + 3) / 200]                                                                                [I 15:30:37.291 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[W 15:30:37.292 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[Stage 187:==================================================>  (190 + 2) / 200]                                                                                [I 15:38:37.811 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[W 15:38:37.813 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[I 15:42:37.409 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[W 15:42:37.410 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[Stage 211:================================>                    (122 + 2) / 200][Stage 211:===============================================>     (179 + 2) / 200]                                                                                [I 15:44:37.374 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[W 15:44:37.376 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[I 15:52:37.729 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[W 15:52:37.759 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[I 15:58:37.370 NotebookApp] Saving file at /DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb
[W 15:58:37.371 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[I 16:01:17.169 NotebookApp] Starting buffering for a89bff14-39b8-433a-ba8d-f26472851227:3826afcead0c4219b26b18754eb771d9
[I 16:02:13.510 NotebookApp] Creating new notebook in /DA-learning-course/Spark
[I 16:02:16.620 NotebookApp] Kernel started: 8debf1de-a104-4459-8fd1-7ecc832cd681, name: spark_start
[W 16:03:28.049 NotebookApp] Notebook DA-learning-course/Spark/241206_03_DataFrameAPI.ipynb is not trusted
[I 16:04:17.677 NotebookApp] Saving file at /DA-learning-course/Spark/241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 16:22:17.699 NotebookApp] Saving file at /DA-learning-course/Spark/241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
24/12/09 16:22:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 16:24:04.185 NotebookApp] Saving file at /DA-learning-course/Spark/241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 16:24:08.059 NotebookApp] Starting buffering for 8debf1de-a104-4459-8fd1-7ecc832cd681:9b05b8e0dcd8453b8439d82553903beb
[I 16:24:10.690 NotebookApp] Kernel restarted: 8debf1de-a104-4459-8fd1-7ecc832cd681
[I 16:24:10.782 NotebookApp] Restoring connection for 8debf1de-a104-4459-8fd1-7ecc832cd681:9b05b8e0dcd8453b8439d82553903beb
[I 16:24:10.782 NotebookApp] Replaying 1 buffered messages
24/12/09 16:24:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 16:24:16.644 NotebookApp] Saving file at /DA-learning-course/Spark/241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 16:26:16.659 NotebookApp] Saving file at /DA-learning-course/Spark/241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 16:27:29.866 NotebookApp] Saving file at /DA-learning-course/Spark/241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 16:27:31.998 NotebookApp] Starting buffering for 8debf1de-a104-4459-8fd1-7ecc832cd681:9b05b8e0dcd8453b8439d82553903beb
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[IPKernelApp] WARNING | Parent appears to have exited, shutting down.
[I 2024-12-09 16:28:57.689 ServerApp] jupyter_lsp | extension was successfully linked.
[I 2024-12-09 16:28:57.693 ServerApp] jupyter_server_terminals | extension was successfully linked.
[I 2024-12-09 16:28:57.698 ServerApp] jupyterlab | extension was successfully linked.
[W 2024-12-09 16:28:57.699 JupyterNotebookApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2024-12-09 16:28:57.702 ServerApp] ServerApp.password config is deprecated in 2.0. Use PasswordIdentityProvider.hashed_password.
[I 2024-12-09 16:28:57.702 ServerApp] notebook | extension was successfully linked.
[I 2024-12-09 16:28:57.703 ServerApp] Writing Jupyter server cookie secret to /home/lab06/.local/share/jupyter/runtime/jupyter_cookie_secret
[W 2024-12-09 16:28:57.888 ServerApp] A `_jupyter_server_extension_points` function was not found in jupyter_nbextensions_configurator. Instead, a `_jupyter_server_extension_paths` function was found and will be used for now. This function name will be deprecated in future releases of Jupyter Server.
[I 2024-12-09 16:28:57.888 ServerApp] jupyter_nbextensions_configurator | extension was found and enabled by notebook_shim. Consider moving the extension to Jupyter Server's extension paths.
[I 2024-12-09 16:28:57.888 ServerApp] jupyter_nbextensions_configurator | extension was successfully linked.
[I 2024-12-09 16:28:57.888 ServerApp] notebook_shim | extension was successfully linked.
[I 2024-12-09 16:28:57.922 ServerApp] notebook_shim | extension was successfully loaded.
[I 2024-12-09 16:28:57.924 ServerApp] jupyter_lsp | extension was successfully loaded.
[I 2024-12-09 16:28:57.925 ServerApp] [jupyter_nbextensions_configurator] enabled 0.6.4
[I 2024-12-09 16:28:57.925 ServerApp] jupyter_nbextensions_configurator | extension was successfully loaded.
[I 2024-12-09 16:28:57.925 ServerApp] jupyter_server_terminals | extension was successfully loaded.
[I 2024-12-09 16:28:57.930 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyterlab
[I 2024-12-09 16:28:57.930 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/envs/spark_start/share/jupyter/lab
[I 2024-12-09 16:28:57.931 LabApp] Extension Manager is 'pypi'.
[I 2024-12-09 16:28:57.977 ServerApp] jupyterlab | extension was successfully loaded.
[I 2024-12-09 16:28:57.980 ServerApp] notebook | extension was successfully loaded.
[I 2024-12-09 16:28:57.981 ServerApp] Serving notebooks from local directory: /home/lab06/src/DA-learning-course/Spark
[I 2024-12-09 16:28:57.981 ServerApp] Jupyter Server 2.14.2 is running at:
[I 2024-12-09 16:28:57.981 ServerApp] http://ip-172-31-13-94:8906/tree
[I 2024-12-09 16:28:57.981 ServerApp]     http://127.0.0.1:8906/tree
[I 2024-12-09 16:28:57.981 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 2024-12-09 16:28:57.996 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server
[I 2024-12-09 16:29:13.163 ServerApp] 302 GET / (@211.231.29.166) 0.41ms
[W 2024-12-09 16:29:13.228 ServerApp] Clearing invalid/expired login cookie username-13-208-159-5-8906
[I 2024-12-09 16:29:13.229 JupyterNotebookApp] 302 GET /tree? (@211.231.29.166) 1.41ms
[I 2024-12-09 16:29:21.969 ServerApp] User 0a40d701d720458c844179d0b37eb071 logged in.
[I 2024-12-09 16:29:21.970 ServerApp] 302 POST /login?next=%2Ftree%3F (0a40d701d720458c844179d0b37eb071@211.231.29.166) 72.66ms
[E 2024-12-09 16:29:36.219 ServerApp] Uncaught exception GET /api/nbconvert?1733729376095 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733729376095', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-09 16:29:36.226 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-09 16:29:36.226 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-09 16:29:36.226 ServerApp] 500 GET /api/nbconvert?1733729376095 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 170.22ms referer=http://13.208.159.5:8906/tree?
[W 2024-12-09 16:29:36.282 ServerApp] Notebook 241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb is not trusted
[E 2024-12-09 16:29:39.476 ServerApp] Uncaught exception GET /api/nbconvert?1733729379480 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733729379480', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-09 16:29:39.477 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-09 16:29:39.477 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-09 16:29:39.477 ServerApp] 500 GET /api/nbconvert?1733729379480 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 40.68ms referer=http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb
[W 2024-12-09 16:29:39.626 ServerApp] Notebook 241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb is not trusted
[I 2024-12-09 16:29:41.143 ServerApp] Kernel started: 0bd2dd07-9ee9-411a-8e73-0f1bdd451956
[I 2024-12-09 16:29:41.576 ServerApp] Connecting to kernel 0bd2dd07-9ee9-411a-8e73-0f1bdd451956.
[I 2024-12-09 16:29:41.745 ServerApp] Connecting to kernel 0bd2dd07-9ee9-411a-8e73-0f1bdd451956.
[I 2024-12-09 16:29:41.912 ServerApp] Connecting to kernel 0bd2dd07-9ee9-411a-8e73-0f1bdd451956.
[W 2024-12-09 16:29:46.007 ServerApp] Notebook 241206_03_DataFrameAPI.ipynb is not trusted
[I 2024-12-09 16:29:48.975 ServerApp] Connecting to kernel 0bd2dd07-9ee9-411a-8e73-0f1bdd451956.
[E 2024-12-09 16:29:49.770 ServerApp] Uncaught exception GET /api/nbconvert?1733729389761 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733729389761', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-09 16:29:49.770 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-09 16:29:49.771 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241206_03_DataFrameAPI.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-09 16:29:49.771 ServerApp] 500 GET /api/nbconvert?1733729389761 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 41.68ms referer=http://13.208.159.5:8906/notebooks/241206_03_DataFrameAPI.ipynb
[W 2024-12-09 16:29:50.058 ServerApp] Notebook 241206_03_DataFrameAPI.ipynb is not trusted
[I 2024-12-09 16:29:52.590 ServerApp] Connecting to kernel 0bd2dd07-9ee9-411a-8e73-0f1bdd451956.
[I 2024-12-09 16:29:53.422 ServerApp] Kernel started: 4b9039d6-cbeb-4212-ab03-53781d4f1c98
[I 2024-12-09 16:29:54.503 ServerApp] Connecting to kernel 4b9039d6-cbeb-4212-ab03-53781d4f1c98.
24/12/09 16:30:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1][Stage 0:===========================================================(1 + 0) / 1]                                                                                [I 2024-12-09 16:31:40.316 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 16:33:40.460 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 16:35:40.620 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 16:36:13.413 ServerApp] 302 GET /login?next=%2Ftree%3F (0a40d701d720458c844179d0b37eb071@211.231.29.166) 0.71ms
[I 2024-12-09 16:36:15.827 ServerApp] Connecting to kernel 0bd2dd07-9ee9-411a-8e73-0f1bdd451956.
[I 2024-12-09 16:36:15.942 ServerApp] Connecting to kernel 4b9039d6-cbeb-4212-ab03-53781d4f1c98.
[W 2024-12-09 16:36:53.514 ServerApp] delete /Learning
[I 2024-12-09 16:37:21.623 ServerApp] Connecting to kernel 0bd2dd07-9ee9-411a-8e73-0f1bdd451956.
[I 2024-12-09 16:37:21.726 ServerApp] Connecting to kernel 4b9039d6-cbeb-4212-ab03-53781d4f1c98.
24/12/09 16:38:35 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[I 2024-12-09 16:39:52.358 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 16:41:52.629 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 16:45:53.700 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 16:53:55.076 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 16:55:55.243 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 16:57:55.437 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 16:59:55.600 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 17:01:55.760 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 2:>                                                          (0 + 2) / 2][Stage 2:=============================>                             (1 + 1) / 2][Stage 3:========>                                               (30 + 3) / 200][Stage 3:============>                                           (46 + 3) / 200][Stage 3:==================>                                     (65 + 2) / 200][Stage 3:========================>                               (88 + 3) / 200][Stage 3:===============================>                       (115 + 2) / 200][Stage 3:=======================================>               (142 + 2) / 200][Stage 3:===============================================>       (171 + 2) / 200][Stage 3:===================================================>   (189 + 2) / 200]                                                                                [I 2024-12-09 17:03:55.922 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 5:=============================>                             (1 + 1) / 2][Stage 6:==========================>                             (93 + 2) / 200][Stage 6:==================================>                    (124 + 2) / 200][Stage 6:==============================================>        (168 + 2) / 200]                                                                                [Stage 8:>                                                          (0 + 2) / 2][Stage 8:=============================>                             (1 + 1) / 2][Stage 9:===========================>                            (98 + 2) / 200][Stage 9:======================================>                (140 + 2) / 200][Stage 9:================================================>      (177 + 2) / 200]                                                                                [I 2024-12-09 17:05:56.078 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 11:>                                                         (0 + 2) / 2]                                                                                [I 2024-12-09 17:07:56.218 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 17:11:56.382 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 17:13:56.543 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 17:19:04.307 ServerApp] 302 GET / (@221.155.17.253) 0.44ms
[W 2024-12-09 17:19:04.344 ServerApp] Clearing invalid/expired login cookie username-13-208-159-5-8906
[I 2024-12-09 17:19:04.344 JupyterNotebookApp] 302 GET /tree? (@221.155.17.253) 0.72ms
[W 2024-12-09 17:19:12.498 ServerApp] 401 POST /login?next=%2Ftree%3F (@221.155.17.253) 66.11ms referer=http://13.208.159.5:8906/login?next=%2Ftree%3F
[I 2024-12-09 17:19:17.925 ServerApp] User d32360df1bf04e038cfede77c3a772c0 logged in.
[I 2024-12-09 17:19:17.925 ServerApp] 302 POST /login?next=%2Ftree%3F (d32360df1bf04e038cfede77c3a772c0@221.155.17.253) 66.19ms
[I 2024-12-09 17:19:19.776 ServerApp] Connecting to kernel 0bd2dd07-9ee9-411a-8e73-0f1bdd451956.
[I 2024-12-09 17:19:19.855 ServerApp] Connecting to kernel 4b9039d6-cbeb-4212-ab03-53781d4f1c98.
[E 2024-12-09 17:19:21.907 ServerApp] Uncaught exception GET /api/nbconvert?1733732360412 (221.155.17.253)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733732360412', version='HTTP/1.1', remote_ip='221.155.17.253')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-09 17:19:21.908 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-09 17:19:21.908 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-09 17:19:21.908 ServerApp] 500 GET /api/nbconvert?1733732360412 (d32360df1bf04e038cfede77c3a772c0@221.155.17.253) 55.93ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-09 17:19:22.544 ServerApp] Connecting to kernel 0bd2dd07-9ee9-411a-8e73-0f1bdd451956.
[I 2024-12-09 17:19:22.645 ServerApp] Connecting to kernel 4b9039d6-cbeb-4212-ab03-53781d4f1c98.
[E 2024-12-09 17:19:22.656 ServerApp] Uncaught exception GET /api/nbconvert?1733732361149 (221.155.17.253)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733732361149', version='HTTP/1.1', remote_ip='221.155.17.253')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-09 17:19:22.656 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-09 17:19:22.657 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-09 17:19:22.658 ServerApp] 500 GET /api/nbconvert?1733732361149 (d32360df1bf04e038cfede77c3a772c0@221.155.17.253) 69.70ms referer=http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb
[I 2024-12-09 17:19:22.923 ServerApp] Connecting to kernel 0bd2dd07-9ee9-411a-8e73-0f1bdd451956.
[I 2024-12-09 17:19:56.831 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 21:>                                                         (0 + 2) / 2][Stage 21:=============================>                            (1 + 1) / 2][Stage 22:======================>                                (81 + 2) / 200][Stage 22:==============================>                       (112 + 2) / 200][Stage 22:=========================================>            (153 + 2) / 200][Stage 22:====================================================> (196 + 2) / 200]                                                                                [I 2024-12-09 17:25:57.256 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 17:27:57.422 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 24:=======================================>              (148 + 2) / 200][Stage 24:====================================================> (196 + 2) / 200]                                                                                [I 2024-12-09 17:29:57.572 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 17:31:58.047 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 17:33:58.272 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 25:=============================>                            (1 + 1) / 2]                                                                                [Stage 27:>                                                         (0 + 2) / 2][Stage 28:=====================================>                (138 + 2) / 200][Stage 28:====================================================> (193 + 2) / 200]                                                                                [I 2024-12-09 17:35:58.468 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 30:===================================>                  (131 + 3) / 200][Stage 30:==================================================>   (188 + 3) / 200]                                                                                [Stage 32:====================================================> (194 + 3) / 200]                                                                                [I 2024-12-09 17:37:58.706 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 33:>                                                         (0 + 2) / 2][Stage 34:====================================>                 (135 + 2) / 200][Stage 34:===================================================>  (192 + 2) / 200]                                                                                [I 2024-12-09 17:39:58.860 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 35:>                                                         (0 + 2) / 2][Stage 36:==================================================>   (186 + 2) / 200]                                                                                [I 2024-12-09 17:41:59.017 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 37:=============================>                            (1 + 1) / 2][Stage 38:===================================================>  (190 + 2) / 200]                                                                                [I 2024-12-09 17:43:59.223 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 17:45:59.477 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 17:47:59.639 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 17:48:16.745 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 17:49:15.876 ServerApp] Connecting to kernel 0bd2dd07-9ee9-411a-8e73-0f1bdd451956.
[I 2024-12-09 17:49:15.964 ServerApp] Connecting to kernel 4b9039d6-cbeb-4212-ab03-53781d4f1c98.
[I 2024-12-09 17:52:14.805 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-09 17:57:47.822 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[C 2024-12-09 18:02:30.868 ServerApp] received signal 15, stopping
[I 2024-12-09 18:02:30.868 ServerApp] Shutting down 6 extensions
[I 2024-12-09 18:02:30.869 ServerApp] Shutting down 2 kernels
[I 2024-12-09 18:02:30.869 ServerApp] Kernel shutdown: 0bd2dd07-9ee9-411a-8e73-0f1bdd451956
[I 2024-12-09 18:02:30.869 ServerApp] Kernel shutdown: 4b9039d6-cbeb-4212-ab03-53781d4f1c98
[I 2024-12-10 09:45:56.691 ServerApp] jupyter_lsp | extension was successfully linked.
[I 2024-12-10 09:45:56.696 ServerApp] jupyter_server_terminals | extension was successfully linked.
[I 2024-12-10 09:45:56.700 ServerApp] jupyterlab | extension was successfully linked.
[W 2024-12-10 09:45:56.702 JupyterNotebookApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2024-12-10 09:45:56.705 ServerApp] ServerApp.password config is deprecated in 2.0. Use PasswordIdentityProvider.hashed_password.
[I 2024-12-10 09:45:56.705 ServerApp] notebook | extension was successfully linked.
[W 2024-12-10 09:45:57.098 ServerApp] A `_jupyter_server_extension_points` function was not found in jupyter_nbextensions_configurator. Instead, a `_jupyter_server_extension_paths` function was found and will be used for now. This function name will be deprecated in future releases of Jupyter Server.
[I 2024-12-10 09:45:57.098 ServerApp] jupyter_nbextensions_configurator | extension was found and enabled by notebook_shim. Consider moving the extension to Jupyter Server's extension paths.
[I 2024-12-10 09:45:57.098 ServerApp] jupyter_nbextensions_configurator | extension was successfully linked.
[I 2024-12-10 09:45:57.098 ServerApp] notebook_shim | extension was successfully linked.
[I 2024-12-10 09:45:57.171 ServerApp] notebook_shim | extension was successfully loaded.
[I 2024-12-10 09:45:57.173 ServerApp] jupyter_lsp | extension was successfully loaded.
[I 2024-12-10 09:45:57.173 ServerApp] [jupyter_nbextensions_configurator] enabled 0.6.4
[I 2024-12-10 09:45:57.173 ServerApp] jupyter_nbextensions_configurator | extension was successfully loaded.
[I 2024-12-10 09:45:57.175 ServerApp] jupyter_server_terminals | extension was successfully loaded.
[I 2024-12-10 09:45:57.183 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyterlab
[I 2024-12-10 09:45:57.183 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/envs/spark_start/share/jupyter/lab
[I 2024-12-10 09:45:57.183 LabApp] Extension Manager is 'pypi'.
[I 2024-12-10 09:45:57.250 ServerApp] jupyterlab | extension was successfully loaded.
[I 2024-12-10 09:45:57.254 ServerApp] notebook | extension was successfully loaded.
[I 2024-12-10 09:45:57.254 ServerApp] Serving notebooks from local directory: /home/lab06/src/DA-learning-course/Spark
[I 2024-12-10 09:45:57.254 ServerApp] Jupyter Server 2.14.2 is running at:
[I 2024-12-10 09:45:57.254 ServerApp] http://ip-172-31-13-94:8906/tree
[I 2024-12-10 09:45:57.254 ServerApp]     http://127.0.0.1:8906/tree
[I 2024-12-10 09:45:57.254 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 2024-12-10 09:45:57.271 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server
[I 2024-12-10 09:46:07.466 ServerApp] 302 GET / (@211.231.29.166) 0.37ms
[E 2024-12-10 09:46:14.582 ServerApp] Uncaught exception GET /api/nbconvert?1733791574082 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733791574082', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 09:46:14.593 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 09:46:14.594 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 09:46:14.594 ServerApp] 500 GET /api/nbconvert?1733791574082 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 365.97ms referer=http://13.208.159.5:8906/tree?
[E 2024-12-10 09:46:17.606 ServerApp] Uncaught exception GET /api/nbconvert?1733791577471 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733791577471', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 09:46:17.606 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 09:46:17.606 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 09:46:17.606 ServerApp] 500 GET /api/nbconvert?1733791577471 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 40.78ms referer=http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb
[I 2024-12-10 09:46:19.820 ServerApp] Kernel started: 7e98d41c-3bad-4316-9d9b-174390ef482f
[I 2024-12-10 09:46:20.381 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 09:46:20.485 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 09:46:20.643 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 09:46:21.184 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 09:49:15.123 ServerApp] 302 GET / (@221.155.17.253) 0.30ms
[I 2024-12-10 09:49:16.425 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[E 2024-12-10 09:49:23.653 ServerApp] Uncaught exception GET /api/nbconvert?1733791763041 (221.155.17.253)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733791763041', version='HTTP/1.1', remote_ip='221.155.17.253')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 09:49:23.654 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 09:49:23.654 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 09:49:23.654 ServerApp] 500 GET /api/nbconvert?1733791763041 (d32360df1bf04e038cfede77c3a772c0@221.155.17.253) 57.61ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-10 09:49:24.224 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[E 2024-12-10 09:49:24.325 ServerApp] Uncaught exception GET /api/nbconvert?1733791763710 (221.155.17.253)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733791763710', version='HTTP/1.1', remote_ip='221.155.17.253')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 09:49:24.326 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 09:49:24.327 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 09:49:24.327 ServerApp] 500 GET /api/nbconvert?1733791763710 (d32360df1bf04e038cfede77c3a772c0@221.155.17.253) 62.39ms referer=http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb
[I 2024-12-10 09:49:24.674 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 09:51:24.550 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-10 09:52:45.699 ServerApp] 302 GET / (@175.118.53.87) 0.29ms
[I 2024-12-10 09:52:45.747 JupyterNotebookApp] 302 GET /tree? (@175.118.53.87) 0.37ms
[I 2024-12-10 09:52:52.145 ServerApp] User dd66125f18534f2abdad1e1cfae26b48 logged in.
[I 2024-12-10 09:52:52.145 ServerApp] 302 POST /login?next=%2Ftree%3F (dd66125f18534f2abdad1e1cfae26b48@175.118.53.87) 80.26ms
[I 2024-12-10 09:52:54.906 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[E 2024-12-10 09:52:57.314 ServerApp] Uncaught exception GET /api/nbconvert?1733791977857 (175.118.53.87)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733791977857', version='HTTP/1.1', remote_ip='175.118.53.87')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 09:52:57.314 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 09:52:57.315 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 09:52:57.315 ServerApp] 500 GET /api/nbconvert?1733791977857 (dd66125f18534f2abdad1e1cfae26b48@175.118.53.87) 54.52ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-10 09:52:58.900 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[E 2024-12-10 09:52:59.075 ServerApp] Uncaught exception GET /api/nbconvert?1733791979592 (175.118.53.87)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733791979592', version='HTTP/1.1', remote_ip='175.118.53.87')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 09:52:59.075 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 09:52:59.076 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 09:52:59.076 ServerApp] 500 GET /api/nbconvert?1733791979592 (dd66125f18534f2abdad1e1cfae26b48@175.118.53.87) 56.72ms referer=http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb
[I 2024-12-10 09:52:59.981 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 09:58:28.332 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
24/12/10 09:58:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2024-12-10 10:00:28.437 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-10 10:02:28.580 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 1:>                                                          (0 + 2) / 2][Stage 2:============>                                           (46 + 2) / 200][Stage 2:===================>                                    (68 + 2) / 200][Stage 2:=========================>                              (91 + 2) / 200][Stage 2:==============================>                        (112 + 2) / 200][Stage 2:======================================>                (139 + 2) / 200][Stage 2:============================================>          (163 + 2) / 200][Stage 2:=====================================================> (196 + 2) / 200]                                                                                [Stage 4:=============================>                             (1 + 1) / 2]                                                                                [Stage 14:>                                                         (0 + 2) / 2][Stage 15:==============>                                        (53 + 2) / 200][Stage 15:=======================>                               (86 + 2) / 200][Stage 15:=================================>                    (123 + 2) / 200][Stage 15:===========================================>          (162 + 3) / 200]                                                                                [Stage 16:=============================>                            (1 + 1) / 2][Stage 17:========================>                              (89 + 2) / 200][Stage 17:====================================>                 (134 + 3) / 200][Stage 17:===============================================>      (177 + 2) / 200]                                                                                [Stage 18:>                                                         (0 + 2) / 2][Stage 18:=============================>                            (1 + 1) / 2]                                                                                [Stage 20:>                                                         (0 + 2) / 2][Stage 21:==========================================>           (157 + 3) / 200]                                                                                [Stage 23:==================================>                   (126 + 2) / 200][Stage 23:==============================================>       (174 + 2) / 200]                                                                                [Stage 25:==================================================>   (188 + 2) / 200]                                                                                [Stage 26:>                                                         (0 + 2) / 2][Stage 27:====================================>                 (135 + 2) / 200][Stage 27:==================================================>   (186 + 2) / 200]                                                                                [Stage 30:>                                                         (0 + 2) / 2][Stage 31:================================================>     (179 + 2) / 200]                                                                                24/12/10 10:04:04 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[I 2024-12-10 10:04:28.771 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-10 10:06:29.010 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 32:=============================>                            (1 + 1) / 2][Stage 33:==============================================>       (174 + 2) / 200]                                                                                [I 2024-12-10 10:08:29.196 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 36:>                                                         (0 + 2) / 2][Stage 37:===================================================>  (191 + 2) / 200]                                                                                [I 2024-12-10 10:10:29.555 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 41:=============================>                            (1 + 1) / 2][Stage 42:================================================>     (179 + 2) / 200]                                                                                [I 2024-12-10 10:14:29.988 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 44:>                                                         (0 + 2) / 2][Stage 45:====================================================> (194 + 2) / 200]                                                                                [I 2024-12-10 10:16:30.539 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-10 10:18:30.701 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 46:>                                                         (0 + 2) / 2]                                                                                [Stage 48:>                                                         (0 + 2) / 2][Stage 48:=============================>                            (1 + 1) / 2][Stage 49:================================================>     (180 + 2) / 200]                                                                                [Stage 51:=================================================>    (182 + 2) / 200]                                                                                [I 2024-12-10 10:20:31.703 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 53:>                                                         (0 + 2) / 2][Stage 53:=============================>                            (1 + 1) / 2][Stage 54:===============================================>      (177 + 2) / 200]                                                                                [Stage 56:==================================>                   (129 + 2) / 200][Stage 56:====================================================> (195 + 2) / 200]                                                                                [Stage 58:>                                                         (0 + 2) / 2][Stage 58:=============================>                            (1 + 1) / 2][Stage 59:====================================================> (194 + 2) / 200]                                                                                [Stage 61:=============================================>        (169 + 2) / 200]                                                                                [I 2024-12-10 10:22:32.223 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-10 10:23:05.682 ServerApp] Malformed HTTP message from 61.76.43.89: no colon in header line
[Stage 66:===============================================>      (176 + 2) / 200]                                                                                [I 2024-12-10 10:23:08.653 ServerApp] 302 GET / (@61.76.43.89) 0.29ms
[I 2024-12-10 10:23:08.699 JupyterNotebookApp] 302 GET /tree? (@61.76.43.89) 0.37ms
[I 2024-12-10 10:23:15.067 ServerApp] User 0636b224d94241ebbf2e1d519a4d962a logged in.
[I 2024-12-10 10:23:15.067 ServerApp] 302 POST /login?next=%2Ftree%3F (0636b224d94241ebbf2e1d519a4d962a@61.76.43.89) 65.93ms
[I 2024-12-10 10:23:16.694 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[E 2024-12-10 10:23:18.650 ServerApp] Uncaught exception GET /api/nbconvert?1733793798570 (61.76.43.89)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733793798570', version='HTTP/1.1', remote_ip='61.76.43.89')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 10:23:18.650 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 10:23:18.651 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 10:23:18.651 ServerApp] 500 GET /api/nbconvert?1733793798570 (0636b224d94241ebbf2e1d519a4d962a@61.76.43.89) 56.03ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-10 10:23:19.228 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[E 2024-12-10 10:23:19.325 ServerApp] Uncaught exception GET /api/nbconvert?1733793799210 (61.76.43.89)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733793799210', version='HTTP/1.1', remote_ip='61.76.43.89')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 10:23:19.326 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 10:23:19.326 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 10:23:19.326 ServerApp] 500 GET /api/nbconvert?1733793799210 (0636b224d94241ebbf2e1d519a4d962a@61.76.43.89) 87.47ms referer=http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb
[I 2024-12-10 10:23:19.598 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 10:24:32.565 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 68:>                                                         (0 + 2) / 2]                                                                                [Stage 71:=============================================>        (168 + 2) / 200]                                                                                [Stage 73:=============================>                            (1 + 1) / 2]                                                                                [Stage 78:=============================>                            (1 + 1) / 2]                                                                                [I 2024-12-10 10:26:32.801 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-10 10:28:33.031 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-10 10:29:43.170 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-10 10:30:09.672 ServerApp] 302 GET / (@58.127.198.35) 0.27ms
[I 2024-12-10 10:30:09.703 JupyterNotebookApp] 302 GET /tree? (@58.127.198.35) 0.37ms
[I 2024-12-10 10:30:21.501 ServerApp] User 740a1b23788446a9b3dbe4a5e3863216 logged in.
[I 2024-12-10 10:30:21.502 ServerApp] 302 POST /login?next=%2Ftree%3F (740a1b23788446a9b3dbe4a5e3863216@58.127.198.35) 67.33ms
[I 2024-12-10 10:30:23.001 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[E 2024-12-10 10:30:28.157 ServerApp] Uncaught exception GET /api/nbconvert?1733794228384 (58.127.198.35)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733794228384', version='HTTP/1.1', remote_ip='58.127.198.35')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 10:30:28.158 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 10:30:28.158 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 10:30:28.158 ServerApp] 500 GET /api/nbconvert?1733794228384 (740a1b23788446a9b3dbe4a5e3863216@58.127.198.35) 59.95ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-10 10:30:28.733 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[E 2024-12-10 10:30:28.838 ServerApp] Uncaught exception GET /api/nbconvert?1733794229071 (58.127.198.35)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733794229071', version='HTTP/1.1', remote_ip='58.127.198.35')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 10:30:28.840 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 10:30:28.840 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 10:30:28.840 ServerApp] 500 GET /api/nbconvert?1733794229071 (740a1b23788446a9b3dbe4a5e3863216@58.127.198.35) 62.13ms referer=http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb
[I 2024-12-10 10:30:29.104 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[Stage 83:>                                                         (0 + 2) / 2][Stage 84:=============================================>        (167 + 2) / 200]                                                                                [I 2024-12-10 10:33:43.524 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-10 10:37:02.011 ServerApp] 302 GET / (@222.235.87.13) 0.28ms
[I 2024-12-10 10:37:02.046 JupyterNotebookApp] 302 GET /tree? (@222.235.87.13) 0.35ms
[I 2024-12-10 10:37:45.045 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 85:>                                                         (0 + 2) / 2][Stage 86:=================================================>    (184 + 2) / 200]                                                                                [I 2024-12-10 10:39:45.329 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-10 10:41:07.812 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-10 10:41:17.588 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-10 10:52:59.084 ServerApp] 302 GET / (@114.203.150.38) 0.28ms
[I 2024-12-10 10:52:59.115 JupyterNotebookApp] 302 GET /tree? (@114.203.150.38) 0.36ms
[I 2024-12-10 10:53:13.116 ServerApp] User cea5bd43a10c44ee82476a55702a86ed logged in.
[I 2024-12-10 10:53:13.116 ServerApp] 302 POST /login?next=%2Ftree%3F (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 65.52ms
[I 2024-12-10 10:53:14.907 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[E 2024-12-10 10:53:16.964 ServerApp] Uncaught exception GET /api/nbconvert?1733795596889 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733795596889', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 10:53:16.964 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 10:53:16.965 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 10:53:16.965 ServerApp] 500 GET /api/nbconvert?1733795596889 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 55.48ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-10 10:53:17.613 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[E 2024-12-10 10:53:17.703 ServerApp] Uncaught exception GET /api/nbconvert?1733795597621 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733795597621', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 10:53:17.703 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 10:53:17.704 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 10:53:17.704 ServerApp] 500 GET /api/nbconvert?1733795597621 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 81.30ms referer=http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb
[I 2024-12-10 10:53:18.129 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 11:23:34.163 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-10 11:24:04.646 ServerApp] 302 GET / (@218.38.167.157) 0.46ms
[I 2024-12-10 11:24:04.677 JupyterNotebookApp] 302 GET /tree? (@218.38.167.157) 0.35ms
[I 2024-12-10 11:24:10.249 ServerApp] User 05a3c152954b4fe68e3a363ad6f3ee96 logged in.
[I 2024-12-10 11:24:10.250 ServerApp] 302 POST /login?next=%2Ftree%3F (05a3c152954b4fe68e3a363ad6f3ee96@218.38.167.157) 67.80ms
[I 2024-12-10 11:24:11.660 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[E 2024-12-10 11:24:17.963 ServerApp] Uncaught exception GET /api/nbconvert?1733797457207 (218.38.167.157)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733797457207', version='HTTP/1.1', remote_ip='218.38.167.157')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 11:24:17.963 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 11:24:17.964 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 11:24:17.964 ServerApp] 500 GET /api/nbconvert?1733797457207 (05a3c152954b4fe68e3a363ad6f3ee96@218.38.167.157) 41.38ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-10 11:24:18.877 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[E 2024-12-10 11:24:19.020 ServerApp] Uncaught exception GET /api/nbconvert?1733797458245 (218.38.167.157)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733797458245', version='HTTP/1.1', remote_ip='218.38.167.157')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 11:24:19.020 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 11:24:19.021 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 11:24:19.021 ServerApp] 500 GET /api/nbconvert?1733797458245 (05a3c152954b4fe68e3a363ad6f3ee96@218.38.167.157) 61.06ms referer=http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb
[I 2024-12-10 11:24:19.497 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 11:27:08.202 ServerApp] 302 GET / (@222.235.87.13) 0.39ms
[I 2024-12-10 11:27:08.247 JupyterNotebookApp] 302 GET /tree? (@222.235.87.13) 0.47ms
[I 2024-12-10 11:27:12.443 ServerApp] User a38974ebebcf4458ba9d656cd1b01d61 logged in.
[I 2024-12-10 11:27:12.444 ServerApp] 302 POST /login?next=%2Ftree%3F (a38974ebebcf4458ba9d656cd1b01d61@222.235.87.13) 64.61ms
[I 2024-12-10 11:27:18.599 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[E 2024-12-10 11:27:22.494 ServerApp] Uncaught exception GET /api/nbconvert?1733797642153 (222.235.87.13)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733797642153', version='HTTP/1.1', remote_ip='222.235.87.13')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 11:27:22.495 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 11:27:22.495 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0"
    }
[E 2024-12-10 11:27:22.495 ServerApp] 500 GET /api/nbconvert?1733797642153 (a38974ebebcf4458ba9d656cd1b01d61@222.235.87.13) 53.70ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-10 11:27:23.496 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[E 2024-12-10 11:27:23.663 ServerApp] Uncaught exception GET /api/nbconvert?1733797643292 (222.235.87.13)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733797643292', version='HTTP/1.1', remote_ip='222.235.87.13')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 11:27:23.663 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 11:27:23.664 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0"
    }
[E 2024-12-10 11:27:23.664 ServerApp] 500 GET /api/nbconvert?1733797643292 (a38974ebebcf4458ba9d656cd1b01d61@222.235.87.13) 83.71ms referer=http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb
[I 2024-12-10 11:27:24.234 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 11:42:02.036 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[Stage 2:=========================================>             (152 + 2) / 200]                                                                                [Stage 15:==============================>                       (114 + 2) / 200][Stage 15:=============================================>        (167 + 2) / 200]                                                                                [Stage 17:================================================>     (180 + 2) / 200]                                                                                [Stage 24:>                                                         (0 + 2) / 2][Stage 25:===================================================>  (190 + 2) / 200]                                                                                [Stage 27:===================================================>  (191 + 2) / 200]                                                                                [Stage 32:=============================>                            (1 + 1) / 2][Stage 33:====================================================> (196 + 2) / 200]                                                                                [I 2024-12-10 11:44:03.002 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-10 12:39:06.396 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[E 2024-12-10 12:39:10.740 ServerApp] Uncaught exception GET /api/nbconvert?1733801949952 (221.155.17.253)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733801949952', version='HTTP/1.1', remote_ip='221.155.17.253')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 12:39:10.740 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 12:39:10.741 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 12:39:10.741 ServerApp] 500 GET /api/nbconvert?1733801949952 (d32360df1bf04e038cfede77c3a772c0@221.155.17.253) 55.80ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-10 12:39:11.290 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[E 2024-12-10 12:39:11.389 ServerApp] Uncaught exception GET /api/nbconvert?1733801950588 (221.155.17.253)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733801950588', version='HTTP/1.1', remote_ip='221.155.17.253')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 12:39:11.390 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 12:39:11.390 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 12:39:11.390 ServerApp] 500 GET /api/nbconvert?1733801950588 (d32360df1bf04e038cfede77c3a772c0@221.155.17.253) 69.14ms referer=http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb
[I 2024-12-10 12:39:11.706 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 13:23:31.191 ServerApp] Saving file at /241209_01_sf_fire_calls_소방서콜데이터분석보고서.ipynb
[I 2024-12-10 13:23:44.118 ServerApp] Creating new notebook in 
[I 2024-12-10 13:23:44.573 ServerApp] Saving file at /Untitled.ipynb
[I 2024-12-10 13:23:44.607 ServerApp] Kernel started: 5d420eeb-6a9e-466c-aa22-3423ef2f67a8
[I 2024-12-10 13:23:45.059 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[I 2024-12-10 13:23:49.341 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 13:23:49.449 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[E 2024-12-10 13:23:49.899 ServerApp] Uncaught exception GET /api/nbconvert?1733804629814 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733804629814', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 13:23:49.900 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 13:23:49.900 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/Untitled.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 13:23:49.900 ServerApp] 500 GET /api/nbconvert?1733804629814 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 41.30ms referer=http://13.208.159.5:8906/notebooks/Untitled.ipynb
[I 2024-12-10 13:23:52.010 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[I 2024-12-10 13:26:31.871 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
24/12/10 13:29:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 2024-12-10 13:30:34.067 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 13:30:55.583 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 13:30:55.681 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[E 2024-12-10 13:30:59.265 ServerApp] Uncaught exception GET /api/nbconvert?1733805058421 (218.38.167.157)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733805058421', version='HTTP/1.1', remote_ip='218.38.167.157')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 13:30:59.266 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 13:30:59.266 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 13:30:59.266 ServerApp] 500 GET /api/nbconvert?1733805058421 (05a3c152954b4fe68e3a363ad6f3ee96@218.38.167.157) 43.26ms referer=http://13.208.159.5:8906/tree
[I 2024-12-10 13:31:00.101 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 13:31:00.163 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[E 2024-12-10 13:31:00.276 ServerApp] Uncaught exception GET /api/nbconvert?1733805059423 (218.38.167.157)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733805059423', version='HTTP/1.1', remote_ip='218.38.167.157')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 13:31:00.277 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 13:31:00.277 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_01_SparkSQL.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 13:31:00.277 ServerApp] 500 GET /api/nbconvert?1733805059423 (05a3c152954b4fe68e3a363ad6f3ee96@218.38.167.157) 52.71ms referer=http://13.208.159.5:8906/notebooks/241210_01_SparkSQL.ipynb
[I 2024-12-10 13:31:00.809 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[I 2024-12-10 13:32:34.250 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 13:34:34.872 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[Stage 0:>                                                          (0 + 1) / 2][Stage 0:>                                                          (0 + 2) / 2]                                                                                [I 2024-12-10 13:36:35.087 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 13:38:35.263 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 13:40:26.901 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 13:44:27.084 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 13:46:27.519 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 13:48:27.666 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 13:50:28.157 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 13:52:28.357 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 13:54:28.514 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 13:56:03.669 ServerApp] 302 GET / (@114.203.150.38) 0.84ms
[I 2024-12-10 13:56:04.720 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 13:56:04.792 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[E 2024-12-10 13:56:06.961 ServerApp] Uncaught exception GET /api/nbconvert?1733806566543 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733806566543', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 13:56:06.962 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 13:56:06.963 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 13:56:06.963 ServerApp] 500 GET /api/nbconvert?1733806566543 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 55.90ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-10 13:56:07.856 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 13:56:07.946 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[E 2024-12-10 13:56:07.958 ServerApp] Uncaught exception GET /api/nbconvert?1733806567494 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733806567494', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 13:56:07.958 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 13:56:07.959 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_01_SparkSQL.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 13:56:07.959 ServerApp] 500 GET /api/nbconvert?1733806567494 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 107.43ms referer=http://13.208.159.5:8906/notebooks/241210_01_SparkSQL.ipynb
[I 2024-12-10 13:56:08.288 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[I 2024-12-10 13:56:19.999 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 13:56:20.091 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[E 2024-12-10 13:56:20.102 ServerApp] Uncaught exception GET /api/nbconvert?1733806579655 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733806579655', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 13:56:20.104 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 13:56:20.104 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_01_SparkSQL.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 13:56:20.104 ServerApp] 500 GET /api/nbconvert?1733806579655 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 91.10ms referer=http://13.208.159.5:8906/notebooks/241210_01_SparkSQL.ipynb
[I 2024-12-10 13:56:20.437 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[I 2024-12-10 13:56:28.676 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 13:57:18.007 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 13:57:18.090 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[E 2024-12-10 13:57:18.108 ServerApp] Uncaught exception GET /api/nbconvert?1733806637646 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733806637646', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 13:57:18.108 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 13:57:18.109 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_01_SparkSQL.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 13:57:18.109 ServerApp] 500 GET /api/nbconvert?1733806637646 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 95.71ms referer=http://13.208.159.5:8906/notebooks/241210_01_SparkSQL.ipynb
[I 2024-12-10 13:57:18.466 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[I 2024-12-10 13:58:28.898 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 14:00:07.086 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[E 2024-12-10 14:00:07.163 ServerApp] Uncaught exception GET /api/nbconvert?1733806806726 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733806806726', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 14:00:07.164 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 14:00:07.164 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_01_SparkSQL.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 14:00:07.164 ServerApp] 500 GET /api/nbconvert?1733806806726 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 67.14ms referer=http://13.208.159.5:8906/notebooks/241210_01_SparkSQL.ipynb
[I 2024-12-10 14:00:07.308 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[I 2024-12-10 14:00:07.521 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[I 2024-12-10 14:00:29.092 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 14:00:43.622 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[E 2024-12-10 14:00:43.708 ServerApp] Uncaught exception GET /api/nbconvert?1733806843261 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733806843261', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 14:00:43.708 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 14:00:43.709 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_01_SparkSQL.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 14:00:43.709 ServerApp] 500 GET /api/nbconvert?1733806843261 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 75.44ms referer=http://13.208.159.5:8906/notebooks/241210_01_SparkSQL.ipynb
[I 2024-12-10 14:00:43.713 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[I 2024-12-10 14:00:44.005 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[I 2024-12-10 14:06:29.256 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 14:25:11.327 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 14:27:11.537 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 14:29:11.779 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 14:31:11.923 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 14:33:12.101 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 14:35:12.455 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[Stage 26:===============================>                       (57 + 1) / 100][Stage 26:========================================>              (74 + 1) / 100][Stage 26:===================================================>   (94 + 1) / 100]                                                                                [Stage 29:==============================================>         (62 + 1) / 75]                                                                                [I 2024-12-10 14:37:12.603 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[Stage 41:============================================>          (80 + 1) / 100]                                                                                [I 2024-12-10 14:41:12.812 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[Stage 56:==================================================>    (92 + 1) / 100]                                                                                [I 2024-12-10 14:43:12.953 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 14:47:13.186 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 14:49:06.092 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 14:49:06.206 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[I 2024-12-10 14:49:14.000 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 14:49:37.403 ServerApp] Creating new notebook in 
[E 2024-12-10 14:49:37.582 ServerApp] Uncaught exception GET /api/nbconvert?1733809777524 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733809777524', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 14:49:37.582 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 14:49:37.582 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 14:49:37.582 ServerApp] 500 GET /api/nbconvert?1733809777524 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 45.63ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-10 14:49:37.744 ServerApp] Saving file at /Untitled.ipynb
[I 2024-12-10 14:49:37.848 ServerApp] Kernel started: 841381ff-b181-4372-b880-93864c771d22
[I 2024-12-10 14:49:38.453 ServerApp] Connecting to kernel 841381ff-b181-4372-b880-93864c771d22.
[I 2024-12-10 14:49:40.950 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 14:49:41.035 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[I 2024-12-10 14:49:41.113 ServerApp] Connecting to kernel 841381ff-b181-4372-b880-93864c771d22.
[E 2024-12-10 14:49:41.437 ServerApp] Uncaught exception GET /api/nbconvert?1733809781380 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733809781380', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 14:49:41.437 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 14:49:41.438 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/Untitled.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 14:49:41.438 ServerApp] 500 GET /api/nbconvert?1733809781380 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 40.96ms referer=http://13.208.159.5:8906/notebooks/Untitled.ipynb
[I 2024-12-10 14:49:42.264 ServerApp] Connecting to kernel 841381ff-b181-4372-b880-93864c771d22.
[I 2024-12-10 14:51:14.157 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 14:51:18.389 ServerApp] Saving file at /241210_01_SparkSQL.ipynb
[I 2024-12-10 14:52:39.841 ServerApp] Saving file at /241210_02_SparkSQL_실행계획.ipynb
24/12/10 14:54:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2024-12-10 14:54:39.993 ServerApp] Saving file at /241210_02_SparkSQL_실행계획.ipynb
[I 2024-12-10 15:00:40.160 ServerApp] Saving file at /241210_02_SparkSQL_실행계획.ipynb
[I 2024-12-10 15:02:40.309 ServerApp] Saving file at /241210_02_SparkSQL_실행계획.ipynb
[I 2024-12-10 15:04:08.570 ServerApp] Starting buffering for 5d420eeb-6a9e-466c-aa22-3423ef2f67a8:8576d555-9882-4bdd-a1fc-0720e36d05f4
[I 2024-12-10 15:04:40.438 ServerApp] Saving file at /241210_02_SparkSQL_실행계획.ipynb
[I 2024-12-10 15:08:40.582 ServerApp] Saving file at /241210_02_SparkSQL_실행계획.ipynb
[I 2024-12-10 15:16:40.737 ServerApp] Saving file at /241210_02_SparkSQL_실행계획.ipynb
[I 2024-12-10 15:18:40.870 ServerApp] Saving file at /241210_02_SparkSQL_실행계획.ipynb
[I 2024-12-10 15:20:41.035 ServerApp] Saving file at /241210_02_SparkSQL_실행계획.ipynb
[I 2024-12-10 15:24:05.673 ServerApp] Saving file at /241210_02_SparkSQL_실행계획.ipynb
[I 2024-12-10 15:41:34.274 ServerApp] Saving file at /241210_02_SparkSQL_실행계획.ipynb
[I 2024-12-10 15:41:49.935 ServerApp] Creating new directory in /data
[I 2024-12-10 15:48:55.944 ServerApp] Creating new notebook in 
[I 2024-12-10 15:48:56.715 ServerApp] Saving file at /Untitled.ipynb
[I 2024-12-10 15:48:56.763 ServerApp] Kernel started: 263dc787-193f-4087-be85-925bc0f14c11
[I 2024-12-10 15:48:57.212 ServerApp] Connecting to kernel 263dc787-193f-4087-be85-925bc0f14c11.
[I 2024-12-10 15:49:02.077 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 15:49:02.173 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[I 2024-12-10 15:49:02.267 ServerApp] Connecting to kernel 841381ff-b181-4372-b880-93864c771d22.
[I 2024-12-10 15:49:02.364 ServerApp] Connecting to kernel 263dc787-193f-4087-be85-925bc0f14c11.
[E 2024-12-10 15:49:02.755 ServerApp] Uncaught exception GET /api/nbconvert?1733813342698 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733813342698', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-10 15:49:02.757 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-10 15:49:02.757 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/Untitled.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-10 15:49:02.757 ServerApp] 500 GET /api/nbconvert?1733813342698 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 42.99ms referer=http://13.208.159.5:8906/notebooks/Untitled.ipynb
[I 2024-12-10 15:49:04.195 ServerApp] Starting buffering for 5d420eeb-6a9e-466c-aa22-3423ef2f67a8:2a2fe067-4b2a-423e-845f-fdea9ddd780d
[I 2024-12-10 15:49:04.483 ServerApp] Connecting to kernel 263dc787-193f-4087-be85-925bc0f14c11.
[I 2024-12-10 15:51:20.201 ServerApp] Saving file at /24121003_yellowtaxi_trip_count.ipynb
24/12/10 15:53:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
24/12/10 15:53:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[I 2024-12-10 15:53:20.479 ServerApp] Saving file at /24121003_yellowtaxi_trip_count.ipynb
[I 2024-12-10 15:55:20.966 ServerApp] Saving file at /24121003_yellowtaxi_trip_count.ipynb
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                         (0 + 2) / 11][I 2024-12-10 15:57:21.456 ServerApp] Saving file at /24121003_yellowtaxi_trip_count.ipynb
[Stage 1:==========>                                               (2 + 2) / 11][Stage 1:=====================>                                    (4 + 2) / 11][Stage 1:==========================>                               (5 + 2) / 11][Stage 1:===============================>                          (6 + 2) / 11][Stage 1:====================================>                     (7 + 2) / 11][Stage 1:==========================================>               (8 + 2) / 11][Stage 1:===============================================>          (9 + 2) / 11][Stage 1:===================================================>     (10 + 1) / 11]                                                                                [I 2024-12-10 15:59:21.640 ServerApp] Saving file at /24121003_yellowtaxi_trip_count.ipynb
[I 2024-12-10 16:01:21.816 ServerApp] Saving file at /24121003_yellowtaxi_trip_count.ipynb
[I 2024-12-10 16:07:21.998 ServerApp] Saving file at /24121003_yellowtaxi_trip_count.ipynb
[Stage 5:>                                                         (0 + 2) / 11][Stage 5:==========>                                               (2 + 2) / 11][Stage 5:=====================>                                    (4 + 2) / 11][Stage 5:===============================>                          (6 + 2) / 11][Stage 5:====================================>                     (7 + 2) / 11][Stage 5:==========================================>               (8 + 2) / 11][Stage 5:===============================================>          (9 + 2) / 11][Stage 5:===================================================>     (10 + 1) / 11]                                                                                [I 2024-12-10 16:15:22.249 ServerApp] Saving file at /24121003_yellowtaxi_trip_count.ipynb
[I 2024-12-10 16:19:22.411 ServerApp] Saving file at /24121003_yellowtaxi_trip_count.ipynb
[Stage 12:>                                                         (0 + 1) / 1]                                                                                [Stage 13:>                                                         (0 + 2) / 2][Stage 13:=============================>                            (1 + 1) / 2]                                                                                [Stage 14:>                                                         (0 + 2) / 2][Stage 14:=============================>                            (1 + 1) / 2]                                                                                [Stage 16:>                                                        (0 + 2) / 11][I 2024-12-10 16:21:22.579 ServerApp] Saving file at /24121003_yellowtaxi_trip_count.ipynb
[Stage 16:=====>                                                   (1 + 2) / 11][Stage 16:==========>                                              (2 + 2) / 11][Stage 16:===============>                                         (3 + 2) / 11][Stage 16:====================>                                    (4 + 2) / 11][Stage 16:=========================>                               (5 + 2) / 11][Stage 16:===============================>                         (6 + 2) / 11][Stage 16:====================================>                    (7 + 2) / 11][Stage 16:=========================================>               (8 + 2) / 11][Stage 16:==============================================>          (9 + 2) / 11][Stage 16:==================================================>     (10 + 1) / 11]                                                                                [I 2024-12-10 16:25:22.781 ServerApp] Saving file at /24121003_yellowtaxi_trip_count.ipynb
[I 2024-12-10 16:49:23.070 ServerApp] Saving file at /24121003_yellowtaxi_trip_count.ipynb
[I 2024-12-10 16:51:23.379 ServerApp] Saving file at /24121003_yellowtaxi_trip_count.ipynb
[Stage 21:>                                                        (0 + 2) / 11][Stage 21:==========>                                              (2 + 2) / 11][Stage 21:====================>                                    (4 + 2) / 11][Stage 21:=========================>                               (5 + 2) / 11][Stage 21:===============================>                         (6 + 2) / 11][Stage 21:====================================>                    (7 + 2) / 11][Stage 21:=========================================>               (8 + 2) / 11][Stage 21:==============================================>          (9 + 2) / 11][Stage 21:==================================================>     (10 + 1) / 11][Stage 22:======================>                                (80 + 2) / 200][Stage 22:==============================>                       (112 + 2) / 200][Stage 22:======================================>               (144 + 3) / 200][Stage 22:=================================================>    (185 + 2) / 200]                                                                                [I 2024-12-10 16:53:23.606 ServerApp] Saving file at /24121003_yellowtaxi_trip_count.ipynb
[I 2024-12-10 17:27:59.291 ServerApp] Saving file at /24121003_yellowtaxi_trip_count.ipynb
[I 2024-12-10 17:28:29.092 ServerApp] Saving file at /24121003_yellowtaxi_trip_count.ipynb
[E 2024-12-10 17:57:37.024 ServerApp] Uncaught exception GET /lab/api/settings?1733821056044 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/lab/api/settings?1733821056044', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
    tornado.iostream.StreamClosedError: Stream is closed
[I 2024-12-10 18:07:21.805 ServerApp] Starting buffering for 263dc787-193f-4087-be85-925bc0f14c11:afceb7fc-59b6-4471-ac28-8a685bd7c2d7
[I 2024-12-10 18:07:21.806 ServerApp] Starting buffering for 841381ff-b181-4372-b880-93864c771d22:a95ba98b-452d-4e7c-9fee-108fed2f185b
[I 2024-12-10 18:07:23.982 ServerApp] Connecting to kernel 7e98d41c-3bad-4316-9d9b-174390ef482f.
[I 2024-12-10 18:07:24.151 ServerApp] Connecting to kernel 5d420eeb-6a9e-466c-aa22-3423ef2f67a8.
[I 2024-12-10 18:07:24.230 ServerApp] Connecting to kernel 841381ff-b181-4372-b880-93864c771d22.
[I 2024-12-10 18:07:24.312 ServerApp] Connecting to kernel 263dc787-193f-4087-be85-925bc0f14c11.
[I 2024-12-10 18:07:24.368 ServerApp] Starting buffering for 5d420eeb-6a9e-466c-aa22-3423ef2f67a8:02bad635-65d8-4337-97f7-d35301076761
[I 2024-12-10 18:07:24.501 ServerApp] Starting buffering for 841381ff-b181-4372-b880-93864c771d22:1448017f-faa6-4b38-aa5b-9cea5f38703e
[I 2024-12-10 18:07:24.525 ServerApp] Starting buffering for 263dc787-193f-4087-be85-925bc0f14c11:6cabda78-7560-4fcd-b2b0-602806fed1e2
[C 2024-12-10 19:00:01.624 ServerApp] received signal 15, stopping
[I 2024-12-10 19:00:01.625 ServerApp] Shutting down 6 extensions
[I 2024-12-10 19:00:01.625 ServerApp] Shutting down 4 kernels
[I 2024-12-10 19:00:01.704 ServerApp] Kernel shutdown: 841381ff-b181-4372-b880-93864c771d22
[I 2024-12-10 19:00:01.711 ServerApp] Kernel shutdown: 7e98d41c-3bad-4316-9d9b-174390ef482f
[I 2024-12-10 19:00:01.739 ServerApp] Kernel shutdown: 263dc787-193f-4087-be85-925bc0f14c11
[I 2024-12-10 19:00:01.742 ServerApp] Kernel shutdown: 5d420eeb-6a9e-466c-aa22-3423ef2f67a8
[I 2024-12-11 09:00:04.719 ServerApp] jupyter_lsp | extension was successfully linked.
[I 2024-12-11 09:00:04.724 ServerApp] jupyter_server_terminals | extension was successfully linked.
[I 2024-12-11 09:00:04.728 ServerApp] jupyterlab | extension was successfully linked.
[W 2024-12-11 09:00:04.731 JupyterNotebookApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2024-12-11 09:00:04.733 ServerApp] ServerApp.password config is deprecated in 2.0. Use PasswordIdentityProvider.hashed_password.
[I 2024-12-11 09:00:04.733 ServerApp] notebook | extension was successfully linked.
[W 2024-12-11 09:00:05.163 ServerApp] A `_jupyter_server_extension_points` function was not found in jupyter_nbextensions_configurator. Instead, a `_jupyter_server_extension_paths` function was found and will be used for now. This function name will be deprecated in future releases of Jupyter Server.
[I 2024-12-11 09:00:05.164 ServerApp] jupyter_nbextensions_configurator | extension was found and enabled by notebook_shim. Consider moving the extension to Jupyter Server's extension paths.
[I 2024-12-11 09:00:05.164 ServerApp] jupyter_nbextensions_configurator | extension was successfully linked.
[I 2024-12-11 09:00:05.164 ServerApp] notebook_shim | extension was successfully linked.
[I 2024-12-11 09:00:05.238 ServerApp] notebook_shim | extension was successfully loaded.
[I 2024-12-11 09:00:05.241 ServerApp] jupyter_lsp | extension was successfully loaded.
[I 2024-12-11 09:00:05.241 ServerApp] [jupyter_nbextensions_configurator] enabled 0.6.4
[I 2024-12-11 09:00:05.241 ServerApp] jupyter_nbextensions_configurator | extension was successfully loaded.
[I 2024-12-11 09:00:05.242 ServerApp] jupyter_server_terminals | extension was successfully loaded.
[I 2024-12-11 09:00:05.250 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyterlab
[I 2024-12-11 09:00:05.250 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/envs/spark_start/share/jupyter/lab
[I 2024-12-11 09:00:05.251 LabApp] Extension Manager is 'pypi'.
[I 2024-12-11 09:00:05.318 ServerApp] jupyterlab | extension was successfully loaded.
[I 2024-12-11 09:00:05.323 ServerApp] notebook | extension was successfully loaded.
[I 2024-12-11 09:00:05.323 ServerApp] Serving notebooks from local directory: /home/lab06/src/DA-learning-course/Spark
[I 2024-12-11 09:00:05.323 ServerApp] Jupyter Server 2.14.2 is running at:
[I 2024-12-11 09:00:05.323 ServerApp] http://ip-172-31-13-94:8906/tree
[I 2024-12-11 09:00:05.323 ServerApp]     http://127.0.0.1:8906/tree
[I 2024-12-11 09:00:05.323 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 2024-12-11 09:00:05.340 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server
[I 2024-12-11 09:00:51.464 ServerApp] 302 GET / (@211.231.29.166) 0.48ms
[W 2024-12-11 09:01:44.114 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f?1733875304053 (61.76.43.89): Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f
[W 2024-12-11 09:01:44.114 ServerApp] wrote error: 'Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/handlers.py", line 75, in get
        model = await ensure_async(km.kernel_model(kernel_id))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 506, in kernel_model
        self._check_kernel_id(kernel_id)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 537, in _check_kernel_id
        raise web.HTTPError(404, "Kernel does not exist: %s" % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f)
[W 2024-12-11 09:01:44.118 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f?1733875304053 (0636b224d94241ebbf2e1d519a4d962a@61.76.43.89) 5.32ms referer=http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb
[W 2024-12-11 09:01:45.120 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f/channels?session_id=b9873305-f745-4681-ad8c-11050eba1166 (61.76.43.89): Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f
[W 2024-12-11 09:01:45.138 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f/channels?session_id=b9873305-f745-4681-ad8c-11050eba1166 (0636b224d94241ebbf2e1d519a4d962a@61.76.43.89) 18.33ms referer=None
[W 2024-12-11 09:01:45.182 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f?1733875305158 (61.76.43.89): Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f
[W 2024-12-11 09:01:45.182 ServerApp] wrote error: 'Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/handlers.py", line 75, in get
        model = await ensure_async(km.kernel_model(kernel_id))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 506, in kernel_model
        self._check_kernel_id(kernel_id)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 537, in _check_kernel_id
        raise web.HTTPError(404, "Kernel does not exist: %s" % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f)
[W 2024-12-11 09:01:45.182 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f?1733875305158 (0636b224d94241ebbf2e1d519a4d962a@61.76.43.89) 1.27ms referer=http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb
[W 2024-12-11 09:01:48.116 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f/channels?session_id=b9873305-f745-4681-ad8c-11050eba1166 (61.76.43.89): Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f
[W 2024-12-11 09:01:48.117 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f/channels?session_id=b9873305-f745-4681-ad8c-11050eba1166 (0636b224d94241ebbf2e1d519a4d962a@61.76.43.89) 1.30ms referer=None
[W 2024-12-11 09:01:48.190 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f?1733875308129 (61.76.43.89): Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f
[W 2024-12-11 09:01:48.190 ServerApp] wrote error: 'Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/handlers.py", line 75, in get
        model = await ensure_async(km.kernel_model(kernel_id))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 506, in kernel_model
        self._check_kernel_id(kernel_id)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 537, in _check_kernel_id
        raise web.HTTPError(404, "Kernel does not exist: %s" % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f)
[W 2024-12-11 09:01:48.190 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f?1733875308129 (0636b224d94241ebbf2e1d519a4d962a@61.76.43.89) 0.92ms referer=http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb
[W 2024-12-11 09:01:49.120 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f/channels?session_id=b9873305-f745-4681-ad8c-11050eba1166 (61.76.43.89): Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f
[W 2024-12-11 09:01:49.121 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f/channels?session_id=b9873305-f745-4681-ad8c-11050eba1166 (0636b224d94241ebbf2e1d519a4d962a@61.76.43.89) 2.03ms referer=None
[W 2024-12-11 09:01:49.159 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f?1733875309134 (61.76.43.89): Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f
[W 2024-12-11 09:01:49.159 ServerApp] wrote error: 'Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/handlers.py", line 75, in get
        model = await ensure_async(km.kernel_model(kernel_id))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 506, in kernel_model
        self._check_kernel_id(kernel_id)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 537, in _check_kernel_id
        raise web.HTTPError(404, "Kernel does not exist: %s" % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f)
[W 2024-12-11 09:01:49.160 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f?1733875309134 (0636b224d94241ebbf2e1d519a4d962a@61.76.43.89) 0.95ms referer=http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb
[W 2024-12-11 09:01:52.117 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f/channels?session_id=b9873305-f745-4681-ad8c-11050eba1166 (61.76.43.89): Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f
[W 2024-12-11 09:01:52.118 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f/channels?session_id=b9873305-f745-4681-ad8c-11050eba1166 (0636b224d94241ebbf2e1d519a4d962a@61.76.43.89) 1.21ms referer=None
[W 2024-12-11 09:01:52.157 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f?1733875312130 (61.76.43.89): Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f
[W 2024-12-11 09:01:52.157 ServerApp] wrote error: 'Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/handlers.py", line 75, in get
        model = await ensure_async(km.kernel_model(kernel_id))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 506, in kernel_model
        self._check_kernel_id(kernel_id)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 537, in _check_kernel_id
        raise web.HTTPError(404, "Kernel does not exist: %s" % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f)
[W 2024-12-11 09:01:52.157 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f?1733875312130 (0636b224d94241ebbf2e1d519a4d962a@61.76.43.89) 0.89ms referer=http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb
[W 2024-12-11 09:02:09.113 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f/channels?session_id=b9873305-f745-4681-ad8c-11050eba1166 (61.76.43.89): Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f
[W 2024-12-11 09:02:09.114 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f/channels?session_id=b9873305-f745-4681-ad8c-11050eba1166 (0636b224d94241ebbf2e1d519a4d962a@61.76.43.89) 1.25ms referer=None
[W 2024-12-11 09:02:09.191 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f?1733875329127 (61.76.43.89): Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f
[W 2024-12-11 09:02:09.192 ServerApp] wrote error: 'Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/handlers.py", line 75, in get
        model = await ensure_async(km.kernel_model(kernel_id))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 506, in kernel_model
        self._check_kernel_id(kernel_id)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 537, in _check_kernel_id
        raise web.HTTPError(404, "Kernel does not exist: %s" % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f)
[W 2024-12-11 09:02:09.192 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f?1733875329127 (0636b224d94241ebbf2e1d519a4d962a@61.76.43.89) 0.96ms referer=http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb
[W 2024-12-11 09:02:12.123 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f/channels?session_id=b9873305-f745-4681-ad8c-11050eba1166 (61.76.43.89): Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f
[W 2024-12-11 09:02:12.124 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f/channels?session_id=b9873305-f745-4681-ad8c-11050eba1166 (0636b224d94241ebbf2e1d519a4d962a@61.76.43.89) 1.21ms referer=None
[W 2024-12-11 09:02:12.171 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f?1733875332144 (61.76.43.89): Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f
[W 2024-12-11 09:02:12.172 ServerApp] wrote error: 'Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/handlers.py", line 75, in get
        model = await ensure_async(km.kernel_model(kernel_id))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 506, in kernel_model
        self._check_kernel_id(kernel_id)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/kernels/kernelmanager.py", line 537, in _check_kernel_id
        raise web.HTTPError(404, "Kernel does not exist: %s" % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: 7e98d41c-3bad-4316-9d9b-174390ef482f)
[W 2024-12-11 09:02:12.172 ServerApp] 404 GET /api/kernels/7e98d41c-3bad-4316-9d9b-174390ef482f?1733875332144 (0636b224d94241ebbf2e1d519a4d962a@61.76.43.89) 0.91ms referer=http://13.208.159.5:8906/notebooks/241209_01_sf_fire_calls_%EC%86%8C%EB%B0%A9%EC%84%9C%EC%BD%9C%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C.ipynb
[I 2024-12-11 09:38:58.807 ServerApp] Creating new notebook in 
[E 2024-12-11 09:38:59.364 ServerApp] Uncaught exception GET /api/nbconvert?1733877539062 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733877539062', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-11 09:38:59.370 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-11 09:38:59.370 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-11 09:38:59.370 ServerApp] 500 GET /api/nbconvert?1733877539062 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 283.94ms referer=http://13.208.159.5:8906/tree
[I 2024-12-11 09:38:59.430 ServerApp] Saving file at /Untitled.ipynb
[I 2024-12-11 09:38:59.522 ServerApp] Kernel started: f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31
[I 2024-12-11 09:39:00.055 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[I 2024-12-11 09:39:00.159 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[I 2024-12-11 09:39:02.745 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[E 2024-12-11 09:39:03.078 ServerApp] Uncaught exception GET /api/nbconvert?1733877543023 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733877543023', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-11 09:39:03.079 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-11 09:39:03.079 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/Untitled.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-11 09:39:03.079 ServerApp] 500 GET /api/nbconvert?1733877543023 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 43.64ms referer=http://13.208.159.5:8906/notebooks/Untitled.ipynb
[I 2024-12-11 09:39:04.496 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[I 2024-12-11 09:41:41.326 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
24/12/11 10:28:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 2024-12-11 10:30:19.208 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 10:32:20.290 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 10:34:21.243 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2024-12-11 10:36:21.417 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 10:44:22.270 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 10:48:23.264 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 10:50:24.255 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 10:52:24.415 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 10:54:24.725 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 10:58:26.258 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 11:02:26.451 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[Stage 19:==========================================>            (77 + 2) / 100]                                                                                [I 2024-12-11 11:06:26.681 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 11:31:01.284 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 11:47:00.563 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 11:49:00.763 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 11:53:00.944 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 11:55:01.096 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 11:57:01.236 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 11:59:02.436 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 11:59:04.684 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[I 2024-12-11 12:03:03.227 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 12:05:03.867 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 13:31:33.473 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 13:33:34.458 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 13:39:37.204 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 13:41:37.564 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 13:43:37.825 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[Stage 68:==============================================>        (84 + 2) / 100]                                                                                [I 2024-12-11 13:45:38.039 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[Stage 83:====================================================>  (96 + 2) / 100]                                                                                [I 2024-12-11 13:47:38.252 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 13:49:38.570 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 13:53:38.772 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[Stage 128:==================================>                   (63 + 3) / 100][Stage 128:=================================================>    (92 + 2) / 100]                                                                                [Stage 131:=================================================>     (68 + 2) / 75]                                                                                [I 2024-12-11 14:01:38.960 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[Stage 143:====================================>                 (68 + 2) / 100]                                                                                [I 2024-12-11 14:05:39.158 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 14:09:39.357 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 14:11:39.598 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 14:15:39.818 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 14:33:40.037 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 14:37:40.212 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[Stage 154:==========================================>          (162 + 2) / 200]                                                                                [I 2024-12-11 14:39:40.402 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 14:41:33.389 ServerApp] 302 GET / (@114.203.150.38) 0.43ms
[I 2024-12-11 14:41:34.794 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[E 2024-12-11 14:41:36.644 ServerApp] Uncaught exception GET /api/nbconvert?1733895696380 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733895696380', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-11 14:41:36.645 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-11 14:41:36.646 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-11 14:41:36.646 ServerApp] 500 GET /api/nbconvert?1733895696380 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 58.99ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-11 14:41:37.494 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[E 2024-12-11 14:41:37.589 ServerApp] Uncaught exception GET /api/nbconvert?1733895697293 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733895697293', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-11 14:41:37.589 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-11 14:41:37.590 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241211_01_SparkSQL_SQLtest_books.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-11 14:41:37.590 ServerApp] 500 GET /api/nbconvert?1733895697293 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 93.89ms referer=http://13.208.159.5:8906/notebooks/241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 14:41:37.923 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[I 2024-12-11 14:48:23.273 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[E 2024-12-11 14:48:23.378 ServerApp] Uncaught exception GET /api/nbconvert?1733896103068 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733896103068', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-11 14:48:23.378 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-11 14:48:23.380 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241211_01_SparkSQL_SQLtest_books.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-11 14:48:23.380 ServerApp] 500 GET /api/nbconvert?1733896103068 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 89.62ms referer=http://13.208.159.5:8906/notebooks/241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 14:48:24.271 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[E 2024-12-11 14:48:24.363 ServerApp] Uncaught exception GET /api/nbconvert?1733896104064 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733896104064', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-11 14:48:24.363 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-11 14:48:24.363 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241211_01_SparkSQL_SQLtest_books.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-11 14:48:24.364 ServerApp] 500 GET /api/nbconvert?1733896104064 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 80.38ms referer=http://13.208.159.5:8906/notebooks/241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 14:48:24.727 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[Stage 157:========================================>            (154 + 2) / 200][Stage 157:====================================================>(198 + 2) / 200]                                                                                [I 2024-12-11 14:49:40.612 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[Stage 160:======================>                               (83 + 2) / 200][Stage 160:================================>                    (121 + 2) / 200][Stage 160:=========================================>           (158 + 2) / 200][Stage 160:==================================================>  (191 + 2) / 200][Stage 161:=======================================>             (149 + 2) / 200][Stage 161:===================================================> (194 + 2) / 200]                                                                                [I 2024-12-11 14:51:40.810 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 14:52:21.856 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[E 2024-12-11 14:52:21.921 ServerApp] Uncaught exception GET /api/nbconvert?1733896341616 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733896341616', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-11 14:52:21.921 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-11 14:52:21.922 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241211_01_SparkSQL_SQLtest_books.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-11 14:52:21.922 ServerApp] 500 GET /api/nbconvert?1733896341616 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 74.20ms referer=http://13.208.159.5:8906/notebooks/241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 14:52:22.280 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[Stage 164:================================>                    (122 + 2) / 200][Stage 164:=========================================>           (158 + 2) / 200][Stage 164:==================================================>  (192 + 2) / 200][Stage 165:=====================================>               (143 + 2) / 200]                                                                                [I 2024-12-11 14:53:41.031 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 14:55:41.259 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 14:57:41.468 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 14:59:41.883 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[Stage 171:===================================================> (196 + 2) / 200]                                                                                [Stage 173:===========================================>         (164 + 2) / 200]                                                                                [Stage 177:===========================>                         (104 + 2) / 200][Stage 177:====================================>                (139 + 2) / 200][Stage 177:=============================================>       (172 + 2) / 200][Stage 178:==============================================>      (177 + 3) / 200]                                                                                [Stage 182:===============================>                     (119 + 2) / 200][Stage 182:================================================>    (182 + 2) / 200]                                                                                [I 2024-12-11 15:01:42.065 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 15:10:07.392 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[E 2024-12-11 15:10:07.631 ServerApp] Uncaught exception GET /api/nbconvert?1733897407123 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733897407123', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-11 15:10:07.632 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-11 15:10:07.633 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241211_01_SparkSQL_SQLtest_books.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-11 15:10:07.633 ServerApp] 500 GET /api/nbconvert?1733897407123 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 93.06ms referer=http://13.208.159.5:8906/notebooks/241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 15:10:07.829 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[I 2024-12-11 15:24:57.551 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[I 2024-12-11 15:25:29.136 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[I 2024-12-11 15:26:22.494 ServerApp] Saving file at /241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 15:27:06.658 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[I 2024-12-11 15:27:44.512 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[I 2024-12-11 15:29:20.215 ServerApp] Creating new notebook in 
[I 2024-12-11 15:29:20.978 ServerApp] Saving file at /Untitled.ipynb
[I 2024-12-11 15:29:21.014 ServerApp] Kernel started: 3af5d36e-9e9c-468b-ad30-349b60bd5154
[I 2024-12-11 15:29:21.544 ServerApp] Connecting to kernel 3af5d36e-9e9c-468b-ad30-349b60bd5154.
[I 2024-12-11 15:29:27.260 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[I 2024-12-11 15:29:27.371 ServerApp] Connecting to kernel 3af5d36e-9e9c-468b-ad30-349b60bd5154.
[E 2024-12-11 15:29:28.145 ServerApp] Uncaught exception GET /api/nbconvert?1733898568132 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733898568132', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-11 15:29:28.146 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-11 15:29:28.146 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/Untitled.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-11 15:29:28.147 ServerApp] 500 GET /api/nbconvert?1733898568132 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 43.20ms referer=http://13.208.159.5:8906/notebooks/Untitled.ipynb
[I 2024-12-11 15:29:30.279 ServerApp] Connecting to kernel 3af5d36e-9e9c-468b-ad30-349b60bd5154.
[I 2024-12-11 15:31:29.219 ServerApp] Saving file at /Untitled.ipynb
[I 2024-12-11 15:33:35.035 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[I 2024-12-11 15:33:35.257 ServerApp] Connecting to kernel 3af5d36e-9e9c-468b-ad30-349b60bd5154.
[E 2024-12-11 15:33:39.765 ServerApp] Uncaught exception GET /api/nbconvert?1733898819491 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733898819491', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-11 15:33:39.765 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-11 15:33:39.766 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-11 15:33:39.766 ServerApp] 500 GET /api/nbconvert?1733898819491 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 54.62ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-11 15:33:40.356 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[I 2024-12-11 15:33:40.570 ServerApp] Connecting to kernel 3af5d36e-9e9c-468b-ad30-349b60bd5154.
[E 2024-12-11 15:33:40.584 ServerApp] Uncaught exception GET /api/nbconvert?1733898820134 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733898820134', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-11 15:33:40.584 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-11 15:33:40.585 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/Untitled.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-11 15:33:40.585 ServerApp] 500 GET /api/nbconvert?1733898820134 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 81.61ms referer=http://13.208.159.5:8906/notebooks/Untitled.ipynb
[I 2024-12-11 15:33:40.712 ServerApp] Connecting to kernel 3af5d36e-9e9c-468b-ad30-349b60bd5154.
[I 2024-12-11 15:37:30.269 ServerApp] Saving file at /Untitled.ipynb
24/12/11 15:37:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 2) / 7][Stage 1:========>                                                  (1 + 2) / 7][Stage 1:================>                                          (2 + 2) / 7][Stage 1:=========================>                                 (3 + 2) / 7][Stage 1:=================================>                         (4 + 2) / 7][Stage 1:==================================================>        (6 + 1) / 7]                                                                                [I 2024-12-11 15:39:30.503 ServerApp] Saving file at /Untitled.ipynb
[Stage 5:>                                                          (0 + 2) / 7][Stage 5:================>                                          (2 + 2) / 7][Stage 5:=================================>                         (4 + 2) / 7][Stage 5:==================================================>        (6 + 1) / 7]                                                                                [Stage 12:=======================================>               (72 + 2) / 100]                                                                                [Stage 15:>                                                         (0 + 2) / 7][Stage 15:================>                                         (2 + 2) / 7][Stage 15:========================>                                 (3 + 2) / 7][Stage 15:=================================>                        (4 + 2) / 7][Stage 15:=================================================>        (6 + 1) / 7]                                                                                [I 2024-12-11 15:41:30.659 ServerApp] Saving file at /Untitled.ipynb
[I 2024-12-11 15:43:30.834 ServerApp] Saving file at /Untitled.ipynb
[I 2024-12-11 15:44:47.764 ServerApp] Saving file at /Untitled.ipynb
[I 2024-12-11 15:46:47.954 ServerApp] Saving file at /Untitled.ipynb
[I 2024-12-11 15:47:48.982 ServerApp] Saving file at /Untitled.ipynb
[I 2024-12-11 16:05:33.981 ServerApp] Saving file at /241211_02_SparkSQL_서브쿼리성능비교.ipynb
[I 2024-12-11 16:08:34.675 ServerApp] Creating new notebook in 
[I 2024-12-11 16:08:34.980 ServerApp] Saving file at /Untitled.ipynb
[I 2024-12-11 16:08:35.048 ServerApp] Kernel started: 71216185-4fc5-4e7d-98e1-c54b69c6910c
[I 2024-12-11 16:08:35.496 ServerApp] Connecting to kernel 71216185-4fc5-4e7d-98e1-c54b69c6910c.
[I 2024-12-11 16:08:38.810 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[I 2024-12-11 16:08:38.898 ServerApp] Connecting to kernel 3af5d36e-9e9c-468b-ad30-349b60bd5154.
[I 2024-12-11 16:08:38.977 ServerApp] Connecting to kernel 71216185-4fc5-4e7d-98e1-c54b69c6910c.
[E 2024-12-11 16:08:39.042 ServerApp] Uncaught exception GET /api/nbconvert?1733900919027 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733900919027', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-11 16:08:39.043 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-11 16:08:39.044 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/Untitled.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-11 16:08:39.044 ServerApp] 500 GET /api/nbconvert?1733900919027 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 56.18ms referer=http://13.208.159.5:8906/notebooks/Untitled.ipynb
[I 2024-12-11 16:08:40.207 ServerApp] Connecting to kernel 71216185-4fc5-4e7d-98e1-c54b69c6910c.
[I 2024-12-11 16:09:57.541 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[E 2024-12-11 16:09:57.622 ServerApp] Uncaught exception GET /api/nbconvert?1733900997284 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733900997284', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-11 16:09:57.623 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-11 16:09:57.623 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241211_03_SparkSQL_UDF.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-11 16:09:57.623 ServerApp] 500 GET /api/nbconvert?1733900997284 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 77.08ms referer=http://13.208.159.5:8906/notebooks/241211_03_SparkSQL_UDF.ipynb
[I 2024-12-11 16:09:57.627 ServerApp] Connecting to kernel 3af5d36e-9e9c-468b-ad30-349b60bd5154.
[I 2024-12-11 16:09:57.712 ServerApp] Connecting to kernel 71216185-4fc5-4e7d-98e1-c54b69c6910c.
[I 2024-12-11 16:09:57.960 ServerApp] Connecting to kernel 71216185-4fc5-4e7d-98e1-c54b69c6910c.
24/12/11 16:10:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 2024-12-11 16:10:51.762 ServerApp] Saving file at /241211_03_SparkSQL_UDF.ipynb
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2024-12-11 16:12:51.927 ServerApp] Saving file at /241211_03_SparkSQL_UDF.ipynb
[I 2024-12-11 16:13:15.671 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[E 2024-12-11 16:13:15.766 ServerApp] Uncaught exception GET /api/nbconvert?1733901195615 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733901195615', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-11 16:13:15.766 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-11 16:13:15.767 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241211_03_SparkSQL_UDF.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-11 16:13:15.767 ServerApp] 500 GET /api/nbconvert?1733901195615 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 72.22ms referer=http://13.208.159.5:8906/notebooks/241211_03_SparkSQL_UDF.ipynb
[I 2024-12-11 16:13:15.771 ServerApp] Connecting to kernel 3af5d36e-9e9c-468b-ad30-349b60bd5154.
[I 2024-12-11 16:13:15.865 ServerApp] Connecting to kernel 71216185-4fc5-4e7d-98e1-c54b69c6910c.
[I 2024-12-11 16:13:16.139 ServerApp] Connecting to kernel 71216185-4fc5-4e7d-98e1-c54b69c6910c.
[I 2024-12-11 16:18:52.124 ServerApp] Saving file at /241211_03_SparkSQL_UDF.ipynb
[I 2024-12-11 16:20:52.317 ServerApp] Saving file at /241211_03_SparkSQL_UDF.ipynb
[I 2024-12-11 16:22:52.515 ServerApp] Saving file at /241211_03_SparkSQL_UDF.ipynb
[I 2024-12-11 16:28:52.815 ServerApp] Saving file at /241211_03_SparkSQL_UDF.ipynb
[I 2024-12-11 16:30:04.021 ServerApp] Saving file at /241211_03_SparkSQL_UDF.ipynb
[I 2024-12-11 16:30:15.718 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[I 2024-12-11 16:30:15.807 ServerApp] Connecting to kernel 3af5d36e-9e9c-468b-ad30-349b60bd5154.
[I 2024-12-11 16:30:15.918 ServerApp] Connecting to kernel 71216185-4fc5-4e7d-98e1-c54b69c6910c.
[E 2024-12-11 16:30:16.700 ServerApp] Uncaught exception GET /api/nbconvert?1733902216695 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733902216695', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-11 16:30:16.701 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-11 16:30:16.701 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-11 16:30:16.701 ServerApp] 500 GET /api/nbconvert?1733902216695 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 41.94ms referer=http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 16:30:18.702 ServerApp] Kernel started: 4718f2d4-2cfd-4075-8322-dc4c8c2c3f2a
[I 2024-12-11 16:30:19.137 ServerApp] Connecting to kernel 4718f2d4-2cfd-4075-8322-dc4c8c2c3f2a.
[I 2024-12-11 16:32:17.717 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 16:34:17.906 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
24/12/11 16:35:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2024-12-11 16:36:18.074 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 5:>                                                         (0 + 2) / 11][Stage 5:=====>                                                    (1 + 2) / 11][Stage 5:==========>                                               (2 + 2) / 11][Stage 5:=====================>                                    (4 + 2) / 11][Stage 5:==========================>                               (5 + 2) / 11][Stage 5:===============================>                          (6 + 2) / 11][Stage 5:====================================>                     (7 + 2) / 11][Stage 5:==========================================>               (8 + 2) / 11][Stage 5:===============================================>          (9 + 2) / 11][Stage 5:===================================================>     (10 + 1) / 11]                                                                                [Stage 7:>                                                         (0 + 2) / 11][Stage 7:>                                                         (0 + 3) / 11][Stage 7:==========>                                               (2 + 2) / 11][Stage 7:=====================>                                    (4 + 2) / 11][Stage 7:===============================>                          (6 + 2) / 11][Stage 7:==========================================>               (8 + 2) / 11][Stage 7:===============================================>          (9 + 2) / 11][Stage 7:===================================================>     (10 + 1) / 11]                                                                                [I 2024-12-11 16:38:18.225 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 14:>                                                         (0 + 1) / 1]                                                                                [Stage 15:>                                                         (0 + 2) / 2]                                                                                [Stage 16:>                                                         (0 + 2) / 2][Stage 16:=============================>                            (1 + 1) / 2]                                                                                [I 2024-12-11 16:40:18.378 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 16:48:19.125 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 16:50:19.345 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 16:58:19.607 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 17:00:19.770 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 19:>                                                        (0 + 2) / 11][Stage 19:>                                                        (0 + 4) / 11][Stage 19:==========>                                              (2 + 2) / 11][I 2024-12-11 17:02:19.948 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 19:===============>                                         (3 + 3) / 11][Stage 19:====================>                                    (4 + 2) / 11][Stage 19:=========================>                               (5 + 2) / 11][Stage 19:===============================>                         (6 + 2) / 11][Stage 19:====================================>                    (7 + 3) / 11][Stage 19:=========================================>               (8 + 2) / 11][Stage 19:==============================================>          (9 + 2) / 11][Stage 19:==================================================>     (10 + 1) / 11]                                                                                [I 2024-12-11 17:04:20.143 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 17:06:20.477 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 21:>                                                        (0 + 2) / 11][Stage 21:==========>                                              (2 + 2) / 11][Stage 21:====================>                                    (4 + 2) / 11][Stage 21:=========================>                               (5 + 2) / 11][Stage 21:===============================>                         (6 + 2) / 11][Stage 21:====================================>                    (7 + 2) / 11][Stage 21:=========================================>               (8 + 2) / 11][Stage 21:==============================================>          (9 + 2) / 11][Stage 21:==================================================>     (10 + 1) / 11][Stage 22:================>                                      (61 + 2) / 200][Stage 22:==========================>                            (98 + 3) / 200][Stage 22:====================================>                 (137 + 2) / 200][Stage 22:==============================================>       (172 + 2) / 200]                                                                                [I 2024-12-11 17:08:20.651 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 17:16:20.836 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 23:>                                                        (0 + 2) / 11][Stage 23:==========>                                              (2 + 2) / 11][Stage 23:====================>                                    (4 + 2) / 11][Stage 23:===============================>                         (6 + 2) / 11][Stage 23:====================================>                    (7 + 2) / 11][Stage 23:=========================================>               (8 + 2) / 11][Stage 23:==============================================>          (9 + 2) / 11][Stage 23:==================================================>     (10 + 1) / 11][Stage 24:===========================>                          (103 + 2) / 200][Stage 24:========================================>             (149 + 2) / 200][Stage 24:==================================================>   (186 + 2) / 200]                                                                                [I 2024-12-11 17:20:21.016 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 17:24:21.312 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 25:>                                                        (0 + 2) / 11][Stage 25:==========>                                              (2 + 2) / 11][Stage 25:===============>                                         (3 + 2) / 11][Stage 25:====================>                                    (4 + 2) / 11][Stage 25:=========================>                               (5 + 2) / 11][Stage 25:===============================>                         (6 + 2) / 11][Stage 25:=========================================>               (8 + 2) / 11][Stage 25:==============================================>          (9 + 2) / 11][Stage 25:==================================================>     (10 + 1) / 11][Stage 26:=================================>                    (125 + 2) / 200][Stage 26:=================================================>    (185 + 2) / 200]                                                                                [I 2024-12-11 17:26:21.463 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 17:28:21.699 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 17:29:27.225 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[I 2024-12-11 17:29:27.320 ServerApp] Connecting to kernel 3af5d36e-9e9c-468b-ad30-349b60bd5154.
[I 2024-12-11 17:29:27.410 ServerApp] Connecting to kernel 71216185-4fc5-4e7d-98e1-c54b69c6910c.
[I 2024-12-11 17:29:27.506 ServerApp] Connecting to kernel 4718f2d4-2cfd-4075-8322-dc4c8c2c3f2a.
[E 2024-12-11 17:29:27.739 ServerApp] Uncaught exception GET /api/nbconvert?1733905767754 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733905767754', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-11 17:29:27.740 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-11 17:29:27.740 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241211_01_SparkSQL_SQLtest_books.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-11 17:29:27.740 ServerApp] 500 GET /api/nbconvert?1733905767754 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 42.44ms referer=http://13.208.159.5:8906/notebooks/241211_01_SparkSQL_SQLtest_books.ipynb
[I 2024-12-11 17:29:30.617 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[Stage 27:>                                                        (0 + 2) / 11][Stage 27:==========>                                              (2 + 2) / 11][Stage 27:====================>                                    (4 + 2) / 11][Stage 27:===============================>                         (6 + 2) / 11][Stage 27:=========================================>               (8 + 2) / 11][Stage 27:==============================================>          (9 + 2) / 11][Stage 27:==================================================>     (10 + 1) / 11][Stage 28:==================================>                   (128 + 2) / 200][Stage 28:================================================>     (179 + 2) / 200]                                                                                [I 2024-12-11 17:30:21.958 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 29:>                                                        (0 + 2) / 11][Stage 29:==========>                                              (2 + 2) / 11][Stage 29:===============>                                         (3 + 2) / 11][Stage 29:====================>                                    (4 + 2) / 11][Stage 29:===============================>                         (6 + 2) / 11][Stage 29:=========================================>               (8 + 2) / 11][Stage 29:==============================================>          (9 + 2) / 11][Stage 29:==================================================>     (10 + 1) / 11][Stage 30:=========================================>            (155 + 2) / 200]                                                                                [Stage 31:>                                                        (0 + 2) / 11][I 2024-12-11 17:32:22.268 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 31:=====>                                                   (1 + 2) / 11][Stage 31:==========>                                              (2 + 2) / 11][Stage 31:====================>                                    (4 + 2) / 11][Stage 31:===============================>                         (6 + 2) / 11][Stage 31:=========================================>               (8 + 2) / 11][Stage 31:==============================================>          (9 + 2) / 11][Stage 31:==================================================>     (10 + 1) / 11][Stage 32:================================================>     (179 + 4) / 200]                                                                                [I 2024-12-11 17:34:22.470 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 17:36:22.761 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 33:>                                                        (0 + 2) / 11][Stage 33:=====>                                                   (1 + 2) / 11][Stage 33:==========>                                              (2 + 2) / 11][Stage 33:===============>                                         (3 + 2) / 11][Stage 33:====================>                                    (4 + 2) / 11][Stage 33:=========================>                               (5 + 2) / 11][Stage 33:===============================>                         (6 + 2) / 11][Stage 33:=========================================>               (8 + 2) / 11][Stage 33:==============================================>          (9 + 2) / 11][Stage 33:==================================================>     (10 + 1) / 11][Stage 34:============================================>         (165 + 2) / 200]                                                                                [Stage 35:>                                                        (0 + 2) / 11][Stage 35:==========>                                              (2 + 2) / 11][Stage 35:====================>                                    (4 + 2) / 11][Stage 35:=========================>                               (5 + 2) / 11][Stage 35:===============================>                         (6 + 2) / 11][Stage 35:====================================>                    (7 + 2) / 11][Stage 35:=========================================>               (8 + 2) / 11][Stage 35:==============================================>          (9 + 2) / 11][Stage 35:==================================================>     (10 + 1) / 11][I 2024-12-11 17:38:23.053 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 36:==============================================>       (172 + 3) / 200]                                                                                [Stage 37:>                                                        (0 + 2) / 11][Stage 37:==========>                                              (2 + 2) / 11][Stage 37:===============>                                         (3 + 2) / 11][Stage 37:====================>                                    (4 + 2) / 11][Stage 37:=========================>                               (5 + 2) / 11][Stage 37:===============================>                         (6 + 2) / 11][Stage 37:====================================>                    (7 + 2) / 11][Stage 37:=========================================>               (8 + 2) / 11][Stage 37:==============================================>          (9 + 2) / 11][Stage 37:==================================================>     (10 + 1) / 11][Stage 38:=======================================>              (148 + 3) / 200]                                                                                [Stage 39:>                                                        (0 + 2) / 11][Stage 39:=====>                                                   (1 + 2) / 11][Stage 39:==========>                                              (2 + 2) / 11][Stage 39:===============>                                         (3 + 2) / 11][Stage 39:====================>                                    (4 + 2) / 11][Stage 39:===============================>                         (6 + 2) / 11][Stage 39:=========================================>               (8 + 2) / 11][Stage 39:==============================================>          (9 + 2) / 11][Stage 39:==================================================>     (10 + 1) / 11][Stage 40:==============================================>       (171 + 2) / 200]                                                                                [I 2024-12-11 17:40:23.244 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 41:>                                                        (0 + 2) / 11][Stage 41:=====>                                                   (1 + 2) / 11][Stage 41:==========>                                              (2 + 2) / 11][Stage 41:====================>                                    (4 + 2) / 11][Stage 41:===============================>                         (6 + 2) / 11][Stage 41:====================================>                    (7 + 2) / 11][Stage 41:=========================================>               (8 + 2) / 11][Stage 41:==============================================>          (9 + 2) / 11][Stage 41:==================================================>     (10 + 1) / 11]                                                                                [I 2024-12-11 17:42:23.496 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 51:>                                                        (0 + 2) / 11][Stage 51:==========>                                              (2 + 2) / 11][Stage 51:====================>                                    (4 + 2) / 11][Stage 51:===============================>                         (6 + 2) / 11][Stage 51:====================================>                    (7 + 2) / 11][Stage 51:=========================================>               (8 + 2) / 11][Stage 51:==============================================>          (9 + 2) / 11][Stage 51:==================================================>     (10 + 1) / 11]                                                                                [I 2024-12-11 17:44:23.750 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 17:46:23.892 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 17:54:15.537 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 18:00:15.721 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 62:>                                                        (0 + 2) / 11][Stage 62:==========>                                              (2 + 2) / 11][Stage 62:====================>                                    (4 + 2) / 11][Stage 62:=========================>                               (5 + 2) / 11][Stage 62:===============================>                         (6 + 2) / 11][Stage 62:====================================>                    (7 + 2) / 11][Stage 62:=========================================>               (8 + 2) / 11][Stage 62:==============================================>          (9 + 2) / 11][Stage 62:==================================================>     (10 + 1) / 11]                                                                                [Stage 64:>                                                        (0 + 2) / 11][Stage 64:==========>                                              (2 + 2) / 11][Stage 64:====================>                                    (4 + 2) / 11][Stage 64:===============================>                         (6 + 2) / 11][Stage 64:=========================================>               (8 + 2) / 11][Stage 64:==============================================>          (9 + 2) / 11][Stage 64:==================================================>     (10 + 1) / 11]                                                                                [I 2024-12-11 18:02:15.925 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 67:>                                                        (0 + 2) / 11][Stage 67:==========>                                              (2 + 2) / 11][Stage 67:====================>                                    (4 + 2) / 11][Stage 67:===============================>                         (6 + 2) / 11][Stage 67:=========================================>               (8 + 2) / 11][I 2024-12-11 18:16:16.106 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 67:==============================================>          (9 + 2) / 11][Stage 67:==================================================>     (10 + 1) / 11][Stage 68:==================================>                   (127 + 2) / 200][Stage 68:===================================================>  (189 + 2) / 200]                                                                                [Stage 69:>                                                        (0 + 2) / 11][Stage 69:==========>                                              (2 + 2) / 11][Stage 69:===============>                                         (3 + 2) / 11][Stage 69:====================>                                    (4 + 2) / 11][Stage 69:=========================>                               (5 + 2) / 11][Stage 69:===============================>                         (6 + 2) / 11][Stage 69:=========================================>               (8 + 2) / 11][Stage 69:==============================================>          (9 + 2) / 11][Stage 69:==================================================>     (10 + 1) / 11]                                                                                [Stage 80:>                                                        (0 + 2) / 11][Stage 80:=====>                                                   (1 + 2) / 11][Stage 80:==========>                                              (2 + 2) / 11][Stage 80:====================>                                    (4 + 2) / 11][Stage 80:===============================>                         (6 + 2) / 11][Stage 80:====================================>                    (7 + 2) / 11][Stage 80:=========================================>               (8 + 2) / 11][Stage 80:==============================================>          (9 + 2) / 11][Stage 80:==================================================>     (10 + 1) / 11][Stage 81:=============================================>        (168 + 2) / 200]                                                                                [Stage 83:>                                                        (0 + 2) / 11][Stage 83:==========>                                              (2 + 2) / 11][Stage 83:====================>                                    (4 + 2) / 11][Stage 83:=========================>                               (5 + 2) / 11][Stage 83:===============================>                         (6 + 2) / 11][Stage 83:====================================>                    (7 + 2) / 11][Stage 83:=========================================>               (8 + 2) / 11][Stage 83:==============================================>          (9 + 2) / 11][Stage 83:==================================================>     (10 + 1) / 11][I 2024-12-11 18:18:16.300 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 84:=================================================>    (182 + 2) / 200]                                                                                [Stage 86:>                                                        (0 + 2) / 11][Stage 86:==========>                                              (2 + 2) / 11][Stage 86:====================>                                    (4 + 2) / 11][Stage 86:=========================>                               (5 + 2) / 11][Stage 86:===============================>                         (6 + 2) / 11][Stage 86:====================================>                    (7 + 2) / 11][Stage 86:=========================================>               (8 + 2) / 11][Stage 86:==============================================>          (9 + 2) / 11][Stage 86:==================================================>     (10 + 1) / 11]                                                                                [Stage 97:>                                                        (0 + 2) / 11][Stage 97:==========>                                              (2 + 2) / 11][Stage 97:====================>                                    (4 + 2) / 11][Stage 97:=========================>                               (5 + 2) / 11][Stage 97:===============================>                         (6 + 2) / 11][Stage 97:=========================================>               (8 + 2) / 11][Stage 97:==============================================>          (9 + 2) / 11][Stage 97:==================================================>     (10 + 1) / 11]                                                                                [I 2024-12-11 18:19:45.876 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 108:>                                                       (0 + 2) / 11][Stage 108:==========>                                             (2 + 2) / 11][Stage 108:====================>                                   (4 + 2) / 11][Stage 108:==============================>                         (6 + 2) / 11][Stage 108:========================================>               (8 + 2) / 11][Stage 108:=============================================>          (9 + 2) / 11][Stage 108:==================================================>    (10 + 1) / 11]                                                                                [Stage 111:>                                                       (0 + 2) / 11][Stage 111:==========>                                             (2 + 2) / 11][Stage 111:====================>                                   (4 + 2) / 11][Stage 111:=========================>                              (5 + 2) / 11][Stage 111:==============================>                         (6 + 2) / 11][Stage 111:========================================>               (8 + 2) / 11][Stage 111:=============================================>          (9 + 2) / 11][Stage 111:==================================================>    (10 + 1) / 11][Stage 112:===========================================>         (166 + 2) / 200]                                                                                [Stage 114:>                                                       (0 + 2) / 11][Stage 114:=====>                                                  (1 + 2) / 11][Stage 114:==========>                                             (2 + 2) / 11][Stage 114:===============>                                        (3 + 2) / 11][Stage 114:====================>                                   (4 + 2) / 11][Stage 114:==============================>                         (6 + 2) / 11][Stage 114:===================================>                    (7 + 2) / 11][Stage 114:========================================>               (8 + 2) / 11][Stage 114:=============================================>          (9 + 2) / 11][Stage 114:==================================================>    (10 + 1) / 11][Stage 115:==================================>                  (130 + 2) / 200][Stage 115:=============================================>       (171 + 2) / 200]                                                                                [I 2024-12-11 18:21:46.158 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 117:>                                                       (0 + 2) / 11][Stage 117:==========>                                             (2 + 2) / 11][Stage 117:====================>                                   (4 + 2) / 11][Stage 117:==============================>                         (6 + 2) / 11][Stage 117:========================================>               (8 + 2) / 11][Stage 117:=============================================>          (9 + 2) / 11][Stage 117:==================================================>    (10 + 1) / 11][Stage 118:===================================>                 (135 + 2) / 200][Stage 118:==================================================>  (192 + 2) / 200]                                                                                [Stage 120:>                                                       (0 + 2) / 11][Stage 120:==========>                                             (2 + 2) / 11][Stage 120:====================>                                   (4 + 2) / 11][Stage 120:=========================>                              (5 + 2) / 11][Stage 120:==============================>                         (6 + 2) / 11][Stage 120:===================================>                    (7 + 2) / 11][Stage 120:========================================>               (8 + 2) / 11][Stage 120:=============================================>          (9 + 2) / 11][Stage 120:==================================================>    (10 + 1) / 11][Stage 121:===================================>                 (134 + 2) / 200][Stage 121:===============================================>     (179 + 2) / 200]                                                                                [I 2024-12-11 18:23:46.405 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 123:>                                                       (0 + 2) / 11][Stage 123:==========>                                             (2 + 2) / 11][Stage 123:===============>                                        (3 + 2) / 11][Stage 123:====================>                                   (4 + 2) / 11][Stage 123:=========================>                              (5 + 2) / 11][Stage 123:==============================>                         (6 + 2) / 11][Stage 123:===================================>                    (7 + 2) / 11][Stage 123:========================================>               (8 + 2) / 11][Stage 123:=============================================>          (9 + 2) / 11][Stage 123:==================================================>    (10 + 1) / 11][Stage 124:=====================================>               (142 + 2) / 200][Stage 124:================================================>    (183 + 4) / 200]                                                                                [Stage 126:>                                                       (0 + 2) / 11][Stage 126:==========>                                             (2 + 2) / 11][Stage 126:====================>                                   (4 + 2) / 11][Stage 126:==============================>                         (6 + 2) / 11][Stage 126:===================================>                    (7 + 2) / 11][Stage 126:========================================>               (8 + 2) / 11][Stage 126:=============================================>          (9 + 2) / 11][Stage 126:==================================================>    (10 + 1) / 11][Stage 127:==============================>                      (116 + 2) / 200][Stage 127:==========================================>          (162 + 2) / 200]                                                                                [Stage 129:>                                                       (0 + 2) / 11][Stage 129:=====>                                                  (1 + 2) / 11][Stage 129:==========>                                             (2 + 2) / 11][Stage 129:===============>                                        (3 + 2) / 11][Stage 129:====================>                                   (4 + 2) / 11][Stage 129:==============================>                         (6 + 2) / 11][Stage 129:========================================>               (8 + 2) / 11][Stage 129:=============================================>          (9 + 2) / 11][Stage 129:==================================================>    (10 + 1) / 11][Stage 130:================================>                    (121 + 3) / 200][Stage 130:=============================================>       (170 + 2) / 200]                                                                                [Stage 132:>                                                       (0 + 2) / 11][Stage 132:==========>                                             (2 + 2) / 11][I 2024-12-11 18:25:46.611 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 132:===============>                                        (3 + 2) / 11][Stage 132:====================>                                   (4 + 2) / 11][Stage 132:==============================>                         (6 + 2) / 11][Stage 132:===================================>                    (7 + 2) / 11][Stage 132:========================================>               (8 + 2) / 11][Stage 132:=============================================>          (9 + 2) / 11][Stage 132:==================================================>    (10 + 1) / 11][Stage 133:===============================================>     (178 + 3) / 200]                                                                                [Stage 135:>                                                       (0 + 2) / 11][Stage 135:==========>                                             (2 + 2) / 11][Stage 135:===============>                                        (3 + 2) / 11][Stage 135:====================>                                   (4 + 2) / 11][Stage 135:==============================>                         (6 + 2) / 11][Stage 135:===================================>                    (7 + 2) / 11][Stage 135:========================================>               (8 + 2) / 11][Stage 135:=============================================>          (9 + 2) / 11][Stage 135:==================================================>    (10 + 1) / 11][Stage 136:=====================================>               (142 + 2) / 200][Stage 136:===================================================> (193 + 2) / 200]                                                                                [Stage 138:==========>                                           (39 + 2) / 200][Stage 138:==============>                                       (52 + 2) / 200][Stage 138:=================>                                    (66 + 2) / 200][Stage 138:=====================>                                (78 + 3) / 200][Stage 138:========================>                             (92 + 2) / 200][Stage 138:============================>                        (106 + 2) / 200][Stage 138:===============================>                     (120 + 2) / 200][Stage 138:===================================>                 (134 + 2) / 200][Stage 138:======================================>              (146 + 2) / 200][Stage 138:==========================================>          (159 + 2) / 200][Stage 138:=============================================>       (172 + 2) / 200][Stage 138:=================================================>   (185 + 2) / 200][Stage 138:====================================================>(199 + 1) / 200][Stage 139:===================>                                  (70 + 2) / 198][Stage 139:===========================>                         (103 + 2) / 198][Stage 139:====================================>                (136 + 2) / 198][Stage 139:============================================>        (168 + 2) / 198]                                                                                [Stage 142:>                                                       (0 + 2) / 11][Stage 142:=====>                                                  (1 + 2) / 11][Stage 142:==========>                                             (2 + 2) / 11][Stage 142:===============>                                        (3 + 2) / 11][Stage 142:====================>                                   (4 + 2) / 11][Stage 142:=========================>                              (5 + 2) / 11][Stage 142:==============================>                         (6 + 2) / 11][Stage 142:========================================>               (8 + 2) / 11][I 2024-12-11 18:27:46.812 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 142:=============================================>          (9 + 2) / 11][Stage 142:==================================================>    (10 + 1) / 11][Stage 143:==============================>                      (115 + 2) / 200][Stage 143:==========================================>          (162 + 2) / 200]                                                                                [Stage 145:>                                                       (0 + 2) / 11][Stage 145:==========>                                             (2 + 2) / 11][Stage 145:===============>                                        (3 + 2) / 11][Stage 145:====================>                                   (4 + 2) / 11][Stage 145:=========================>                              (5 + 2) / 11][Stage 145:==============================>                         (6 + 2) / 11][Stage 145:===================================>                    (7 + 2) / 11][Stage 145:========================================>               (8 + 2) / 11][Stage 145:=============================================>          (9 + 2) / 11][Stage 145:==================================================>    (10 + 1) / 11][Stage 146:=====================================>               (141 + 2) / 200][Stage 146:====================================================>(198 + 2) / 200]                                                                                [Stage 148:>                                                       (0 + 2) / 11][Stage 148:==========>                                             (2 + 2) / 11][Stage 148:====================>                                   (4 + 2) / 11][Stage 148:==============================>                         (6 + 2) / 11][Stage 148:========================================>               (8 + 2) / 11][Stage 148:=============================================>          (9 + 2) / 11][Stage 148:==================================================>    (10 + 1) / 11][Stage 149:=======================================>             (148 + 2) / 200][Stage 149:===================================================> (195 + 2) / 200]                                                                                [Stage 151:>                                                       (0 + 2) / 11][Stage 151:==========>                                             (2 + 2) / 11][Stage 151:====================>                                   (4 + 2) / 11][Stage 151:=========================>                              (5 + 2) / 11][Stage 151:==============================>                         (6 + 2) / 11][Stage 151:===================================>                    (7 + 2) / 11][Stage 151:========================================>               (8 + 2) / 11][Stage 151:=============================================>          (9 + 2) / 11][Stage 151:==================================================>    (10 + 1) / 11][Stage 152:============================================>        (168 + 2) / 200]                                                                                [Stage 154:>                                                       (0 + 2) / 11][Stage 154:==========>                                             (2 + 2) / 11][Stage 154:===============>                                        (3 + 2) / 11][Stage 154:====================>                                   (4 + 2) / 11][Stage 154:=========================>                              (5 + 2) / 11][Stage 154:==============================>                         (6 + 2) / 11][Stage 154:===================================>                    (7 + 2) / 11][Stage 154:========================================>               (8 + 2) / 11][Stage 154:=============================================>          (9 + 2) / 11][Stage 154:==================================================>    (10 + 1) / 11][Stage 155:=================================>                   (126 + 2) / 200][Stage 155:==============================================>      (174 + 2) / 200]                                                                                [Stage 157:=========>                                            (36 + 2) / 200][Stage 157:=============>                                        (49 + 2) / 200][Stage 157:================>                                     (62 + 2) / 200][Stage 157:===================>                                  (74 + 2) / 200][Stage 157:======================>                               (84 + 2) / 200][Stage 157:=========================>                            (95 + 2) / 200][Stage 157:============================>                        (109 + 2) / 200][Stage 157:================================>                    (122 + 2) / 200][Stage 157:===================================>                 (135 + 2) / 200][Stage 157:=======================================>             (149 + 2) / 200][Stage 157:==========================================>          (162 + 2) / 200][Stage 157:==============================================>      (176 + 2) / 200][Stage 157:==================================================>  (190 + 2) / 200][Stage 158:=======================>                              (85 + 2) / 198][Stage 158:===============================>                     (116 + 2) / 198][Stage 158:======================================>              (142 + 2) / 198][Stage 158:==============================================>      (175 + 2) / 198]                                                                                [I 2024-12-11 18:29:47.022 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 18:31:47.193 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 18:33:47.370 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 18:37:47.534 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 18:39:47.700 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 18:41:47.914 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 18:43:48.131 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 162:>                                                       (0 + 2) / 11][Stage 162:=====>                                                  (1 + 2) / 11][Stage 162:==========>                                             (2 + 2) / 11][Stage 162:===============>                                        (3 + 2) / 11][Stage 162:====================>                                   (4 + 2) / 11][Stage 162:=========================>                              (5 + 2) / 11][Stage 162:==============================>                         (6 + 2) / 11][Stage 162:===================================>                    (7 + 2) / 11][Stage 162:========================================>               (8 + 2) / 11][Stage 162:=============================================>          (9 + 2) / 11][Stage 162:==================================================>    (10 + 1) / 11][Stage 163:========================================>            (154 + 2) / 200]                                                                                [I 2024-12-11 18:45:48.718 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 165:>                                                       (0 + 2) / 11][Stage 165:=====>                                                  (1 + 2) / 11][Stage 165:==========>                                             (2 + 2) / 11][Stage 165:====================>                                   (4 + 2) / 11][Stage 165:=========================>                              (5 + 2) / 11][Stage 165:==============================>                         (6 + 2) / 11][Stage 165:===================================>                    (7 + 2) / 11][Stage 165:========================================>               (8 + 2) / 11][Stage 165:=============================================>          (9 + 2) / 11][I 2024-12-11 18:49:48.916 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 165:==================================================>    (10 + 1) / 11][Stage 166:==========================================>          (162 + 2) / 200]                                                                                [Stage 168:>                                                       (0 + 2) / 11][Stage 168:==========>                                             (2 + 2) / 11][Stage 168:===============>                                        (3 + 2) / 11][Stage 168:====================>                                   (4 + 2) / 11][Stage 168:=========================>                              (5 + 2) / 11][Stage 168:==============================>                         (6 + 2) / 11][Stage 168:===================================>                    (7 + 2) / 11][Stage 168:========================================>               (8 + 2) / 11][Stage 168:=============================================>          (9 + 2) / 11][Stage 168:==================================================>    (10 + 1) / 11][Stage 169:===============================================>     (179 + 2) / 200]                                                                                [Stage 171:>                                                       (0 + 2) / 11][Stage 171:==========>                                             (2 + 2) / 11][Stage 171:====================>                                   (4 + 2) / 11][I 2024-12-11 18:51:49.123 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 171:=========================>                              (5 + 2) / 11][Stage 171:==============================>                         (6 + 2) / 11][Stage 171:===================================>                    (7 + 2) / 11][Stage 171:========================================>               (8 + 2) / 11][Stage 171:=============================================>          (9 + 2) / 11][Stage 171:==================================================>    (10 + 1) / 11]                                                                                [Stage 174:>                                                       (0 + 2) / 11][Stage 174:=====>                                                  (1 + 2) / 11][Stage 174:==========>                                             (2 + 2) / 11][Stage 174:===============>                                        (3 + 2) / 11][Stage 174:====================>                                   (4 + 2) / 11][Stage 174:=========================>                              (5 + 2) / 11][Stage 174:==============================>                         (6 + 2) / 11][Stage 174:===================================>                    (7 + 2) / 11][Stage 174:========================================>               (8 + 2) / 11][Stage 174:=============================================>          (9 + 2) / 11][Stage 174:==================================================>    (10 + 1) / 11]                                                                                [I 2024-12-11 18:53:49.333 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 177:>                                                       (0 + 2) / 11][Stage 177:==========>                                             (2 + 2) / 11][Stage 177:===============>                                        (3 + 2) / 11][Stage 177:====================>                                   (4 + 2) / 11][Stage 177:=========================>                              (5 + 2) / 11][Stage 177:==============================>                         (6 + 2) / 11][Stage 177:===================================>                    (7 + 2) / 11][Stage 177:========================================>               (8 + 2) / 11][I 2024-12-11 18:54:38.772 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 177:=============================================>          (9 + 2) / 11][Stage 177:==================================================>    (10 + 1) / 11]                                                                                [Stage 180:>                                                       (0 + 2) / 11][Stage 180:==========>                                             (2 + 2) / 11][Stage 180:====================>                                   (4 + 2) / 11][Stage 180:=========================>                              (5 + 2) / 11][Stage 180:==============================>                         (6 + 2) / 11][Stage 180:===================================>                    (7 + 2) / 11][Stage 180:========================================>               (8 + 2) / 11][Stage 180:=============================================>          (9 + 2) / 11][Stage 180:==================================================>    (10 + 1) / 11][Stage 181:=============================>                       (112 + 2) / 200][Stage 181:======================================>              (144 + 2) / 200][Stage 181:==============================================>      (176 + 2) / 200]                                                                                [I 2024-12-11 18:56:38.999 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 18:57:03.445 ServerApp] Starting buffering for 4718f2d4-2cfd-4075-8322-dc4c8c2c3f2a:bedc51a3-ed34-4ca8-90fa-46baa131ea54
[I 2024-12-11 18:57:22.240 ServerApp] Connecting to kernel f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31.
[E 2024-12-11 18:57:22.378 ServerApp] Uncaught exception GET /api/nbconvert?1733911042399 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733911042399', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-11 18:57:22.379 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-11 18:57:22.379 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-11 18:57:22.379 ServerApp] 500 GET /api/nbconvert?1733911042399 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 58.95ms referer=http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 18:57:22.385 ServerApp] Connecting to kernel 3af5d36e-9e9c-468b-ad30-349b60bd5154.
[I 2024-12-11 18:57:22.491 ServerApp] Connecting to kernel 71216185-4fc5-4e7d-98e1-c54b69c6910c.
[I 2024-12-11 18:57:22.583 ServerApp] Connecting to kernel 4718f2d4-2cfd-4075-8322-dc4c8c2c3f2a.
[I 2024-12-11 18:57:23.070 ServerApp] Starting buffering for 4718f2d4-2cfd-4075-8322-dc4c8c2c3f2a:4bd78ee7-b999-47bd-9af0-6e4f85405441
[I 2024-12-11 18:57:23.320 ServerApp] Connecting to kernel 4718f2d4-2cfd-4075-8322-dc4c8c2c3f2a.
[I 2024-12-11 18:57:50.347 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 18:58:29.360 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-11 18:58:30.814 ServerApp] Starting buffering for 4718f2d4-2cfd-4075-8322-dc4c8c2c3f2a:2ac10920-f6b4-4c20-9461-cd74548a0994
[I 2024-12-11 18:58:30.848 ServerApp] Starting buffering for f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31:51b7d8d2-8bf1-45ee-808c-1b62cfa3924d
[I 2024-12-11 18:58:30.848 ServerApp] Starting buffering for 3af5d36e-9e9c-468b-ad30-349b60bd5154:5397d5f8-a1e5-4335-a1cb-b6f3d93fdff0
[I 2024-12-11 18:58:30.849 ServerApp] Starting buffering for 71216185-4fc5-4e7d-98e1-c54b69c6910c:ae6647cc-52dd-43ae-8361-9ec7ecb05c02
[C 2024-12-11 18:58:50.645 ServerApp] received signal 15, stopping
[I 2024-12-11 18:58:50.649 ServerApp] Shutting down 6 extensions
[I 2024-12-11 18:58:50.649 ServerApp] Shutting down 4 kernels
[I 2024-12-11 18:58:50.671 ServerApp] Kernel shutdown: 71216185-4fc5-4e7d-98e1-c54b69c6910c
[I 2024-12-11 18:58:50.683 ServerApp] Kernel shutdown: 3af5d36e-9e9c-468b-ad30-349b60bd5154
[I 2024-12-11 18:58:50.728 ServerApp] Kernel shutdown: f70dc594-9ea4-4d1d-9f13-3a9f9aa06f31
[I 2024-12-11 18:58:50.732 ServerApp] Kernel shutdown: 4718f2d4-2cfd-4075-8322-dc4c8c2c3f2a
[I 2024-12-12 08:52:49.576 ServerApp] jupyter_lsp | extension was successfully linked.
[I 2024-12-12 08:52:49.581 ServerApp] jupyter_server_terminals | extension was successfully linked.
[I 2024-12-12 08:52:49.585 ServerApp] jupyterlab | extension was successfully linked.
[W 2024-12-12 08:52:49.587 JupyterNotebookApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2024-12-12 08:52:49.589 ServerApp] ServerApp.password config is deprecated in 2.0. Use PasswordIdentityProvider.hashed_password.
[I 2024-12-12 08:52:49.589 ServerApp] notebook | extension was successfully linked.
[W 2024-12-12 08:52:49.995 ServerApp] A `_jupyter_server_extension_points` function was not found in jupyter_nbextensions_configurator. Instead, a `_jupyter_server_extension_paths` function was found and will be used for now. This function name will be deprecated in future releases of Jupyter Server.
[I 2024-12-12 08:52:49.995 ServerApp] jupyter_nbextensions_configurator | extension was found and enabled by notebook_shim. Consider moving the extension to Jupyter Server's extension paths.
[I 2024-12-12 08:52:49.995 ServerApp] jupyter_nbextensions_configurator | extension was successfully linked.
[I 2024-12-12 08:52:49.996 ServerApp] notebook_shim | extension was successfully linked.
[I 2024-12-12 08:52:50.066 ServerApp] notebook_shim | extension was successfully loaded.
[I 2024-12-12 08:52:50.068 ServerApp] jupyter_lsp | extension was successfully loaded.
[I 2024-12-12 08:52:50.069 ServerApp] [jupyter_nbextensions_configurator] enabled 0.6.4
[I 2024-12-12 08:52:50.069 ServerApp] jupyter_nbextensions_configurator | extension was successfully loaded.
[I 2024-12-12 08:52:50.070 ServerApp] jupyter_server_terminals | extension was successfully loaded.
[I 2024-12-12 08:52:50.078 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyterlab
[I 2024-12-12 08:52:50.078 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/envs/spark_start/share/jupyter/lab
[I 2024-12-12 08:52:50.078 LabApp] Extension Manager is 'pypi'.
[I 2024-12-12 08:52:50.145 ServerApp] jupyterlab | extension was successfully loaded.
[I 2024-12-12 08:52:50.149 ServerApp] notebook | extension was successfully loaded.
[I 2024-12-12 08:52:50.149 ServerApp] Serving notebooks from local directory: /home/lab06/src/DA-learning-course/Spark
[I 2024-12-12 08:52:50.149 ServerApp] Jupyter Server 2.14.2 is running at:
[I 2024-12-12 08:52:50.149 ServerApp] http://ip-172-31-13-94:8906/tree
[I 2024-12-12 08:52:50.149 ServerApp]     http://127.0.0.1:8906/tree
[I 2024-12-12 08:52:50.149 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 2024-12-12 08:52:50.166 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server
[I 2024-12-12 08:53:11.986 ServerApp] 302 GET / (@211.231.29.166) 0.43ms
[E 2024-12-12 08:53:24.664 ServerApp] Uncaught exception GET /api/nbconvert?1733961204282 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733961204282', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 08:53:24.675 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 08:53:24.675 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 08:53:24.675 ServerApp] 500 GET /api/nbconvert?1733961204282 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 369.86ms referer=http://13.208.159.5:8906/tree?
[E 2024-12-12 08:53:26.030 ServerApp] Uncaught exception GET /api/nbconvert?1733961205955 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733961205955', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 08:53:26.031 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 08:53:26.031 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 08:53:26.031 ServerApp] 500 GET /api/nbconvert?1733961205955 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 56.09ms referer=http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 08:53:26.819 ServerApp] Kernel started: 7a331094-526a-477c-a0f2-1c9177ed2c13
[I 2024-12-12 08:53:27.405 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 08:53:27.486 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 08:53:27.567 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 08:53:34.604 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
24/12/12 08:54:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                         (0 + 2) / 11][Stage 1:=====>                                                    (1 + 2) / 11][Stage 1:==========>                                               (2 + 2) / 11][Stage 1:===============>                                          (3 + 2) / 11][Stage 1:=====================>                                    (4 + 2) / 11][Stage 1:===============================>                          (6 + 2) / 11][Stage 1:==========================================>               (8 + 2) / 11][I 2024-12-12 08:55:26.400 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 1:===============================================>          (9 + 2) / 11][Stage 1:===================================================>     (10 + 1) / 11]                                                                                [Stage 5:>                                                         (0 + 2) / 11][Stage 5:==========>                                               (2 + 2) / 11][Stage 5:===============>                                          (3 + 2) / 11][Stage 5:=====================>                                    (4 + 2) / 11][Stage 5:==========================>                               (5 + 2) / 11][Stage 5:===============================>                          (6 + 2) / 11][Stage 5:====================================>                     (7 + 2) / 11][Stage 5:==========================================>               (8 + 2) / 11][Stage 5:===============================================>          (9 + 2) / 11][Stage 5:===================================================>     (10 + 1) / 11]                                                                                [Stage 10:>                                                        (0 + 2) / 11][Stage 10:>                                                        (0 + 3) / 11][Stage 10:==========>                                              (2 + 2) / 11][Stage 10:====================>                                    (4 + 2) / 11][Stage 10:=========================>                               (5 + 2) / 11][Stage 10:===============================>                         (6 + 2) / 11][Stage 10:====================================>                    (7 + 2) / 11][Stage 10:=========================================>               (8 + 2) / 11][Stage 10:==============================================>          (9 + 2) / 11][Stage 10:==================================================>     (10 + 1) / 11][I 2024-12-12 08:57:26.615 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 11:===============>                                       (57 + 2) / 200][Stage 11:======================>                                (82 + 2) / 200][Stage 11:=============================>                        (111 + 2) / 200][Stage 11:======================================>               (144 + 2) / 200][Stage 11:================================================>     (181 + 2) / 200]                                                                                [Stage 13:>                                                        (0 + 2) / 11][Stage 13:==========>                                              (2 + 2) / 11][Stage 13:====================>                                    (4 + 2) / 11][Stage 13:=========================>                               (5 + 2) / 11][Stage 13:===============================>                         (6 + 2) / 11][Stage 13:====================================>                    (7 + 2) / 11][Stage 13:=========================================>               (8 + 2) / 11][Stage 13:==============================================>          (9 + 2) / 11][Stage 13:==================================================>     (10 + 1) / 11][Stage 14:============>                                          (45 + 2) / 200][Stage 14:===================>                                   (70 + 2) / 200][Stage 14:==========================>                            (95 + 3) / 200][Stage 14:===============================>                      (118 + 2) / 200][Stage 14:====================================>                 (137 + 3) / 200][Stage 14:==========================================>           (158 + 2) / 200][Stage 14:==================================================>   (186 + 2) / 200]                                                                                [I 2024-12-12 08:59:26.772 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 09:01:10.199 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 16:>                                                        (0 + 2) / 11][Stage 16:==========>                                              (2 + 2) / 11][I 2024-12-12 09:03:10.408 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 16:===============>                                         (3 + 2) / 11][Stage 16:====================>                                    (4 + 2) / 11][Stage 16:=========================>                               (5 + 2) / 11][Stage 16:===============================>                         (6 + 2) / 11][Stage 16:====================================>                    (7 + 2) / 11][Stage 16:=========================================>               (8 + 2) / 11][Stage 16:==============================================>          (9 + 2) / 11][Stage 16:==================================================>     (10 + 1) / 11][Stage 17:==================================>                   (129 + 2) / 200][Stage 17:===============================================>      (177 + 2) / 200]                                                                                [Stage 19:>                                                        (0 + 2) / 11][Stage 19:=====>                                                   (1 + 2) / 11][Stage 19:==========>                                              (2 + 2) / 11][Stage 19:====================>                                    (4 + 2) / 11][Stage 19:=========================>                               (5 + 2) / 11][Stage 19:===============================>                         (6 + 2) / 11][Stage 19:====================================>                    (7 + 2) / 11][Stage 19:====================================>                    (7 + 3) / 11][Stage 19:=========================================>               (8 + 2) / 11][Stage 19:==============================================>          (9 + 2) / 11][Stage 19:==================================================>     (10 + 1) / 11][Stage 20:================================>                     (122 + 2) / 200][Stage 20:=============================================>        (167 + 2) / 200]                                                                                [I 2024-12-12 09:05:10.643 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 09:07:10.796 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 22:>                                                        (0 + 2) / 11][Stage 22:==========>                                              (2 + 2) / 11][I 2024-12-12 09:09:10.994 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 22:===============>                                         (3 + 2) / 11][Stage 22:====================>                                    (4 + 2) / 11][Stage 22:===============================>                         (6 + 2) / 11][Stage 22:=========================================>               (8 + 2) / 11][Stage 22:==============================================>          (9 + 2) / 11][Stage 22:==================================================>     (10 + 1) / 11]                                                                                [Stage 33:>                                                        (0 + 2) / 11][Stage 33:=====>                                                   (1 + 2) / 11][Stage 33:==========>                                              (2 + 2) / 11][Stage 33:===============>                                         (3 + 2) / 11][Stage 33:====================>                                    (4 + 2) / 11][Stage 33:=========================>                               (5 + 2) / 11][Stage 33:===============================>                         (6 + 2) / 11][Stage 33:====================================>                    (7 + 2) / 11][Stage 33:=========================================>               (8 + 2) / 11][I 2024-12-12 09:11:11.181 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 33:==============================================>          (9 + 2) / 11][Stage 33:==================================================>     (10 + 1) / 11][Stage 34:========================================>             (149 + 2) / 200]                                                                                [I 2024-12-12 09:13:11.371 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 36:>                                                        (0 + 2) / 11][Stage 36:==========>                                              (2 + 2) / 11][Stage 36:====================>                                    (4 + 2) / 11][Stage 36:=========================>                               (5 + 2) / 11][Stage 36:===============================>                         (6 + 2) / 11][Stage 36:====================================>                    (7 + 2) / 11][Stage 36:=========================================>               (8 + 2) / 11][Stage 36:==============================================>          (9 + 2) / 11][Stage 36:==================================================>     (10 + 1) / 11][Stage 37:========================================>             (149 + 2) / 200]                                                                                [I 2024-12-12 09:15:11.522 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 39:>                                                        (0 + 2) / 11][Stage 39:==========>                                              (2 + 2) / 11][Stage 39:====================>                                    (4 + 2) / 11][Stage 39:=========================>                               (5 + 2) / 11][Stage 39:===============================>                         (6 + 2) / 11][Stage 39:====================================>                    (7 + 2) / 11][Stage 39:=========================================>               (8 + 2) / 11][Stage 39:==============================================>          (9 + 2) / 11][Stage 39:==================================================>     (10 + 1) / 11][Stage 40:==============================================>       (174 + 2) / 200]                                                                                [I 2024-12-12 09:17:11.685 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 42:>                                                        (0 + 2) / 11][Stage 42:==========>                                              (2 + 2) / 11][Stage 42:====================>                                    (4 + 2) / 11][Stage 42:=========================>                               (5 + 2) / 11][Stage 42:===============================>                         (6 + 2) / 11][Stage 42:====================================>                    (7 + 2) / 11][Stage 42:=========================================>               (8 + 2) / 11][Stage 42:==============================================>          (9 + 2) / 11][Stage 42:==================================================>     (10 + 1) / 11][Stage 43:====================================>                 (135 + 2) / 200][Stage 43:=================================================>    (185 + 2) / 200]                                                                                [I 2024-12-12 09:19:11.842 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 45:>                                                        (0 + 2) / 11][Stage 45:==========>                                              (2 + 2) / 11][Stage 45:===============>                                         (3 + 2) / 11][Stage 45:====================>                                    (4 + 2) / 11][Stage 45:=========================>                               (5 + 2) / 11][Stage 45:===============================>                         (6 + 2) / 11][Stage 45:====================================>                    (7 + 2) / 11][Stage 45:=========================================>               (8 + 2) / 11][Stage 45:==============================================>          (9 + 2) / 11][Stage 45:==================================================>     (10 + 1) / 11][Stage 46:========================================>             (151 + 2) / 200][Stage 46:=====================================================>(198 + 2) / 200]                                                                                [Stage 48:>                                                        (0 + 2) / 11][I 2024-12-12 09:21:12.041 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 48:==========>                                              (2 + 2) / 11][Stage 48:====================>                                    (4 + 2) / 11][Stage 48:=========================>                               (5 + 2) / 11][Stage 48:===============================>                         (6 + 2) / 11][Stage 48:===============================>                         (6 + 3) / 11][Stage 48:====================================>                    (7 + 2) / 11][Stage 48:=========================================>               (8 + 2) / 11][Stage 48:==============================================>          (9 + 2) / 11][Stage 48:==================================================>     (10 + 1) / 11][Stage 49:=======================================>              (145 + 3) / 200][Stage 49:====================================================> (195 + 2) / 200]                                                                                [Stage 51:>                                                        (0 + 2) / 11][Stage 51:==========>                                              (2 + 2) / 11][Stage 51:====================>                                    (4 + 2) / 11][Stage 51:=========================>                               (5 + 2) / 11][Stage 51:===============================>                         (6 + 2) / 11][Stage 51:====================================>                    (7 + 2) / 11][Stage 51:=========================================>               (8 + 2) / 11][Stage 51:==============================================>          (9 + 2) / 11][Stage 51:==================================================>     (10 + 1) / 11][Stage 52:========================================>             (150 + 2) / 200][Stage 52:=====================================================>(197 + 2) / 200]                                                                                [I 2024-12-12 09:23:12.273 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 09:25:12.426 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 54:>                                                        (0 + 2) / 11][I 2024-12-12 09:27:12.596 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 54:==========>                                              (2 + 2) / 11][Stage 54:====================>                                    (4 + 2) / 11][Stage 54:=========================>                               (5 + 2) / 11][Stage 54:===============================>                         (6 + 2) / 11][Stage 54:====================================>                    (7 + 2) / 11][Stage 54:=========================================>               (8 + 2) / 11][Stage 54:==============================================>          (9 + 2) / 11][Stage 54:==================================================>     (10 + 1) / 11]                                                                                [I 2024-12-12 09:29:12.817 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[IPKernelApp] ERROR | Failed to open SQLite history /home/lab06/.ipython/profile_default/history.sqlite (datatype mismatch).
[IPKernelApp] ERROR | History file was moved to /home/lab06/.ipython/profile_default/history-corrupt-2024-12-12T09.30.08.497712.sqlite and a new file created.
[I 2024-12-12 09:31:13.008 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 09:33:13.221 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 09:35:13.468 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 09:35:33.744 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 09:37:13.668 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 57:>                                                        (0 + 2) / 11][Stage 57:==========>                                              (2 + 2) / 11][Stage 57:====================>                                    (4 + 2) / 11][Stage 57:=========================>                               (5 + 2) / 11][Stage 57:===============================>                         (6 + 2) / 11][Stage 57:====================================>                    (7 + 2) / 11][Stage 57:=========================================>               (8 + 2) / 11][Stage 57:==============================================>          (9 + 2) / 11][Stage 57:==================================================>     (10 + 1) / 11][Stage 58:========================>                              (90 + 2) / 200][Stage 58:==================================>                   (126 + 2) / 200][Stage 58:===========================================>          (160 + 2) / 200][Stage 58:====================================================> (195 + 3) / 200]                                                                                [Stage 60:>                                                        (0 + 2) / 11][Stage 60:==========>                                              (2 + 2) / 11][Stage 60:===============>                                         (3 + 2) / 11][Stage 60:====================>                                    (4 + 2) / 11][Stage 60:=========================>                               (5 + 2) / 11][Stage 60:===============================>                         (6 + 2) / 11][Stage 60:====================================>                    (7 + 2) / 11][Stage 60:=========================================>               (8 + 2) / 11][I 2024-12-12 09:39:14.716 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 60:==============================================>          (9 + 2) / 11][Stage 60:==================================================>     (10 + 1) / 11][Stage 61:==============================>                       (114 + 3) / 200][Stage 61:===========================================>          (160 + 2) / 200][Stage 61:===================================================>  (190 + 3) / 200]                                                                                [Stage 63:>                                                        (0 + 2) / 11][Stage 63:==========>                                              (2 + 2) / 11][Stage 63:====================>                                    (4 + 2) / 11][Stage 63:=========================>                               (5 + 2) / 11][Stage 63:===============================>                         (6 + 2) / 11][Stage 63:====================================>                    (7 + 2) / 11][Stage 63:=========================================>               (8 + 2) / 11][Stage 63:==============================================>          (9 + 2) / 11][Stage 63:==================================================>     (10 + 1) / 11][Stage 64:===========================>                          (103 + 2) / 200][Stage 64:======================================>               (143 + 2) / 200][Stage 64:=================================================>    (182 + 2) / 200]                                                                                [Stage 66:>                                                        (0 + 2) / 11][Stage 66:==========>                                              (2 + 2) / 11][Stage 66:====================>                                    (4 + 2) / 11][Stage 66:=========================>                               (5 + 2) / 11][Stage 66:===============================>                         (6 + 2) / 11][Stage 66:====================================>                    (7 + 2) / 11][Stage 66:=========================================>               (8 + 2) / 11][Stage 66:==============================================>          (9 + 2) / 11][Stage 66:==================================================>     (10 + 1) / 11][Stage 67:============================>                         (106 + 2) / 200][Stage 67:=========================================>            (153 + 3) / 200][Stage 67:=====================================================>(198 + 2) / 200]                                                                                [Stage 69:>                                                        (0 + 2) / 11][Stage 69:=====>                                                   (1 + 2) / 11][Stage 69:==========>                                              (2 + 2) / 11][Stage 69:===============>                                         (3 + 2) / 11][Stage 69:====================>                                    (4 + 2) / 11][Stage 69:=========================>                               (5 + 2) / 11][Stage 69:===============================>                         (6 + 2) / 11][I 2024-12-12 09:41:14.919 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 69:====================================>                    (7 + 2) / 11][Stage 69:=========================================>               (8 + 2) / 11][Stage 69:==============================================>          (9 + 2) / 11][Stage 69:==================================================>     (10 + 1) / 11][Stage 70:=======================>                               (87 + 2) / 200][Stage 70:===================================>                  (131 + 2) / 200][Stage 70:===============================================>      (175 + 2) / 200]                                                                                [Stage 72:======>                                                (25 + 3) / 200][Stage 72:==========>                                            (39 + 2) / 200][Stage 72:==============>                                        (52 + 2) / 200][Stage 72:==================>                                    (67 + 2) / 200][Stage 72:======================>                                (82 + 2) / 200][Stage 72:==========================>                            (98 + 2) / 200][Stage 72:=============================>                        (110 + 2) / 200][Stage 72:=================================>                    (123 + 2) / 200][Stage 72:=====================================>                (139 + 2) / 200][Stage 72:========================================>             (151 + 2) / 200][Stage 72:============================================>         (165 + 2) / 200][Stage 72:================================================>     (179 + 2) / 200][Stage 72:===================================================>  (191 + 2) / 200][Stage 73:====================>                                  (75 + 2) / 200][Stage 73:===========================>                          (103 + 2) / 200][Stage 73:===================================>                  (131 + 2) / 200][Stage 73:=========================================>            (153 + 2) / 200][Stage 73:===============================================>      (177 + 2) / 200]                                                                                [I 2024-12-12 09:43:15.136 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 09:45:15.651 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[IPKernelApp] ERROR | Failed to open SQLite history /home/lab06/.ipython/profile_default/history.sqlite (datatype mismatch).
[IPKernelApp] ERROR | History file was moved to /home/lab06/.ipython/profile_default/history-corrupt-2024-12-12T09.52.41.695385.sqlite and a new file created.
[I 2024-12-12 09:53:19.909 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 76:>                                                        (0 + 2) / 11][Stage 76:==========>                                              (2 + 2) / 11][Stage 76:===============>                                         (3 + 2) / 11][Stage 76:====================>                                    (4 + 2) / 11][Stage 76:=========================>                               (5 + 2) / 11][Stage 76:===============================>                         (6 + 2) / 11][Stage 76:====================================>                    (7 + 2) / 11][Stage 76:=========================================>               (8 + 2) / 11][Stage 76:==============================================>          (9 + 2) / 11][Stage 76:==================================================>     (10 + 1) / 11][Stage 77:============================================>         (164 + 2) / 200]                                                                                [I 2024-12-12 09:55:20.302 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 79:>                                                        (0 + 2) / 11][Stage 79:==========>                                              (2 + 2) / 11][Stage 79:====================>                                    (4 + 2) / 11][Stage 79:=========================>                               (5 + 2) / 11][Stage 79:===============================>                         (6 + 2) / 11][Stage 79:====================================>                    (7 + 2) / 11][Stage 79:=========================================>               (8 + 2) / 11][Stage 79:==============================================>          (9 + 2) / 11][Stage 79:==================================================>     (10 + 1) / 11][Stage 80:==============================================>       (172 + 2) / 200]                                                                                [I 2024-12-12 09:57:20.492 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[Stage 82:>                                                        (0 + 2) / 11][Stage 82:=====>                                                   (1 + 2) / 11][Stage 82:==========>                                              (2 + 2) / 11][Stage 82:====================>                                    (4 + 2) / 11][Stage 82:=========================>                               (5 + 2) / 11][Stage 82:===============================>                         (6 + 2) / 11][Stage 82:====================================>                    (7 + 2) / 11][Stage 82:=========================================>               (8 + 2) / 11][Stage 82:==============================================>          (9 + 2) / 11][Stage 82:==================================================>     (10 + 1) / 11][Stage 83:==============================================>       (171 + 2) / 200]                                                                                [I 2024-12-12 09:59:20.663 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 10:01:20.830 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 10:01:40.747 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 10:39:08.924 ServerApp] Starting buffering for 7a331094-526a-477c-a0f2-1c9177ed2c13:7b112a0d-1aca-4e98-98a9-d9a15e03ef56
[I 2024-12-12 10:56:12.526 ServerApp] Creating new notebook in 
[I 2024-12-12 10:56:12.835 ServerApp] Saving file at /Untitled.ipynb
[I 2024-12-12 10:56:12.899 ServerApp] Kernel started: 36e813aa-b4e2-4a73-8abc-741981e31fb7
[I 2024-12-12 10:56:13.547 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 10:56:16.564 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 10:56:16.660 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 10:56:16.896 ServerApp] Uncaught exception GET /api/nbconvert?1733968576845 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733968576845', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 10:56:16.896 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 10:56:16.897 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/Untitled.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 10:56:16.897 ServerApp] 500 GET /api/nbconvert?1733968576845 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 42.17ms referer=http://13.208.159.5:8906/notebooks/Untitled.ipynb
[I 2024-12-12 10:56:18.025 ServerApp] Starting buffering for 7a331094-526a-477c-a0f2-1c9177ed2c13:1bf6974d-031a-48f6-9bc8-8264d54cf028
[I 2024-12-12 10:56:18.354 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 10:58:35.824 ServerApp] 302 GET / (@114.203.150.38) 0.32ms
[I 2024-12-12 10:58:36.697 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 10:58:36.840 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 10:58:36.903 ServerApp] Starting buffering for 7a331094-526a-477c-a0f2-1c9177ed2c13:78fd1322-2c5a-4ba7-9945-b8f46d8ecb9e
[E 2024-12-12 10:58:39.804 ServerApp] Uncaught exception GET /api/nbconvert?1733968719724 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733968719724', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 10:58:39.804 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 10:58:39.805 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 10:58:39.805 ServerApp] 500 GET /api/nbconvert?1733968719724 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 55.22ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-12 10:58:40.539 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 10:58:40.627 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 10:58:40.648 ServerApp] Uncaught exception GET /api/nbconvert?1733968720538 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733968720538', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 10:58:40.649 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 10:58:40.650 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/Untitled.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 10:58:40.650 ServerApp] 500 GET /api/nbconvert?1733968720538 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 88.97ms referer=http://13.208.159.5:8906/notebooks/Untitled.ipynb
[I 2024-12-12 10:58:40.707 ServerApp] Starting buffering for 7a331094-526a-477c-a0f2-1c9177ed2c13:cb963294-9b29-472b-8f0f-c005b16bf7c6
[I 2024-12-12 10:58:40.799 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 10:59:17.552 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 10:59:17.637 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 10:59:17.766 ServerApp] Uncaught exception GET /api/nbconvert?1733968757700 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733968757700', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 10:59:17.766 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 10:59:17.767 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/Untitled.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 10:59:17.767 ServerApp] 500 GET /api/nbconvert?1733968757700 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 58.39ms referer=http://13.208.159.5:8906/notebooks/Untitled.ipynb
[I 2024-12-12 10:59:18.395 ServerApp] Starting buffering for 7a331094-526a-477c-a0f2-1c9177ed2c13:ad9d6913-dc15-4a7a-9665-872a783e1c16
[I 2024-12-12 10:59:18.543 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
24/12/12 10:59:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [W 2024-12-12 11:00:41.574 ServerApp] 404 GET /api/contents/Untitled.ipynb?content=0&hash=1&1733968841448 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 1.28ms referer=http://13.208.159.5:8906/notebooks/Untitled.ipynb
[W 2024-12-12 11:00:41.575 ServerApp] 404 GET /api/contents/Untitled.ipynb?content=0&hash=1&1733968841448 (114.203.150.38): No such file or directory: Untitled.ipynb
[I 2024-12-12 11:00:41.614 ServerApp] Uploading file to /Untitled.ipynb
[I 2024-12-12 11:01:47.427 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 11:09:23.247 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 11:09:23.328 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 11:09:23.352 ServerApp] Starting buffering for 7a331094-526a-477c-a0f2-1c9177ed2c13:5d57c930-c4e9-4317-af27-a11c9823964a
[E 2024-12-12 11:09:25.994 ServerApp] Uncaught exception GET /api/nbconvert?1733969365930 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733969365930', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 11:09:25.994 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 11:09:25.994 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 11:09:25.994 ServerApp] 500 GET /api/nbconvert?1733969365930 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 53.29ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-12 11:09:26.623 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 11:09:26.712 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 11:09:26.721 ServerApp] Uncaught exception GET /api/nbconvert?1733969366624 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733969366624', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 11:09:26.721 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 11:09:26.722 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 11:09:26.722 ServerApp] 500 GET /api/nbconvert?1733969366624 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 84.81ms referer=http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb
[I 2024-12-12 11:09:26.904 ServerApp] Starting buffering for 7a331094-526a-477c-a0f2-1c9177ed2c13:54545f75-930e-4774-a7ec-a6698dab1736
[I 2024-12-12 11:09:26.974 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 11:09:33.938 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 11:09:34.031 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 11:09:34.043 ServerApp] Uncaught exception GET /api/nbconvert?1733969373920 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733969373920', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 11:09:34.043 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 11:09:34.043 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 11:09:34.044 ServerApp] 500 GET /api/nbconvert?1733969373920 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 103.03ms referer=http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 11:09:34.050 ServerApp] Starting buffering for 7a331094-526a-477c-a0f2-1c9177ed2c13:fd7703a6-e1cf-430b-8b4e-a2a9847201be
[I 2024-12-12 11:09:34.403 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 11:29:56.792 ServerApp] 302 GET / (@221.155.17.253) 0.85ms
[I 2024-12-12 11:29:58.582 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 11:29:58.653 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 11:30:06.159 ServerApp] Uncaught exception GET /api/nbconvert?1733970605754 (221.155.17.253)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733970605754', version='HTTP/1.1', remote_ip='221.155.17.253')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 11:30:06.159 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 11:30:06.159 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 11:30:06.159 ServerApp] 500 GET /api/nbconvert?1733970605754 (d32360df1bf04e038cfede77c3a772c0@221.155.17.253) 55.44ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-12 11:30:06.844 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 11:30:06.951 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 11:30:06.956 ServerApp] Uncaught exception GET /api/nbconvert?1733970606542 (221.155.17.253)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733970606542', version='HTTP/1.1', remote_ip='221.155.17.253')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 11:30:06.956 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 11:30:06.957 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 11:30:06.957 ServerApp] 500 GET /api/nbconvert?1733970606542 (d32360df1bf04e038cfede77c3a772c0@221.155.17.253) 65.01ms referer=http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 11:30:07.371 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 11:34:00.524 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[E 2024-12-12 11:34:00.585 ServerApp] Uncaught exception GET /api/nbconvert?1733970840480 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733970840480', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 11:34:00.585 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 11:34:00.586 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 11:34:00.586 ServerApp] 500 GET /api/nbconvert?1733970840480 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 50.38ms referer=http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb
[I 2024-12-12 11:34:00.745 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 11:34:00.884 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 11:47:48.021 ServerApp] Starting buffering for 7a331094-526a-477c-a0f2-1c9177ed2c13:68e2ddc4-2620-40ec-b867-3d6e91559505
[I 2024-12-12 11:47:48.072 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 11:47:48.182 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 11:47:48.182 ServerApp] Restoring connection for 7a331094-526a-477c-a0f2-1c9177ed2c13:68e2ddc4-2620-40ec-b867-3d6e91559505
[I 2024-12-12 13:13:17.942 ServerApp] 302 GET / (@118.219.28.24) 0.40ms
[I 2024-12-12 13:13:18.182 ServerApp] 302 GET / (@180.224.156.167) 0.27ms
[I 2024-12-12 13:13:18.221 JupyterNotebookApp] 302 GET /tree? (@180.224.156.167) 0.35ms
[I 2024-12-12 13:13:20.584 ServerApp] 302 GET / (@175.118.53.87) 0.26ms
[I 2024-12-12 13:13:24.308 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:13:24.420 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[W 2024-12-12 13:13:26.749 ServerApp] 401 POST /login?next=%2Ftree%3F (@180.224.156.167) 87.78ms referer=http://13.208.159.5:8906/login?next=%2Ftree%3F
[I 2024-12-12 13:13:29.924 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:13:30.029 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 13:13:31.913 ServerApp] Uncaught exception GET /api/nbconvert?1733976811856 (175.118.53.87)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733976811856', version='HTTP/1.1', remote_ip='175.118.53.87')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 13:13:31.914 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 13:13:31.915 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 13:13:31.915 ServerApp] 500 GET /api/nbconvert?1733976811856 (dd66125f18534f2abdad1e1cfae26b48@175.118.53.87) 41.63ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-12 13:13:33.236 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[W 2024-12-12 13:13:33.341 ServerApp] 401 POST /login?next=%2Ftree%3F (@180.224.156.167) 67.05ms referer=http://13.208.159.5:8906/login?next=%2Ftree%3F
[I 2024-12-12 13:13:33.344 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 13:13:33.417 ServerApp] Uncaught exception GET /api/nbconvert?1733976813325 (175.118.53.87)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733976813325', version='HTTP/1.1', remote_ip='175.118.53.87')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 13:13:33.418 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 13:13:33.419 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 13:13:33.419 ServerApp] 500 GET /api/nbconvert?1733976813325 (dd66125f18534f2abdad1e1cfae26b48@175.118.53.87) 75.31ms referer=http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 13:13:34.083 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:13:40.394 ServerApp] User 7ffaf1472f9a49828db979327a9c5a1b logged in.
[I 2024-12-12 13:13:40.394 ServerApp] 302 POST /login?next=%2Ftree%3F (7ffaf1472f9a49828db979327a9c5a1b@180.224.156.167) 64.35ms
[I 2024-12-12 13:13:41.792 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:13:41.874 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 13:13:45.249 ServerApp] Uncaught exception GET /api/nbconvert?1733976824647 (180.224.156.167)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733976824647', version='HTTP/1.1', remote_ip='180.224.156.167')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 13:13:45.249 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 13:13:45.250 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 13:13:45.250 ServerApp] 500 GET /api/nbconvert?1733976824647 (7ffaf1472f9a49828db979327a9c5a1b@180.224.156.167) 54.81ms referer=http://13.208.159.5:8906/tree?
[E 2024-12-12 13:13:45.652 ServerApp] Uncaught exception GET /api/nbconvert?1733976825286 (118.219.28.24)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733976825286', version='HTTP/1.1', remote_ip='118.219.28.24')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 13:13:45.652 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 13:13:45.652 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 13:13:45.652 ServerApp] 500 GET /api/nbconvert?1733976825286 (0636b224d94241ebbf2e1d519a4d962a@118.219.28.24) 142.74ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-12 13:13:45.971 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:13:46.070 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 13:13:46.080 ServerApp] Uncaught exception GET /api/nbconvert?1733976825447 (180.224.156.167)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733976825447', version='HTTP/1.1', remote_ip='180.224.156.167')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 13:13:46.083 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 13:13:46.085 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 13:13:46.085 ServerApp] 500 GET /api/nbconvert?1733976825447 (7ffaf1472f9a49828db979327a9c5a1b@180.224.156.167) 83.17ms referer=http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb
[I 2024-12-12 13:13:46.229 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:13:46.347 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 13:13:46.370 ServerApp] Uncaught exception GET /api/nbconvert?1733976826089 (118.219.28.24)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733976826089', version='HTTP/1.1', remote_ip='118.219.28.24')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 13:13:46.371 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 13:13:46.374 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 13:13:46.374 ServerApp] 500 GET /api/nbconvert?1733976826089 (0636b224d94241ebbf2e1d519a4d962a@118.219.28.24) 134.36ms referer=http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 13:13:46.376 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 13:13:46.813 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:13:49.689 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[E 2024-12-12 13:13:49.781 ServerApp] Uncaught exception GET /api/nbconvert?1733976829151 (180.224.156.167)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733976829151', version='HTTP/1.1', remote_ip='180.224.156.167')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 13:13:49.781 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 13:13:49.782 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 13:13:49.782 ServerApp] 500 GET /api/nbconvert?1733976829151 (7ffaf1472f9a49828db979327a9c5a1b@180.224.156.167) 78.03ms referer=http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 13:13:49.786 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 13:13:50.078 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:13:54.571 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[E 2024-12-12 13:13:54.669 ServerApp] Uncaught exception GET /api/nbconvert?1733976834022 (180.224.156.167)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733976834022', version='HTTP/1.1', remote_ip='180.224.156.167')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 13:13:54.669 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 13:13:54.670 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 13:13:54.670 ServerApp] 500 GET /api/nbconvert?1733976834022 (7ffaf1472f9a49828db979327a9c5a1b@180.224.156.167) 93.80ms referer=http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 13:13:54.672 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 13:13:54.936 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:14:53.461 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:14:53.552 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 13:14:54.029 ServerApp] Uncaught exception GET /api/nbconvert?1733976893984 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733976893984', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 13:14:54.029 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 13:14:54.030 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/Untitled.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 13:14:54.030 ServerApp] 500 GET /api/nbconvert?1733976893984 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 41.75ms referer=http://13.208.159.5:8906/notebooks/Untitled.ipynb
[I 2024-12-12 13:14:55.557 ServerApp] Kernel started: b59183b6-ba66-4df9-b49a-e6fa5f0b4fd2
[I 2024-12-12 13:14:55.998 ServerApp] Connecting to kernel b59183b6-ba66-4df9-b49a-e6fa5f0b4fd2.
[I 2024-12-12 13:14:57.207 ServerApp] Starting buffering for b59183b6-ba66-4df9-b49a-e6fa5f0b4fd2:7571fbef-c2a1-4e17-adc3-77469f6a5336
[I 2024-12-12 13:15:05.688 ServerApp] Kernel shutdown: b59183b6-ba66-4df9-b49a-e6fa5f0b4fd2
[W 2024-12-12 13:15:05.901 ServerApp] delete /Untitled.ipynb
[I 2024-12-12 13:15:13.736 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:15:13.840 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 13:15:14.347 ServerApp] Uncaught exception GET /api/nbconvert?1733976914289 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733976914289', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 13:15:14.347 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 13:15:14.348 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 13:15:14.348 ServerApp] 500 GET /api/nbconvert?1733976914289 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 43.00ms referer=http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 13:15:15.795 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:16:26.959 ServerApp] Malformed HTTP message from 1.236.236.172: Malformed HTTP version in HTTP Request-Line: 'úú\x13\x01\x13\x02\x13\x03À+À/À,À0Ì©Ì¨À\x13À\x14\x00\x9c\x00\x9d\x00/\x005\x01\x00\x063ÊÊ\x00\x00\x00\r\x00\x12\x00\x10\x04\x03\x08\x04\x04\x01\x05\x03\x08\x05\x05\x01\x08\x06\x06\x01Di\x00\x05\x00\x03\x02h2\x00\x1b\x00\x03\x02\x00\x02\x003\x04ï\x04í'
[I 2024-12-12 13:16:27.015 ServerApp] Malformed HTTP message from 1.236.236.172: no colon in header line
[I 2024-12-12 13:16:27.089 ServerApp] 302 GET / (@1.236.236.172) 0.29ms
[I 2024-12-12 13:16:27.243 ServerApp] 302 GET / (@1.236.236.172) 0.25ms
[I 2024-12-12 13:16:27.266 JupyterNotebookApp] 302 GET /tree? (@1.236.236.172) 0.35ms
[I 2024-12-12 13:16:34.689 ServerApp] User 041bd9cd5ce04e438781c26fd7b11100 logged in.
[I 2024-12-12 13:16:34.689 ServerApp] 302 POST /login?next=%2Ftree%3F (041bd9cd5ce04e438781c26fd7b11100@1.236.236.172) 67.94ms
[I 2024-12-12 13:16:35.908 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:16:36.015 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 13:16:40.857 ServerApp] Uncaught exception GET /api/nbconvert?1733977000376 (1.236.236.172)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733977000376', version='HTTP/1.1', remote_ip='1.236.236.172')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 13:16:40.858 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 13:16:40.858 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 13:16:40.858 ServerApp] 500 GET /api/nbconvert?1733977000376 (041bd9cd5ce04e438781c26fd7b11100@1.236.236.172) 52.82ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-12 13:16:41.477 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:16:41.528 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 13:16:41.613 ServerApp] Uncaught exception GET /api/nbconvert?1733977001104 (1.236.236.172)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733977001104', version='HTTP/1.1', remote_ip='1.236.236.172')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 13:16:41.614 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 13:16:41.614 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 13:16:41.614 ServerApp] 500 GET /api/nbconvert?1733977001104 (041bd9cd5ce04e438781c26fd7b11100@1.236.236.172) 80.79ms referer=http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb
[I 2024-12-12 13:16:41.830 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 13:17:36.184 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:17:36.265 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 13:17:36.554 ServerApp] Uncaught exception GET /api/nbconvert?1733977056514 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733977056514', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 13:17:36.555 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 13:17:36.555 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 13:17:36.555 ServerApp] 500 GET /api/nbconvert?1733977056514 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 41.50ms referer=http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb
[I 2024-12-12 13:17:37.961 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 13:17:49.309 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[E 2024-12-12 13:17:49.392 ServerApp] Uncaught exception GET /api/nbconvert?1733977068774 (180.224.156.167)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733977068774', version='HTTP/1.1', remote_ip='180.224.156.167')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 13:17:49.392 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 13:17:49.393 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 13:17:49.393 ServerApp] 500 GET /api/nbconvert?1733977068774 (7ffaf1472f9a49828db979327a9c5a1b@180.224.156.167) 62.69ms referer=http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 13:17:49.408 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 13:17:49.727 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:19:37.289 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 13:21:32.516 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:21:32.614 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 13:21:32.888 ServerApp] Uncaught exception GET /api/nbconvert?1733977292850 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733977292850', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 13:21:32.889 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 13:21:32.889 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 13:21:32.890 ServerApp] 500 GET /api/nbconvert?1733977292850 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 42.57ms referer=http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 13:21:35.167 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:21:38.740 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 13:23:39.510 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 13:25:39.682 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 13:27:39.858 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 13:29:40.013 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 13:31:40.203 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 13:33:40.371 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 13:39:40.853 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 13:44:41.368 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:44:41.469 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 13:44:41.480 ServerApp] Uncaught exception GET /api/nbconvert?1733978681207 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733978681207', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 13:44:41.480 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 13:44:41.480 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 13:44:41.480 ServerApp] 500 GET /api/nbconvert?1733978681207 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 92.00ms referer=http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb
[I 2024-12-12 13:44:41.768 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 13:44:47.191 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 13:44:47.288 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 13:44:47.298 ServerApp] Uncaught exception GET /api/nbconvert?1733978687030 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733978687030', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 13:44:47.299 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 13:44:47.300 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 13:44:47.300 ServerApp] 500 GET /api/nbconvert?1733978687030 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 92.52ms referer=http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb
[I 2024-12-12 13:44:47.690 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 13:47:41.032 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 13:49:41.233 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 14:09:41.448 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 14:11:41.610 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 14:13:41.793 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 14:15:41.977 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
24/12/12 14:16:16 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
24/12/12 14:16:16 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
[I 2024-12-12 14:17:42.161 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 14:19:42.317 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 14:21:42.460 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 14:27:42.626 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 14:29:42.768 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 14:33:42.954 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 14:35:43.279 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 14:37:43.457 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 14:39:43.627 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 14:43:43.787 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 14:45:43.946 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 14:47:44.107 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 14:47:51.598 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[E 2024-12-12 14:47:51.670 ServerApp] Uncaught exception GET /api/nbconvert?1733982471300 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733982471300', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 14:47:51.671 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 14:47:51.672 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 14:47:51.672 ServerApp] 500 GET /api/nbconvert?1733982471300 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 63.05ms referer=http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 14:47:51.825 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 14:47:52.090 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 14:47:55.497 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[E 2024-12-12 14:47:55.546 ServerApp] Uncaught exception GET /api/nbconvert?1733982475022 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733982475022', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 14:47:55.546 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 14:47:55.547 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 14:47:55.547 ServerApp] 500 GET /api/nbconvert?1733982475022 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 108.35ms referer=http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb
[I 2024-12-12 14:47:55.573 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 14:47:55.787 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 14:49:44.291 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 14:51:21.256 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 15:07:59.460 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 15:25:05.883 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 15:25:05.973 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 15:25:06.398 ServerApp] Uncaught exception GET /api/nbconvert?1733984706344 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733984706344', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 15:25:06.398 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 15:25:06.399 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 15:25:06.399 ServerApp] 500 GET /api/nbconvert?1733984706344 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 41.12ms referer=http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 15:25:08.417 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 15:26:41.581 ServerApp] 302 GET / (@1.236.236.172) 0.30ms
[I 2024-12-12 15:26:41.792 ServerApp] 302 GET / (@1.236.236.172) 0.27ms
[I 2024-12-12 15:26:42.784 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 15:26:42.898 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 15:26:43.426 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[E 2024-12-12 15:26:44.707 ServerApp] Uncaught exception GET /api/nbconvert?1733984804028 (1.236.236.172)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733984804028', version='HTTP/1.1', remote_ip='1.236.236.172')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 15:26:44.708 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 15:26:44.708 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/tree?",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 15:26:44.708 ServerApp] 500 GET /api/nbconvert?1733984804028 (041bd9cd5ce04e438781c26fd7b11100@1.236.236.172) 42.29ms referer=http://13.208.159.5:8906/tree?
[I 2024-12-12 15:26:45.233 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 15:26:45.343 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 15:26:45.355 ServerApp] Uncaught exception GET /api/nbconvert?1733984804653 (1.236.236.172)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733984804653', version='HTTP/1.1', remote_ip='1.236.236.172')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 15:26:45.355 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 15:26:45.356 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 15:26:45.356 ServerApp] 500 GET /api/nbconvert?1733984804653 (041bd9cd5ce04e438781c26fd7b11100@1.236.236.172) 65.40ms referer=http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb
[I 2024-12-12 15:26:45.797 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 15:26:51.432 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 15:26:51.518 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[E 2024-12-12 15:26:51.541 ServerApp] Uncaught exception GET /api/nbconvert?1733984811446 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733984811446', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 15:26:51.541 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 15:26:51.542 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 15:26:51.542 ServerApp] 500 GET /api/nbconvert?1733984811446 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 99.24ms referer=http://13.208.159.5:8906/notebooks/241212_01_MLlib_classification..ipynb
[I 2024-12-12 15:26:51.950 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 15:27:07.300 ServerApp] Saving file at /241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 15:44:55.636 ServerApp] Saving file at /241212_01_MLlib_classification..ipynb
[I 2024-12-12 15:46:37.665 ServerApp] Creating new notebook in 
[I 2024-12-12 15:46:38.252 ServerApp] Saving file at /Untitled.ipynb
[I 2024-12-12 15:46:38.347 ServerApp] Kernel started: ddcf9b4b-5f46-4193-a669-1bf2333e1b9b
[I 2024-12-12 15:46:38.804 ServerApp] Connecting to kernel ddcf9b4b-5f46-4193-a669-1bf2333e1b9b.
[I 2024-12-12 15:46:42.057 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 15:46:42.156 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 15:46:42.234 ServerApp] Connecting to kernel ddcf9b4b-5f46-4193-a669-1bf2333e1b9b.
[E 2024-12-12 15:46:42.711 ServerApp] Uncaught exception GET /api/nbconvert?1733986002649 (211.231.29.166)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733986002649', version='HTTP/1.1', remote_ip='211.231.29.166')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 15:46:42.712 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 15:46:42.712 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/Untitled.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 15:46:42.712 ServerApp] 500 GET /api/nbconvert?1733986002649 (0a40d701d720458c844179d0b37eb071@211.231.29.166) 41.44ms referer=http://13.208.159.5:8906/notebooks/Untitled.ipynb
[I 2024-12-12 15:46:44.485 ServerApp] Connecting to kernel ddcf9b4b-5f46-4193-a669-1bf2333e1b9b.
[I 2024-12-12 15:49:12.933 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 15:49:18.631 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[E 2024-12-12 15:49:18.656 ServerApp] Uncaught exception GET /api/nbconvert?1733986158536 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733986158536', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 15:49:18.656 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 15:49:18.657 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241212_01_MLlib_regression.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 15:49:18.657 ServerApp] 500 GET /api/nbconvert?1733986158536 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 97.95ms referer=http://13.208.159.5:8906/notebooks/241212_01_MLlib_regression.ipynb
[I 2024-12-12 15:49:18.721 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 15:49:18.800 ServerApp] Connecting to kernel ddcf9b4b-5f46-4193-a669-1bf2333e1b9b.
[I 2024-12-12 15:49:18.873 ServerApp] Connecting to kernel ddcf9b4b-5f46-4193-a669-1bf2333e1b9b.
24/12/12 15:51:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 2024-12-12 15:53:13.089 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 15:53:58.510 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 15:53:58.597 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 15:53:58.702 ServerApp] Connecting to kernel ddcf9b4b-5f46-4193-a669-1bf2333e1b9b.
[E 2024-12-12 15:53:58.769 ServerApp] Uncaught exception GET /api/nbconvert?1733986438686 (175.118.53.87)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733986438686', version='HTTP/1.1', remote_ip='175.118.53.87')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 15:53:58.769 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 15:53:58.770 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb",
      "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 15:53:58.770 ServerApp] 500 GET /api/nbconvert?1733986438686 (dd66125f18534f2abdad1e1cfae26b48@175.118.53.87) 73.24ms referer=http://13.208.159.5:8906/notebooks/241210_03_yellowtaxi_trip_count.ipynb
[I 2024-12-12 15:53:59.632 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 15:55:13.292 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 15:57:13.437 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 15:59:13.610 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 16:01:13.769 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 16:03:14.010 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 16:05:14.153 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 16:07:14.410 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 16:09:14.594 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 16:11:14.726 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 16:29:14.913 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 16:31:15.112 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 16:35:15.305 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 16:37:15.514 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 16:41:15.739 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 16:43:15.920 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[Stage 6:>                                                          (0 + 1) / 1]                                                                                [I 2024-12-12 16:45:16.083 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
24/12/12 16:48:15 WARN Instrumentation: [76dc05f6] regParam is zero, which might cause numerical instability and overfitting.
24/12/12 16:48:16 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
24/12/12 16:48:16 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
24/12/12 16:48:16 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
24/12/12 16:48:16 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
[I 2024-12-12 16:49:16.233 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 16:51:16.386 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 16:54:33.665 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[I 2024-12-12 16:54:33.767 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 16:54:33.993 ServerApp] Connecting to kernel ddcf9b4b-5f46-4193-a669-1bf2333e1b9b.
[I 2024-12-12 16:56:39.507 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 17:18:06.268 ServerApp] Saving file at /241212_01_MLlib_regression.ipynb
[I 2024-12-12 17:21:48.751 ServerApp] Connecting to kernel 7a331094-526a-477c-a0f2-1c9177ed2c13.
[E 2024-12-12 17:21:48.809 ServerApp] Uncaught exception GET /api/nbconvert?1733991708583 (114.203.150.38)
    HTTPServerRequest(protocol='http', host='13.208.159.5:8906', method='GET', uri='/api/nbconvert?1733991708583', version='HTTP/1.1', remote_ip='114.203.150.38')
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[W 2024-12-12 17:21:48.809 ServerApp] wrote error: 'Unhandled error'
    Traceback (most recent call last):
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/tornado/web.py", line 1790, in _execute
        result = await result
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/auth/decorator.py", line 73, in inner
        return await out
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_server/services/nbconvert/handlers.py", line 41, in get
        exporters = await run_sync(base.get_export_names)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/to_thread.py", line 56, in run_sync
        return await get_async_backend().run_sync_in_worker_thread(
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 2364, in run_sync_in_worker_thread
        return await future
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/anyio/_backends/_asyncio.py", line 864, in run
        result = context.run(func, *args)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 145, in get_export_names
        e = get_exporter(exporter_name)(config=config)
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/nbconvert/exporters/base.py", line 106, in get_exporter
        exporter = items[0].load()
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 189, in load
        module = import_module(match.group('module'))
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
      File "<frozen importlib._bootstrap>", line 991, in _find_and_load
      File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
      File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
      File "<frozen importlib._bootstrap_external>", line 843, in exec_module
      File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/__init__.py", line 5, in <module>
        from .collapsible_headings import ExporterCollapsibleHeadings
      File "/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/jupyter_contrib_nbextensions/nbconvert_support/collapsible_headings.py", line 6, in <module>
        from notebook.services.config import ConfigManager
    ModuleNotFoundError: No module named 'notebook.services'
[E 2024-12-12 17:21:48.810 ServerApp] {
      "Host": "13.208.159.5:8906",
      "Accept": "*/*",
      "Referer": "http://13.208.159.5:8906/notebooks/241212_01_MLlib_regression.ipynb",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    }
[E 2024-12-12 17:21:48.810 ServerApp] 500 GET /api/nbconvert?1733991708583 (cea5bd43a10c44ee82476a55702a86ed@114.203.150.38) 131.76ms referer=http://13.208.159.5:8906/notebooks/241212_01_MLlib_regression.ipynb
[I 2024-12-12 17:21:48.831 ServerApp] Connecting to kernel 36e813aa-b4e2-4a73-8abc-741981e31fb7.
[I 2024-12-12 17:21:48.919 ServerApp] Connecting to kernel ddcf9b4b-5f46-4193-a669-1bf2333e1b9b.
[I 2024-12-12 17:21:49.002 ServerApp] Connecting to kernel ddcf9b4b-5f46-4193-a669-1bf2333e1b9b.
