{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd220a1-b84b-49ec-8296-2434b49be8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/12 08:54:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"24121003_yellowtaxi_trip_count\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc59635-6d32-4c23-8a91-8eaf94c94e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "trip_files = '/trips/*'\n",
    "zone_file = 'taxi+_zone_lookup.csv'\n",
    "directory = os.path.join(os.getcwd(), 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "028366ed-43c8-47f9-9e64-ae4ea9213e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "trips_df = spark.read.csv(f'file:///{directory}/{trip_files}', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "366c571f-ed44-4c96-bfd5-bb372a3a2a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_df = spark.read.csv(f'file:///{directory}/{zone_file}', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73f02b1f-ee42-463d-968b-6383e21dae78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf40815-a912-431a-b84a-0bf387fb7cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zone_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2461645a-848d-49fd-bd22-96c876e5a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.createOrReplaceTempView('trips')\n",
    "zone_df.createOrReplaceTempView('zone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59a241de-b9ac-4b32-89c5-3016c6fb98f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "select\n",
    "t.VendorID,\n",
    "TO_DATE(t.tpep_pickup_datetime) as pickup_date,\n",
    "TO_DATE(t.tpep_dropoff_datetime) as dropoff_date,\n",
    "HOUR(t.tpep_pickup_datetime)  as pickup_time,\n",
    "HOUR(t.tpep_dropoff_datetime) as dropoff_time,\n",
    "t.passenger_count,\n",
    "t.trip_distance,\n",
    "t.tip_amount,\n",
    "t.total_amount,\n",
    "t.payment_type,\n",
    "pz.Zone as pickup_zone,\n",
    "dz.Zone as dropoff_zone\n",
    "from trips t\n",
    "LEFT JOIN zone pz ON t.PULocationID = pz.LocationID\n",
    "LEFT JOIN zone dz ON t.DOLocationID = dz.LocationID\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1150270f-c54e-4fef-99f6-232b8d418ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1d12f58-a343-4c74-8ea3-0d61c1e31107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "15000700"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02ea24c9-b019-47a8-a071-d95e4073881c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------------+-----------+------------+---------------+-------------+----------+------------+------------+-----------------+--------------+\n",
      "|VendorID|pickup_date|dropoff_date|pickup_time|dropoff_time|passenger_count|trip_distance|tip_amount|total_amount|payment_type|      pickup_zone|  dropoff_zone|\n",
      "+--------+-----------+------------+-----------+------------+---------------+-------------+----------+------------+------------+-----------------+--------------+\n",
      "|       2| 2021-03-01|  2021-03-01|          0|           0|              1|          0.0|       0.0|         4.3|           2|               NV|            NV|\n",
      "|       2| 2021-03-01|  2021-03-01|          0|           0|              1|          0.0|       0.0|         3.8|           2|   Manhattanville|Manhattanville|\n",
      "|       2| 2021-03-01|  2021-03-01|          0|           0|              1|          0.0|       0.0|         4.8|           2|   Manhattanville|Manhattanville|\n",
      "|       1| 2021-03-01|  2021-03-01|          0|           0|              0|         16.5|     11.65|       70.07|           1|LaGuardia Airport|            NA|\n",
      "|       2| 2021-03-01|  2021-03-01|          0|           0|              1|         1.13|      1.86|       11.16|           1|     East Chelsea|            NV|\n",
      "+--------+-----------+------------+-----------+------------+---------------+-------------+----------+------------+------------+-----------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comb_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02c85c25-0fe1-4ca6-b23f-f31dd8875742",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df.createOrReplaceTempView('comb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12608a13-efc8-47d0-89a2-d8424dce536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "select pickup_date, pickup_time \n",
    "from comb \n",
    "where pickup_time>0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1796b96-edb3-40e2-8efd-5acabf85a181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|pickup_date|pickup_time|\n",
      "+-----------+-----------+\n",
      "| 2021-02-28|         23|\n",
      "| 2021-02-28|         23|\n",
      "| 2021-02-28|         23|\n",
      "| 2021-02-28|         23|\n",
      "| 2021-02-28|         23|\n",
      "| 2021-02-28|         23|\n",
      "| 2021-02-28|         23|\n",
      "| 2021-03-01|         22|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5df1ab94-42d3-48ca-9ec5-8d7b58bcc3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:=============================>                            (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|pickup_date|pickup_time|\n",
      "+-----------+-----------+\n",
      "| 2009-01-01|          0|\n",
      "| 2008-12-31|         23|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          1|\n",
      "| 2009-01-01|          0|\n",
      "| 2008-12-31|         23|\n",
      "| 2008-12-31|         23|\n",
      "| 2008-12-31|         23|\n",
      "| 2008-12-31|         23|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|         16|\n",
      "| 2009-01-01|         16|\n",
      "| 2009-01-01|          0|\n",
      "| 2009-01-01|          0|\n",
      "+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select pickup_date, pickup_time \n",
    "from comb \n",
    "where pickup_date<'2020-12-31'\n",
    "'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "098f75f7-3ddf-4d40-9666-83826813799d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, VendorID: string, pickup_time: string, dropoff_time: string, passenger_count: string, trip_distance: string, tip_amount: string, total_amount: string, payment_type: string, pickup_zone: string, dropoff_zone: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b0078e5-b9cc-476d-b8ca-b5d6f6d6f2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Project [cast(tpep_pickup_datetime#17 as date) AS pickup_date#76, hour(cast(tpep_pickup_datetime#17 as timestamp), Some(Asia/Seoul)) AS pickup_time#78]\n",
      "+- *(3) BroadcastHashJoin [DOLocationID#24], [LocationID#82], LeftOuter, BuildRight, false\n",
      "   :- *(3) Project [tpep_pickup_datetime#17, DOLocationID#24]\n",
      "   :  +- *(3) BroadcastHashJoin [PULocationID#23], [LocationID#68], LeftOuter, BuildRight, false\n",
      "   :     :- *(3) Filter (isnotnull(tpep_pickup_datetime#17) AND (cast(tpep_pickup_datetime#17 as date) < 18627))\n",
      "   :     :  +- FileScan csv [tpep_pickup_datetime#17,PULocationID#23,DOLocationID#24] Batched: false, DataFilters: [isnotnull(tpep_pickup_datetime#17), (cast(tpep_pickup_datetime#17 as date) < 18627)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab06/src/DA-learning-course/Spark/data/trips/yellow_tripdata_2021-0..., PartitionFilters: [], PushedFilters: [IsNotNull(tpep_pickup_datetime)], ReadSchema: struct<tpep_pickup_datetime:string,PULocationID:int,DOLocationID:int>\n",
      "   :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#570]\n",
      "   :        +- *(1) Filter isnotnull(LocationID#68)\n",
      "   :           +- FileScan csv [LocationID#68] Batched: false, DataFilters: [isnotnull(LocationID#68)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab06/src/DA-learning-course/Spark/data/taxi+_zone_lookup.csv], PartitionFilters: [], PushedFilters: [IsNotNull(LocationID)], ReadSchema: struct<LocationID:int>\n",
      "   +- ReusedExchange [LocationID#82], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#570]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b93861b4-e1a1-4e03-abf5-bf03ebf8a853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|pickup_date|pickup_time|\n",
      "+-----------+-----------+\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "| 2021-03-01|          1|\n",
      "+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#실행계획, 실행결과(4040)\n",
    "\n",
    "query2 = '''\n",
    "select pickup_date, pickup_time \n",
    "from comb \n",
    "where pickup_time > 0 and pickup_time<=12\n",
    "'''\n",
    "spark.sql(query2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a68330f-e89a-469b-9274-0df19d36ec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:=================================================>    (185 + 2) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|pickup_date|pickup_time|\n",
      "+-----------+-----------+\n",
      "| 2002-12-31|         23|\n",
      "| 2003-01-05|          7|\n",
      "| 2004-04-04|          4|\n",
      "| 2008-12-31|         22|\n",
      "| 2008-12-31|         23|\n",
      "| 2009-01-01|          5|\n",
      "| 2009-01-01|         20|\n",
      "| 2009-01-01|         11|\n",
      "| 2009-01-01|          1|\n",
      "| 2009-01-01|         19|\n",
      "| 2009-01-01|         17|\n",
      "| 2009-01-01|         18|\n",
      "| 2009-01-01|         23|\n",
      "| 2009-01-01|          4|\n",
      "| 2009-01-01|          3|\n",
      "| 2009-01-01|         21|\n",
      "| 2009-01-01|         12|\n",
      "| 2009-01-01|         16|\n",
      "| 2009-01-01|          2|\n",
      "| 2009-01-01|         10|\n",
      "+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "query3 = '''\n",
    "select pickup_date, pickup_time \n",
    "from comb \n",
    "where pickup_time > 0\n",
    "group by pickup_date, pickup_time\n",
    "order by pickup_date\n",
    "'''\n",
    "spark.sql(query3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf84f66-5976-41bc-9c96-b5425d77b16b",
   "metadata": {},
   "source": [
    "# 실습 과제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac9a38a4-25c2-43ae-994e-e0940e188010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc4a9ab-7992-42e8-98d4-4d147538784a",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c630539-2a1e-4b95-ad7b-7f620cb73272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-----------+----------+\n",
      "|payment_type|total_amount|fare_amount|tip_amount|\n",
      "+------------+------------+-----------+----------+\n",
      "|           3|       -15.3|      -15.0|       0.0|\n",
      "|           4|        -6.3|       -2.5|       0.0|\n",
      "|           4|       -11.3|       -7.5|       0.0|\n",
      "|           2|       -30.3|      -26.5|       0.0|\n",
      "|           3|        -6.8|       -3.0|       0.0|\n",
      "|           4|       -11.3|       -7.5|       0.0|\n",
      "|           3|        -6.3|       -2.5|       0.0|\n",
      "|           4|        -3.8|       -2.5|       0.0|\n",
      "|           3|        -6.3|       -2.5|       0.0|\n",
      "|           4|       -35.8|      -32.0|       0.0|\n",
      "|           4|        -6.8|       -3.5|       0.0|\n",
      "|           3|        -6.8|       -3.5|       0.0|\n",
      "|           4|        -5.8|       -2.5|       0.0|\n",
      "|           4|       -14.3|      -11.0|       0.0|\n",
      "|           2|       -12.3|       -9.0|       0.0|\n",
      "|           4|       -14.3|      -11.0|       0.0|\n",
      "|           4|        -5.8|       -2.5|       0.0|\n",
      "|           3|       -15.3|      -12.0|       0.0|\n",
      "|           3|        -3.3|       -2.5|       0.0|\n",
      "|           3|       -17.8|      -14.5|       0.0|\n",
      "+------------+------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 음수 요금 값을 가진 레코드 필터링\n",
    "negative_fare_df = trips_df.filter(col(\"total_amount\") < 0).select(\"payment_type\", \"total_amount\", \"fare_amount\", \"tip_amount\")\n",
    "\n",
    "# 결과 출력\n",
    "negative_fare_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfdd8768-ced7-4004-b14b-2458cac0d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, avg, count, round, hour\n",
    "\n",
    "# 1. 음수 요금 제거\n",
    "trips_df = trips_df.filter(col(\"total_amount\") >= 0)\n",
    "\n",
    "# 2. 비정상적인 거리 데이터 제거\n",
    "trips_df = trips_df.filter((col(\"trip_distance\") >= 0) & (col(\"trip_distance\") <= 100))\n",
    "\n",
    "# 3. 요금이 비정상적으로 높은 경우 제거\n",
    "trips_df = trips_df.filter((col(\"total_amount\") / col(\"trip_distance\")) <= 100)\n",
    "\n",
    "# 4. 결측치 제거\n",
    "trips_df = trips_df.na.drop()\n",
    "\n",
    "# 5. 거리 구간화\n",
    "trips_df = trips_df.withColumn(\n",
    "    \"distance_bin\",\n",
    "    when(col(\"trip_distance\") < 3, \"0-3 km\")\n",
    "    .when((col(\"trip_distance\") >= 3) & (col(\"trip_distance\") < 6), \"3-6 km\")\n",
    "    .when((col(\"trip_distance\") >= 6) & (col(\"trip_distance\") < 9), \"6-9 km\")\n",
    "    .when((col(\"trip_distance\") >= 9) & (col(\"trip_distance\") < 12), \"9-12 km\")\n",
    "    .when((col(\"trip_distance\") >= 12) & (col(\"trip_distance\") < 15), \"12-15 km\")\n",
    "    .when((col(\"trip_distance\") >= 15) & (col(\"trip_distance\") < 18), \"15-18 km\")\n",
    "    .when((col(\"trip_distance\") >= 18) & (col(\"trip_distance\") < 21), \"18-21 km\")\n",
    "    .when((col(\"trip_distance\") >= 21) & (col(\"trip_distance\") < 24), \"21-24 km\")\n",
    "    .when((col(\"trip_distance\") >= 24) & (col(\"trip_distance\") < 27), \"24-27 km\")\n",
    "    .when((col(\"trip_distance\") >= 27) & (col(\"trip_distance\") < 30), \"27-30 km\")\n",
    "    .otherwise(\"30+ km\")\n",
    ")\n",
    "\n",
    "# 6. 시간대 구분\n",
    "trips_df = trips_df.withColumn(\"pickup_hour\", hour(col(\"tpep_pickup_datetime\")))\n",
    "\n",
    "# View 생성 및 쿼리\n",
    "trips_df.createOrReplaceTempView('trips')\n",
    "zone_df.createOrReplaceTempView('zone')\n",
    "\n",
    "query = '''\n",
    "SELECT\n",
    "  t.VendorID,\n",
    "  TO_DATE(t.tpep_pickup_datetime) AS pickup_date,\n",
    "  TO_DATE(t.tpep_dropoff_datetime) AS dropoff_date,\n",
    "  HOUR(t.tpep_pickup_datetime) AS pickup_time,\n",
    "  HOUR(t.tpep_dropoff_datetime) AS dropoff_time,\n",
    "  t.passenger_count,\n",
    "  t.trip_distance,\n",
    "  t.tip_amount,\n",
    "  t.total_amount,\n",
    "  t.payment_type,\n",
    "  pz.Zone AS pickup_zone,\n",
    "  dz.Zone AS dropoff_zone,\n",
    "  t.distance_bin\n",
    "FROM trips t\n",
    "LEFT JOIN zone pz ON t.PULocationID = pz.LocationID\n",
    "LEFT JOIN zone dz ON t.DOLocationID = dz.LocationID\n",
    "'''\n",
    "comb_df = spark.sql(query)\n",
    "comb_df.createOrReplaceTempView('comb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b8aff6-5659-4ae3-99b9-fd74ad705f93",
   "metadata": {},
   "source": [
    "## 1. 운행 거리와 요금의 상관관계 분석\n",
    "> 쿼리작성, 데이터프레임으로도 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b327f66b-71f0-434d-840a-f5f49b035e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:======================================>               (144 + 2) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+---------+\n",
      "|distance_bin|avg_fare|num_trips|\n",
      "+------------+--------+---------+\n",
      "|      0-3 km|   13.07| 10347228|\n",
      "|      3-6 km|   22.56|  2172487|\n",
      "|      6-9 km|   33.06|   558129|\n",
      "|     9-12 km|   43.65|   319466|\n",
      "|    12-15 km|   51.22|   120130|\n",
      "|    15-18 km|   65.66|   150925|\n",
      "|    18-21 km|   70.26|   161403|\n",
      "|    21-24 km|    74.5|    34754|\n",
      "|    24-27 km|   87.43|     9797|\n",
      "|    27-30 km|   96.18|     5564|\n",
      "|      30+ km|  129.01|    10866|\n",
      "+------------+--------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 쿼리\n",
    "distance_fare_query = '''\n",
    "SELECT \n",
    "  distance_bin,\n",
    "  ROUND(AVG(total_amount), 2) AS avg_fare,\n",
    "  COUNT(total_amount) AS num_trips\n",
    "FROM comb\n",
    "GROUP BY distance_bin\n",
    "ORDER BY \n",
    "  CASE \n",
    "    WHEN distance_bin = '0-3 km' THEN 1\n",
    "    WHEN distance_bin = '3-6 km' THEN 2\n",
    "    WHEN distance_bin = '6-9 km' THEN 3\n",
    "    WHEN distance_bin = '9-12 km' THEN 4\n",
    "    WHEN distance_bin = '12-15 km' THEN 5\n",
    "    WHEN distance_bin = '15-18 km' THEN 6\n",
    "    WHEN distance_bin = '18-21 km' THEN 7\n",
    "    WHEN distance_bin = '21-24 km' THEN 8\n",
    "    WHEN distance_bin = '24-27 km' THEN 9\n",
    "    WHEN distance_bin = '27-30 km' THEN 10\n",
    "    ELSE 11\n",
    "  END;\n",
    "'''\n",
    "distance_fare_grouped_df = spark.sql(distance_fare_query)\n",
    "distance_fare_grouped_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa06d330-cfbf-44a0-8f91-e24f23e2dea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:==========================================>           (158 + 2) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+---------+\n",
      "|distance_bin|avg_fare|num_trips|\n",
      "+------------+--------+---------+\n",
      "|      0-3 km|   13.07| 10347228|\n",
      "|      3-6 km|   22.56|  2172487|\n",
      "|      6-9 km|   33.06|   558129|\n",
      "|     9-12 km|   43.65|   319466|\n",
      "|    12-15 km|   51.22|   120130|\n",
      "|    15-18 km|   65.66|   150925|\n",
      "|    18-21 km|   70.26|   161403|\n",
      "|    21-24 km|    74.5|    34754|\n",
      "|    24-27 km|   87.43|     9797|\n",
      "|    27-30 km|   96.18|     5564|\n",
      "|      30+ km|  129.01|    10866|\n",
      "+------------+--------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 데이터프레임\n",
    "\n",
    "# 각 거리 구간별 평균 요금 계산 및 정렬\n",
    "distance_fare_grouped_df = comb_df.groupBy(\"distance_bin\").agg(\n",
    "    round(avg(\"total_amount\"), 2).alias(\"avg_fare\"),\n",
    "    count(\"total_amount\").alias(\"num_trips\")\n",
    ").orderBy(\n",
    "    when(col(\"distance_bin\") == '0-3 km', 1)\n",
    "    .when(col(\"distance_bin\") == '3-6 km', 2)\n",
    "    .when(col(\"distance_bin\") == '6-9 km', 3)\n",
    "    .when(col(\"distance_bin\") == '9-12 km', 4)\n",
    "    .when(col(\"distance_bin\") == '12-15 km', 5)\n",
    "    .when(col(\"distance_bin\") == '15-18 km', 6)\n",
    "    .when(col(\"distance_bin\") == '18-21 km', 7)\n",
    "    .when(col(\"distance_bin\") == '21-24 km', 8)\n",
    "    .when(col(\"distance_bin\") == '24-27 km', 9)\n",
    "    .when(col(\"distance_bin\") == '27-30 km', 10)\n",
    "    .otherwise(11)\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "distance_fare_grouped_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "136061f3-66c8-4e6c-81c4-4a5f29aacba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:==================================================>     (10 + 1) / 11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "운행 거리와 요금의 상관 계수: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 운행 거리와 요금의 상관 계수 계산\n",
    "correlation = comb_df.select(\"trip_distance\", \"total_amount\").stat.corr(\"trip_distance\", \"total_amount\")\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"운행 거리와 요금의 상관 계수: {correlation:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2759ecb-c836-4cb7-b6ea-4ce40fac10be",
   "metadata": {},
   "source": [
    "> 결과 분석\n",
    "\n",
    "### 전체 결과\n",
    "- 30+ km 구간의 평균 요금이 가장 높으며, \\$129.01임.  \n",
    "- 0-3 km 구간의 평균 요금이 가장 낮으며, \\$13.07임.  \n",
    "- 0-3 km 구간에서 가장 많은 운행이 이루어졌으며, 10,347,228건임.  \n",
    "- 30+ km 구간에서 가장 적은 운행이 이루어졌으며, 10,866건임.  \n",
    "\n",
    "### 결론\n",
    "- **장거리 운행**: 평균 요금이 높고 운행 횟수는 적음.\n",
    "- **단거리 운행**: 평균 요금이 낮고 운행 횟수는 많음.\n",
    "- **중간 거리 구간**: 요금과 운행 횟수가 점진적으로 변화함.\n",
    "\n",
    "### 인사이트\n",
    "- 운행 거리가 증가함에 따라 요금도 비례적으로 증가하는 경향을 보임.\n",
    "- 대부분의 운행은 짧은 거리(0-3 km) 구간에서 이루어지며, 그 다음으로는 3-6 km 구간이 많음.\n",
    "- 장거리 구간에서는 운행 횟수가 상대적으로 적지만, 평균 요금이 훨씬 높음.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd47495-7cc7-47ef-8eb9-cf2b3f79fd3b",
   "metadata": {},
   "source": [
    "# 2. 피크 시간대 요금 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53ec919b-83d0-4fa4-a658-6825d368e5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:==================================>                   (129 + 2) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---------+\n",
      "|hour|avg_fare|num_trips|\n",
      "+----+--------+---------+\n",
      "|   0|   21.03|   252406|\n",
      "|   1|   20.37|   147940|\n",
      "|   2|   19.77|    88174|\n",
      "|   3|   19.95|    50557|\n",
      "|   4|   22.64|    33862|\n",
      "|   5|   24.19|    64658|\n",
      "|   6|   19.63|   210817|\n",
      "|   7|   17.53|   394091|\n",
      "|   8|   16.71|   583266|\n",
      "|   9|   16.58|   650890|\n",
      "|  10|   16.61|   727994|\n",
      "|  11|   16.58|   806514|\n",
      "|  12|    16.7|   893464|\n",
      "|  13|   16.92|   923919|\n",
      "|  14|   17.45|  1007120|\n",
      "|  15|   17.89|  1017848|\n",
      "|  16|   18.96|   972418|\n",
      "|  17|   18.65|  1016672|\n",
      "|  18|    18.1|  1025067|\n",
      "|  19|   17.94|   865410|\n",
      "|  20|   18.13|   664606|\n",
      "|  21|   18.87|   584488|\n",
      "|  22|   19.56|   513630|\n",
      "|  23|   20.43|   394938|\n",
      "+----+--------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 쿼리\n",
    "peak_hours_query = '''\n",
    "SELECT \n",
    "  pickup_time AS hour,\n",
    "  ROUND(AVG(total_amount), 2) AS avg_fare,\n",
    "  COUNT(total_amount) AS num_trips\n",
    "FROM comb\n",
    "GROUP BY pickup_time\n",
    "ORDER BY hour;\n",
    "'''\n",
    "peak_hours_df = spark.sql(peak_hours_query)\n",
    "peak_hours_df.show(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c73244f-77e6-4355-9916-8203c82ec0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:=============================================>        (167 + 2) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---------+\n",
      "|pickup_time|avg_fare|num_trips|\n",
      "+-----------+--------+---------+\n",
      "|          0|   21.03|   252406|\n",
      "|          1|   20.37|   147940|\n",
      "|          2|   19.77|    88174|\n",
      "|          3|   19.95|    50557|\n",
      "|          4|   22.64|    33862|\n",
      "|          5|   24.19|    64658|\n",
      "|          6|   19.63|   210817|\n",
      "|          7|   17.53|   394091|\n",
      "|          8|   16.71|   583266|\n",
      "|          9|   16.58|   650890|\n",
      "|         10|   16.61|   727994|\n",
      "|         11|   16.58|   806514|\n",
      "|         12|    16.7|   893464|\n",
      "|         13|   16.92|   923919|\n",
      "|         14|   17.45|  1007120|\n",
      "|         15|   17.89|  1017848|\n",
      "|         16|   18.96|   972418|\n",
      "|         17|   18.65|  1016672|\n",
      "|         18|    18.1|  1025067|\n",
      "|         19|   17.94|   865410|\n",
      "|         20|   18.13|   664606|\n",
      "|         21|   18.87|   584488|\n",
      "|         22|   19.56|   513630|\n",
      "|         23|   20.43|   394938|\n",
      "+-----------+--------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 데이터프레임\n",
    "\n",
    "# 피크 시간대별 평균 요금 계산 및 운행 횟수 집계\n",
    "peak_hours_df = comb_df.groupBy(\"pickup_time\").agg(\n",
    "    round(avg(\"total_amount\"), 2).alias(\"avg_fare\"),\n",
    "    count(\"total_amount\").alias(\"num_trips\")\n",
    ").orderBy(\"pickup_time\")\n",
    "\n",
    "# 결과 출력\n",
    "peak_hours_df.show(24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb331d67-0985-4385-90e3-1df869b05fc9",
   "metadata": {},
   "source": [
    "> 결과 분석\n",
    "\n",
    "### 전체 결과\n",
    "- **평균 요금이 가장 높은 시간대**: 5시, 평균 요금 \\$24.19임.\n",
    "- **평균 요금이 가장 낮은 시간대**: 9시, 11시, 평균 요금 \\$16.58임.\n",
    "- **가장 많은 운행이 이루어진 시간대**: 15시, 1,017,848건임.\n",
    "- **가장 적은 운행이 이루어진 시간대**: 3시, 50,557건임.\n",
    "\n",
    "### 결론\n",
    "- **심야 시간대 (0시 - 5시)**: 평균 요금이 높고, 운행 횟수는 적음.\n",
    "- **출퇴근 시간대 (7시 - 9시, 17시 - 19시)**: 평균 요금이 낮고, 운행 횟수가 많음.\n",
    "- **일반 시간대 (10시 - 16시)**: 평균 요금과 운행 횟수가 중간 수준임.\n",
    "\n",
    "### 인사이트\n",
    "- **심야 시간대**: 택시 요금이 높음. 이 시간대에는 이동 수요가 적어 요금이 더 높아지는 경향이 있음.\n",
    "- **출퇴근 시간대**: 택시 이용이 활발하고, 운행 횟수가 많아짐. 이 시간대에는 이동 수요가 많아 요금이 비교적 낮음.\n",
    "- **일반 시간대**: 요금과 운행 횟수가 비교적 균형을 이룸. 이 시간대는 특별히 높거나 낮은 요금 없이 안정적인 운행이 이루어짐."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcf1ae1-71d0-4edd-baf8-185c5b15972e",
   "metadata": {},
   "source": [
    "# 3. 지불 유형별 요금, 팁 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59622a4f-404f-4362-ae1a-abdfa04d2e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:========================================>             (150 + 2) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-------+\n",
      "|payment_type|avg_fare|avg_tip|\n",
      "+------------+--------+-------+\n",
      "|           1|   18.72|   2.88|\n",
      "|           2|   15.51|    0.0|\n",
      "|           3|   15.95|    0.0|\n",
      "|           4|   16.47|    0.0|\n",
      "+------------+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 쿼리\n",
    "payment_tip_query = '''\n",
    "SELECT \n",
    "  payment_type,\n",
    "  ROUND(AVG(total_amount), 2) AS avg_fare,\n",
    "  ROUND(AVG(tip_amount), 2) AS avg_tip\n",
    "FROM comb\n",
    "GROUP BY payment_type\n",
    "ORDER BY payment_type;\n",
    "'''\n",
    "payment_tip_df = spark.sql(payment_tip_query)\n",
    "payment_tip_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97c27d83-8f79-4a76-9ab5-4a49e50fd6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:=================================================>    (185 + 2) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-------+\n",
      "|payment_type|avg_fare|avg_tip|\n",
      "+------------+--------+-------+\n",
      "|           1|   18.72|   2.88|\n",
      "|           2|   15.51|    0.0|\n",
      "|           3|   15.95|    0.0|\n",
      "|           4|   16.47|    0.0|\n",
      "+------------+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 데이터프레임\n",
    "\n",
    "# 각 지불 유형별 평균 요금과 평균 팁 계산 및 지불 유형 순서대로 정렬\n",
    "payment_tip_df = comb_df.groupBy(\"payment_type\").agg(\n",
    "    round(avg(\"total_amount\"), 2).alias(\"avg_fare\"),\n",
    "    round(avg(\"tip_amount\"), 2).alias(\"avg_tip\")\n",
    ").orderBy(\"payment_type\")\n",
    "\n",
    "# 결과 출력\n",
    "payment_tip_df.select(\"payment_type\", \"avg_fare\", \"avg_tip\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08b611b-454c-4e8b-84eb-f914ab7f928e",
   "metadata": {},
   "source": [
    "> 결과 분석\n",
    "\n",
    "### 전체 결과\n",
    "- **Payment Type 1**: 평균 요금 \\$18.72, 평균 팁 \\$2.88  \n",
    "- **Payment Type 2**: 평균 요금 \\$15.51, 평균 팁 \\$0.00  \n",
    "- **Payment Type 3**: 평균 요금 \\$15.95, 평균 팁 \\$0.00  \n",
    "- **Payment Type 4**: 평균 요금 \\$16.47, 평균 팁 \\$0.00  \n",
    "\n",
    "### 결론\n",
    "- **Payment Type 1**: 다른 지불 유형에 비해 평균 요금과 평균 팁이 가장 높음.\n",
    "- **Payment Type 2, 3, 4**: 평균 요금이 비슷하며, 팁이 없음.\n",
    "\n",
    "### 인사이트\n",
    "- **Payment Type 1**: 평균 요금이 높고 팁도 높음.\n",
    "- **Payment Type 2, 3, 4**: 팁이 없고 평균 요금이 상대적으로 낮음.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78431618-7742-488c-bd9c-feb462eb05d5",
   "metadata": {},
   "source": [
    "# 4. 승차지역 / 하차지역별 평균거리, 요금"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c7e87fb-7e61-4e85-95b7-24c8a4fc8d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쿼리\n",
    "distance_fare_query = '''\n",
    "SELECT \n",
    "  pickup_zone,\n",
    "  dropoff_zone,\n",
    "  ROUND(AVG(trip_distance), 2) AS avg_distance,\n",
    "  ROUND(AVG(total_amount), 2) AS avg_fare\n",
    "FROM comb\n",
    "GROUP BY pickup_zone, dropoff_zone\n",
    "ORDER BY avg_distance DESC;\n",
    "'''\n",
    "distance_fare_df = spark.sql(distance_fare_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "feaf082c-230d-4ed0-b61e-85a8ef303f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임\n",
    "\n",
    "# 각 승차지역 및 하차지역별 평균 거리와 평균 요금을 계산하고, 소숫점 2자리까지 표시\n",
    "distance_fare_df = comb_df.groupBy(\"pickup_zone\", \"dropoff_zone\").agg(\n",
    "    round(avg(\"trip_distance\"), 2).alias(\"avg_distance\"),\n",
    "    round(avg(\"total_amount\"), 2).alias(\"avg_fare\")\n",
    ").orderBy(\"avg_distance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "067a244b-0122-4d84-b896-f6c43039a970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+--------+\n",
      "|         pickup_zone|        dropoff_zone|avg_distance|avg_fare|\n",
      "+--------------------+--------------------+------------+--------+\n",
      "|East New York/Pen...|                  NA|       63.29|  255.28|\n",
      "|Heartland Village...|                  NA|       56.87|   208.9|\n",
      "|      Sheepshead Bay|            Longwood|       54.12|   93.85|\n",
      "|         Eastchester|Charleston/Totten...|       51.37|   156.4|\n",
      "|   Rossville/Woodrow|     Pelham Bay Park|       51.28|   151.0|\n",
      "|Charleston/Totten...|     Pelham Bay Park|       51.02|   157.5|\n",
      "|Charleston/Totten...|         Eastchester|       49.48|  149.26|\n",
      "|          Co-Op City|Charleston/Totten...|       48.87|  149.21|\n",
      "|          Co-Op City|     Mariners Harbor|       48.75|  157.99|\n",
      "|         Eastchester|   Rossville/Woodrow|       48.66|  138.04|\n",
      "+--------------------+--------------------+------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+--------+\n",
      "|         pickup_zone|        dropoff_zone|avg_distance|avg_fare|\n",
      "+--------------------+--------------------+------------+--------+\n",
      "|East New York/Pen...|                  NA|       63.29|  255.28|\n",
      "|Heartland Village...|                  NA|       56.87|   208.9|\n",
      "|      Sheepshead Bay|            Longwood|       54.12|   93.85|\n",
      "|         Eastchester|Charleston/Totten...|       51.37|   156.4|\n",
      "|   Rossville/Woodrow|     Pelham Bay Park|       51.28|   151.0|\n",
      "|Charleston/Totten...|     Pelham Bay Park|       51.02|   157.5|\n",
      "|Charleston/Totten...|         Eastchester|       49.48|  149.26|\n",
      "|          Co-Op City|Charleston/Totten...|       48.87|  149.21|\n",
      "|          Co-Op City|     Mariners Harbor|       48.75|  157.99|\n",
      "|         Eastchester|   Rossville/Woodrow|       48.66|  138.04|\n",
      "+--------------------+--------------------+------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+------------+--------+\n",
      "|         pickup_zone|     dropoff_zone|avg_distance|avg_fare|\n",
      "+--------------------+-----------------+------------+--------+\n",
      "|Forest Park/Highl...|      Kew Gardens|        0.04|     3.3|\n",
      "|  Van Cortlandt Park|               NV|        0.04|     0.9|\n",
      "|       East New York|               NV|        0.05|     4.3|\n",
      "|           Bay Ridge|               NV|        0.05|     3.8|\n",
      "|  Claremont/Bathgate|     Crotona Park|        0.06|     4.3|\n",
      "|    Sunset Park West|               NV|        0.06|     4.3|\n",
      "|        Astoria Park|     Astoria Park|         0.1|     3.3|\n",
      "|        East Tremont|               NV|         0.1|    3.47|\n",
      "|   Rossville/Woodrow|Rossville/Woodrow|         0.1|     0.3|\n",
      "|            Rosedale|  Cambria Heights|         0.1|     3.3|\n",
      "+--------------------+-----------------+------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+------------+--------+\n",
      "|      pickup_zone|        dropoff_zone|avg_distance|avg_fare|\n",
      "+-----------------+--------------------+------------+--------+\n",
      "|        Flatlands|     Lenox Hill East|        0.13|     0.0|\n",
      "|     Bloomingdale|        Coney Island|       20.43|     0.0|\n",
      "|Rossville/Woodrow|   Rossville/Woodrow|         0.1|     0.3|\n",
      "|          Jamaica|  South Williamsburg|        12.0|     0.3|\n",
      "|      Westerleigh|Bloomfield/Emerso...|         1.2|     0.3|\n",
      "|    South Jamaica|         Kew Gardens|         1.9|     0.3|\n",
      "|          Jamaica|       Willets Point|         4.6|     0.3|\n",
      "|       Bronx Park|  Woodlawn/Wakefield|         2.6|     0.3|\n",
      "|      Parkchester|        Baisley Park|       14.36|    0.31|\n",
      "|    Fresh Meadows|         JFK Airport|         1.0|    0.31|\n",
      "+-----------------+--------------------+------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+\n",
      "|summary|      avg_distance|         avg_fare|\n",
      "+-------+------------------+-----------------+\n",
      "|  count|             29959|            29959|\n",
      "|   mean|10.148192863580233|41.46117927834707|\n",
      "| stddev| 6.786928575677103|23.87105460877794|\n",
      "|    min|              0.04|              0.0|\n",
      "|    max|             63.29|           1165.3|\n",
      "+-------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 평균 거리 기준 상위 10개 지역\n",
    "distance_fare_df.orderBy(col(\"avg_distance\").desc()).show(10)\n",
    "\n",
    "# 평균 요금 기준 상위 10개 지역\n",
    "distance_fare_df.orderBy(col(\"avg_distance\").desc()).show(10)\n",
    "\n",
    "# 평균 거리 기준 하위 10개 지역\n",
    "distance_fare_df.orderBy(col(\"avg_distance\").asc()).show(10)\n",
    "\n",
    "# 평균 요금 기준 하위 10개 지역\n",
    "distance_fare_df.orderBy(col(\"avg_fare\").asc()).show(10)\n",
    "\n",
    "# 요약 통계\n",
    "distance_fare_df.describe([\"avg_distance\", \"avg_fare\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d544862-0097-438f-92f0-b507c04f4f24",
   "metadata": {},
   "source": [
    "> 결과 분석\n",
    "\n",
    "### 전체 결과\n",
    "- **평균 거리 기준 상위 10개 지역**:\n",
    "  - East New York/Pennsylvania와 Heartland Village 지역은 평균 거리가 50km 이상으로 가장 길며, 요금도 상대적으로 높음.\n",
    "  - 대부분의 상위 지역들은 장거리 운행에 해당하며, 평균 요금도 높음.\n",
    "\n",
    "- **평균 요금 기준 상위 10개 지역**:\n",
    "  - 평균 거리 기준 상위 10개 지역과 일치하는 경우가 많음.\n",
    "  - East New York/Pennsylvania와 Heartland Village는 높은 평균 요금이 두드러짐.\n",
    "\n",
    "- **평균 거리 기준 하위 10개 지역**:\n",
    "  - Forest Park/Highland Park와 Van Cortlandt Park는 평균 거리가 0.04km로 가장 짧음.\n",
    "  - 대부분의 하위 지역들은 매우 짧은 거리를 운행하는 경우가 많음.\n",
    "\n",
    "- **평균 요금 기준 하위 10개 지역**:\n",
    "  - Flatlands와 Bloomingdale은 평균 요금이 $0.00로 나타남.\n",
    "  - 대부분의 하위 지역들은 평균 요금이 매우 낮거나 무료인 경우가 있음.\n",
    "\n",
    "- **요약 통계**:\n",
    "  - 평균 거리는 약 10.15km, 평균 요금은 약 $41.46으로 나타남.\n",
    "  - 최대 거리는 63.29km, 최대 요금은 $1165.30으로 나타남.\n",
    "\n",
    "### 결론\n",
    "- 장거리 운행: 평균 요금이 높고 운행 횟수는 적음.\n",
    "- 단거리 운행: 평균 요금이 낮고 운행 횟수는 많음.\n",
    "- 중간 거리 구간: 요금과 운행 횟수가 점진적으로 변화함.\n",
    "\n",
    "### 인사이트\n",
    "- 장거리 운행에서는 요금이 높아지는 경향이 뚜렷함.\n",
    "- 단거리 운행에서는 요금이 상대적으로 낮고 운행 횟수가 많음.\n",
    "- 중간 거리 구간에서는 요금과 운행 횟수가 균형을 이루는 경향을 보임.\n",
    "- 운행 거리와 요금은 대부분의 경우 비례하는 경향이 있으며, 이는 택시 요금 구조와 관련이 있음.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2093c8-2f2e-4120-94f4-d138d74c2a31",
   "metadata": {},
   "source": [
    "# 5. 팁의 비율에 따른 거리, 여행 건수 서비스 관련 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a501c29-48d2-475a-b3cb-5e9c4cf2cc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 76:==================================================>     (10 + 1) / 11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---------+\n",
      "|tip_ratio|avg_distance|num_trips|\n",
      "+---------+------------+---------+\n",
      "|    0-10%|        3.09|  4971107|\n",
      "|   10-20%|        2.84|  7339171|\n",
      "|   20-30%|        2.48|  1511876|\n",
      "|   30-40%|         2.0|    46236|\n",
      "|     40%+|        2.28|    22359|\n",
      "+---------+------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 쿼리\n",
    "tip_ratio_query = '''\n",
    "SELECT \n",
    "  CASE \n",
    "    WHEN tip_amount / total_amount < 0.1 THEN '0-10%'\n",
    "    WHEN tip_amount / total_amount >= 0.1 AND tip_amount / total_amount < 0.2 THEN '10-20%'\n",
    "    WHEN tip_amount / total_amount >= 0.2 AND tip_amount / total_amount < 0.3 THEN '20-30%'\n",
    "    WHEN tip_amount / total_amount >= 0.3 AND tip_amount / total_amount < 0.4 THEN '30-40%'\n",
    "    ELSE '40%+'\n",
    "  END AS tip_ratio,\n",
    "  ROUND(AVG(trip_distance), 2) AS avg_distance,\n",
    "  COUNT(*) AS num_trips\n",
    "FROM comb\n",
    "GROUP BY tip_ratio\n",
    "ORDER BY tip_ratio;\n",
    "'''\n",
    "tip_ratio_df = spark.sql(tip_ratio_query)\n",
    "tip_ratio_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86109238-1739-4946-bd9f-ec1590a3518a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 82:==================================================>     (10 + 1) / 11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---------+\n",
      "|tip_ratio|avg_distance|num_trips|\n",
      "+---------+------------+---------+\n",
      "|    0-10%|        3.09|  4971107|\n",
      "|   10-20%|        2.81|  7839352|\n",
      "|   20-30%|        2.57|  1011837|\n",
      "|   30-40%|         2.0|    46126|\n",
      "|     40%+|        2.28|    22327|\n",
      "+---------+------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 데이터프레임\n",
    "\n",
    "# 팁 비율 구간별로 평균 거리와 여행 건수를 계산\n",
    "tip_ratio_df = comb_df.withColumn(\n",
    "    \"tip_ratio\", \n",
    "    when((col(\"tip_amount\") / col(\"total_amount\")) < 0.1, '0-10%')\n",
    "    .when((col(\"tip_amount\") / col(\"total_amount\")).between(0.1, 0.2), '10-20%')\n",
    "    .when((col(\"tip_amount\") / col(\"total_amount\")).between(0.2, 0.3), '20-30%')\n",
    "    .when((col(\"tip_amount\") / col(\"total_amount\")).between(0.3, 0.4), '30-40%')\n",
    "    .otherwise('40%+')\n",
    ").groupBy(\"tip_ratio\").agg(\n",
    "    round(avg(\"trip_distance\"), 2).alias(\"avg_distance\"),\n",
    "    count(\"*\").alias(\"num_trips\")\n",
    ").orderBy(\"tip_ratio\")\n",
    "\n",
    "# 결과 출력\n",
    "tip_ratio_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c2e395-3896-4e22-a889-162989e33d1a",
   "metadata": {},
   "source": [
    "> 결과 분석\n",
    "### 전체 결과\n",
    "- **0-10% 팁 비율**:\n",
    "  - 평균 거리: 3.09 km\n",
    "  - 여행 건수: 4,971,107건\n",
    "- **10-20% 팁 비율**:\n",
    "  - 평균 거리: 2.81 km\n",
    "  - 여행 건수: 7,839,352건\n",
    "- **20-30% 팁 비율**:\n",
    "  - 평균 거리: 2.57 km\n",
    "  - 여행 건수: 1,011,837건\n",
    "- **30-40% 팁 비율**:\n",
    "  - 평균 거리: 2.00 km\n",
    "  - 여행 건수: 46,126건\n",
    "- **40%+ 팁 비율**:\n",
    "  - 평균 거리: 2.28 km\n",
    "  - 여행 건수: 22,327건\n",
    "\n",
    "### 결론\n",
    "- **팁 비율이 낮을수록 여행 거리가 길다**: 0-10% 팁 비율 구간에서 평균 거리가 가장 길며, 팁 비율이 높아질수록 평균 거리가 짧아짐.\n",
    "- **팁 비율이 높을수록 여행 건수는 적다**: 10-20% 팁 비율 구간에서 가장 많은 여행 건수가 발생하였으며, 팁 비율이 높아질수록 여행 건수는 줄어듦.\n",
    "\n",
    "### 인사이트\n",
    "- **0-10% 팁 비율**: 이 구간에서는 여행 거리가 길고, 많은 여행이 이루어짐. 이는 상대적으로 긴 거리를 이동하는 승객들이 팁을 적게 주는 경향이 있음을 시사함.\n",
    "- **10-20% 팁 비율**: 이 구간에서 가장 많은 여행 건수가 발생함. 평균 거리가 약간 짧아지지만 여전히 많은 승객들이 이 범위 내에서 팁을 줌.\n",
    "- **20-30% 팁 비율**: 이 구간에서는 여행 거리와 건수가 더 감소함. 팁을 적당히 많이 주는 승객들의 경우, 이동 거리가 더 짧아지는 경향이 있음.\n",
    "- **30-40% 팁 비율**: 이 구간에서는 평균 거리가 더 짧아지고, 여행 건수도 급격히 줄어듦. 매우 높은 팁 비율을 주는 승객들은 주로 짧은 거리를 이동함.\n",
    "- **40%+ 팁 비율**: 이 구간에서는 여행 거리가 다시 약간 길어지지만, 여행 건수는 매우 적음. 극도로 높은 팁을 주는 승객들은 특별한 경우에 한정될 가능성이 큼."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8527c79-d1bd-439a-9d5d-87a72ef6c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
