{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65667af3-2f72-48cf-8359-08e9f930eb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/09 13:53:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"FirstSparkSessionApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8da3bbd5-79bc-4e95-b5d5-4e7a6026f552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('json').load('data/2015-summary.json')#, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a2c7122-650b-419a-84e5-9ed20c907cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(DEST_COUNTRY_NAME,StringType,true),StructField(ORIGIN_COUNTRY_NAME,StringType,true),StructField(count,LongType,true)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4bb78e9-c0ca-4db7-af1f-402dd0d9e706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e57b09-29e2-4796-af56-de85ec54bc2c",
   "metadata": {},
   "source": [
    "## Row 클래스, 단일 레코드(행)을 나타내는 객체\n",
    "\n",
    "Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d80d704-490d-4c7e-9deb-0d639e869b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344),\n",
       " Row(DEST_COUNTRY_NAME='Egypt', ORIGIN_COUNTRY_NAME='United States', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='India', count=62)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e504050e-c628-41d5-bdc4-efe27cf38c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8262f09e-131c-4ede-816d-f9258f17117c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "|    United States|\n",
      "|            Egypt|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#spark DataTable 프로젝션\n",
    "df.select(\"DEST_COUNTRY_NAME\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1b4e425-e961-4a3e-96db-8526b13348ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15174025-6c41-48c0-98b2-22da4320945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dup2 = df.select('DEST_COUNTRY_NAME').dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73fadd55-cc40-4ad1-bf32-e2958dde1ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   DEST_COUNTRY_NAME|\n",
      "+--------------------+\n",
      "|            Anguilla|\n",
      "|              Russia|\n",
      "|            Paraguay|\n",
      "|             Senegal|\n",
      "|              Sweden|\n",
      "|            Kiribati|\n",
      "|              Guyana|\n",
      "|         Philippines|\n",
      "|            Djibouti|\n",
      "|            Malaysia|\n",
      "|           Singapore|\n",
      "|                Fiji|\n",
      "|              Turkey|\n",
      "|                Iraq|\n",
      "|             Germany|\n",
      "|              Jordan|\n",
      "|               Palau|\n",
      "|Turks and Caicos ...|\n",
      "|              France|\n",
      "|              Greece|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dup2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49d2fdb5-c742-4531-bd6c-011ee8d7b016",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_dup1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_dup1\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_dup1' is not defined"
     ]
    }
   ],
   "source": [
    "df_dup1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cbfd700-31ea-4929-aa9e-e74f91bfe02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   DEST_COUNTRY_NAME|\n",
      "+--------------------+\n",
      "|            Anguilla|\n",
      "|              Russia|\n",
      "|            Paraguay|\n",
      "|             Senegal|\n",
      "|              Sweden|\n",
      "|            Kiribati|\n",
      "|              Guyana|\n",
      "|         Philippines|\n",
      "|            Djibouti|\n",
      "|            Malaysia|\n",
      "|           Singapore|\n",
      "|                Fiji|\n",
      "|              Turkey|\n",
      "|                Iraq|\n",
      "|             Germany|\n",
      "|              Jordan|\n",
      "|               Palau|\n",
      "|Turks and Caicos ...|\n",
      "|              France|\n",
      "|              Greece|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dup3= df.select('DEST_COUNTRY_NAME').dropDuplicates().cache()\n",
    "df_dup3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9abf5f9a-f057-4dcb-ac8e-391c0978d45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   DEST_COUNTRY_NAME|\n",
      "+--------------------+\n",
      "|            Anguilla|\n",
      "|              Russia|\n",
      "|            Paraguay|\n",
      "|             Senegal|\n",
      "|              Sweden|\n",
      "|            Kiribati|\n",
      "|              Guyana|\n",
      "|         Philippines|\n",
      "|            Djibouti|\n",
      "|            Malaysia|\n",
      "|           Singapore|\n",
      "|                Fiji|\n",
      "|              Turkey|\n",
      "|                Iraq|\n",
      "|             Germany|\n",
      "|              Jordan|\n",
      "|               Palau|\n",
      "|Turks and Caicos ...|\n",
      "|              France|\n",
      "|              Greece|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dup2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f42ad8eb-8aae-47c6-9e1b-984513f640d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_dup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_dup\u001b[49m\u001b[38;5;241m.\u001b[39mcount()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_dup' is not defined"
     ]
    }
   ],
   "source": [
    "df_dup.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14d1356a-db58-4e5d-b7f6-8ed7f720e926",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_dup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_dup\u001b[49m\u001b[38;5;241m.\u001b[39mdistinct()\u001b[38;5;241m.\u001b[39mcount()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_dup' is not defined"
     ]
    }
   ],
   "source": [
    "df_dup.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3502cbd-6989-4a59-9f67-7cdd486d0498",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_dup1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_dup1\u001b[49m\u001b[38;5;241m.\u001b[39mcount()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_dup1' is not defined"
     ]
    }
   ],
   "source": [
    "df_dup1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c94dcdb-e480-4101-872f-5fc7e604c8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dup3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62df3ef4-bb42-42ab-8344-decaefe02a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|             Algeria|      United States|    4|\n",
      "|              Angola|      United States|   15|\n",
      "|            Anguilla|      United States|   41|\n",
      "| Antigua and Barbuda|      United States|  126|\n",
      "|           Argentina|      United States|  180|\n",
      "|               Aruba|      United States|  346|\n",
      "|           Australia|      United States|  329|\n",
      "|             Austria|      United States|   62|\n",
      "|          Azerbaijan|      United States|   21|\n",
      "|             Bahrain|      United States|   19|\n",
      "|            Barbados|      United States|  154|\n",
      "|             Belgium|      United States|  259|\n",
      "|              Belize|      United States|  188|\n",
      "|             Bermuda|      United States|  183|\n",
      "|             Bolivia|      United States|   30|\n",
      "|Bonaire, Sint Eus...|      United States|   58|\n",
      "|              Brazil|      United States|  853|\n",
      "|British Virgin Is...|      United States|  107|\n",
      "|            Bulgaria|      United States|    3|\n",
      "|        Burkina Faso|      United States|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort('DEST_COUNTRY_NAME').show() #셔플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bd1de25-ac9e-41aa-a454-1a4add275649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b55d8e1-77e8-4be1-a8c0-fdc934379b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.withColumn('withInCountry', expr('ORIGIN_COUNTRY_NAME==DEST_COUNTRY_NAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f015095f-86cb-42a3-8b39-2acbce812f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withInCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7304f68-728a-4f33-b326-1aac0e85cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL 구문 CASE WHEN > 수치형 변수 > 명목형 변수로 변환 > 파생변수\n",
    "df4 = df.withColumn('category', expr('CASE WHEN count<10 THEN \"under\" WHEN count>=10 THEN \"upper\" END'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed5e6f84-beac-4a14-aa57-786c64084577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+--------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|category|\n",
      "+-----------------+-------------------+-----+--------+\n",
      "|    United States|            Romania|   15|   upper|\n",
      "|    United States|            Croatia|    1|   under|\n",
      "|    United States|            Ireland|  344|   upper|\n",
      "|            Egypt|      United States|   15|   upper|\n",
      "|    United States|              India|   62|   upper|\n",
      "+-----------------+-------------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14a32245-cd22-47b8-976a-e0eb2df86015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count 2배 해보세요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "674b72b6-5027-4380-bcd9-2bca27f1d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.withColumn('withInCountry', expr('ORIGIN_COUNTRY_NAME==DEST_COUNTRY_NAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "902952e5-c235-458b-b864-5324129e8ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+--------+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|category|withInCountry|\n",
      "+-----------------+-------------------+-----+--------+-------------+\n",
      "|    United States|            Romania|   15|   upper|        false|\n",
      "|    United States|            Croatia|    1|   under|        false|\n",
      "|    United States|            Ireland|  344|   upper|        false|\n",
      "|            Egypt|      United States|   15|   upper|        false|\n",
      "|    United States|              India|   62|   upper|        false|\n",
      "+-----------------+-------------------+-----+--------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccb36cc8-9ec7-44c4-8f05-1db82423d78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|withInCountry|count|\n",
      "+-------------+-----+\n",
      "|         true|    1|\n",
      "|        false|  255|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.groupBy(\"withInCountry\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e742607-ec96-4cf1-be7f-69721fef3a66",
   "metadata": {},
   "source": [
    "## Projection 과 Filter\n",
    "\n",
    "```\n",
    "select a,b,c  # projection > column > Transformation select('colname')\n",
    "from TableA  \n",
    "where a>10  #filter > Row >Transformation where('cond')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7523143-b12e-4f43-8f6c-6149d01aff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5.where('count<5' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecd5b980-c145-4283-b49d-37f4dc129a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+--------+-------------+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|category|withInCountry|\n",
      "+--------------------+-------------------+-----+--------+-------------+\n",
      "|       United States|            Croatia|    1|   under|        false|\n",
      "|       United States|          Singapore|    1|   under|        false|\n",
      "|             Moldova|      United States|    1|   under|        false|\n",
      "|               Malta|      United States|    1|   under|        false|\n",
      "|             Algeria|      United States|    4|   under|        false|\n",
      "|       United States|          Gibraltar|    1|   under|        false|\n",
      "|Saint Vincent and...|      United States|    1|   under|        false|\n",
      "|            Suriname|      United States|    1|   under|        false|\n",
      "|       United States|             Cyprus|    1|   under|        false|\n",
      "|       United States|           Malaysia|    3|   under|        false|\n",
      "|            Thailand|      United States|    3|   under|        false|\n",
      "|             Liberia|      United States|    2|   under|        false|\n",
      "|             Hungary|      United States|    2|   under|        false|\n",
      "|       United States|            Vietnam|    2|   under|        false|\n",
      "|        Burkina Faso|      United States|    1|   under|        false|\n",
      "|            Djibouti|      United States|    1|   under|        false|\n",
      "|       United States|            Estonia|    1|   under|        false|\n",
      "|       United States|            Hungary|    3|   under|        false|\n",
      "|              Zambia|      United States|    1|   under|        false|\n",
      "|            Malaysia|      United States|    2|   under|        false|\n",
      "+--------------------+-------------------+-----+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ea098ef-cc26-4be1-9d0f-3ae7f5ca661e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc87d0d-ca6f-4cbf-a37a-ee87f854bfa0",
   "metadata": {},
   "source": [
    "where a>10 and b!=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c42f86aa-ea4f-4a28-8135-102da182de6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+--------+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|category|withInCountry|\n",
      "+-----------------+-------------------+-----+--------+-------------+\n",
      "|    United States|            Croatia|    1|   under|        false|\n",
      "|    United States|          Singapore|    1|   under|        false|\n",
      "|    United States|          Gibraltar|    1|   under|        false|\n",
      "|    United States|             Cyprus|    1|   under|        false|\n",
      "|    United States|           Malaysia|    3|   under|        false|\n",
      "|    United States|            Vietnam|    2|   under|        false|\n",
      "|    United States|            Estonia|    1|   under|        false|\n",
      "|    United States|            Hungary|    3|   under|        false|\n",
      "|    United States|           Thailand|    4|   under|        false|\n",
      "|    United States|            Liberia|    2|   under|        false|\n",
      "|    United States|              Malta|    2|   under|        false|\n",
      "|    United States|          Lithuania|    1|   under|        false|\n",
      "|    United States|           Bulgaria|    1|   under|        false|\n",
      "|    United States|            Georgia|    1|   under|        false|\n",
      "|    United States|            Bahrain|    1|   under|        false|\n",
      "|    United States|   Papua New Guinea|    1|   under|        false|\n",
      "|    United States|          Greenland|    4|   under|        false|\n",
      "|    United States|          Indonesia|    2|   under|        false|\n",
      "|    United States|         Montenegro|    1|   under|        false|\n",
      "|    United States|            Namibia|    1|   under|        false|\n",
      "+-----------------+-------------------+-----+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df7 = df5.where('count<5' ).where('ORIGIN_COUNTRY_NAME != \"United States\"')\n",
    "df7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b58ab84-08d1-4ef4-93fc-1738fab36241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#프로젝션, 필터링 연습을 진행해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b862132c-26e0-4ffc-9f24-f7d45c338cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|withInCountry|count|\n",
      "+-------------+-----+\n",
      "|         true|    1|\n",
      "|        false|  255|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.groupBy('withInCountry').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8d14a98-e6a8-4c31-9455-c11afe33730e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+------+--------+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|category|withInCountry|\n",
      "+-----------------+-------------------+------+--------+-------------+\n",
      "|    United States|      United States|370002|   upper|         true|\n",
      "+-----------------+-------------------+------+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#국내 여행 카운트를 확인합니다.\n",
    "df5.where('withInCountry==true').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef0b2006-e880-4d5c-b1f9-dfeb890e1080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upper 인 ORIGIN_COUNTRY_NAME별 평균 카운트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0b609d5-f9dc-4caf-8221-b85975bd9cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#카운트가 200 이상인 ORIGIN_COUNTRY_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6364d579-d0be-4d6d-9b8f-49beb39229c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#국내 여행이 아니면서 가장 횟수가 많은 ORIGIN_COUNTRY_NAME top 10을  추출해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ad32bae-1118-4d41-b43d-f4fb01681ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#국내 여행이 아니면서 가장 횟수가 적은 ORIGIN_COUNTRY_NAME top 10을  추출해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0cbfdc88-8a8a-467b-99ab-43b81496fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#도착국가별 count 총합이 가장 많은 top10을 추출해 보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e48de6e6-dc74-4a01-8a1f-dffc33712b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1357fc-778c-481b-88d8-4d55264dc317",
   "metadata": {},
   "source": [
    "# 집계 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfc7152c-8540-400f-bce9-616713b7b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"SecondSparkSessionApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd121977-c127-40e5-91b7-55c0b530b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", 'true')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load('data/emp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c27a9a22-e822-47c4-9f83-61f2aac968c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- empno: integer (nullable = true)\n",
      " |-- ename: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- mgr: integer (nullable = true)\n",
      " |-- hiredate: string (nullable = true)\n",
      " |-- sal: integer (nullable = true)\n",
      " |-- comm: integer (nullable = true)\n",
      " |-- deptno: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e430d64b-e0ee-45fd-9274-35886b609368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|null|    20|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|null|    20|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|null|    30|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|null|    20|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|null|    20|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|null|    30|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|null|    20|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|null|    70|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21286242-8d80-40a3-8ff8-6aebfc0f5b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "| ename|deptno|\n",
      "+------+------+\n",
      "| SMITH|    20|\n",
      "| ALLEN|    30|\n",
      "|  WARD|    30|\n",
      "| JONES|    20|\n",
      "|MARTIN|    30|\n",
      "| BLAKE|    30|\n",
      "| CLARK|    10|\n",
      "| SCOTT|    20|\n",
      "|  KING|    10|\n",
      "|TURNER|    30|\n",
      "| ADAMS|    20|\n",
      "| JAMES|    30|\n",
      "|  FORD|    20|\n",
      "|MILLER|    10|\n",
      "|  JACK|    70|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('ename', 'deptno').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "528d92da-f42d-4941-b6c4-7bdc301b87c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|ename|deptno|\n",
      "+-----+------+\n",
      "|SMITH|    20|\n",
      "|JONES|    20|\n",
      "|SCOTT|    20|\n",
      "|ADAMS|    20|\n",
      "| FORD|    20|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('ename', 'deptno').where('deptno=20').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd9ea73a-5b11-4bba-bf04-4fc8135331e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카운트 집계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91d3c3ff-4384-468d-b33c-fbda1ae4bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c10789f8-200a-4a35-aefc-c58f6b338b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|count(job)|\n",
      "+----------+\n",
      "|        15|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(count('job')).show()  #null 값 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2a7040c9-86c0-4ca9-864c-a1c2f4a3d7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      15|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr('count(*)').show()  #null 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0f00277-53b8-460c-90dc-85b67664198f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|      job|\n",
      "+---------+\n",
      "|  ANALYST|\n",
      "| SALESMAN|\n",
      "|    CLERK|\n",
      "|  MANAGER|\n",
      "|PRESIDENT|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('job').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "226d2915-eccb-4f83-875e-57a55b0a989b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 20:============================================>         (163 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('job').distinct().count() #정확"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a3801edb-7fe2-48cf-9f13-62be283c74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct, approx_count_distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a1344d8-1848-404b-9d69-f31963c62a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 23:======================================>               (144 + 2) / 200]\r",
      "\r",
      "[Stage 23:===================================================>  (191 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count(DISTINCT job)|\n",
      "+-------------------+\n",
      "|                  5|\n",
      "+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(countDistinct('job')).show() #근사치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b99b2355-ad8c-4b2f-80d8-6f2fed446a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|approx_count_distinct(job)|\n",
      "+--------------------------+\n",
      "|                         5|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(approx_count_distinct('job', 0.1)).show()  #성능면에서 유리한 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ea8023d4-8ed3-404e-ac49-767f1cc2ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import first, last, min, max, sum, avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83a5542a-0100-4244-9d2b-66f53a3a90da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|first(ename)|last(ename)|\n",
      "+------------+-----------+\n",
      "|       SMITH|       JACK|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(first('ename'), last('ename')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "63fb45f6-2b4e-4711-bb0e-30e1a18fc909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0df048bf-f245-4208-b10d-09f214f40774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|min(sal)|max(sal)|\n",
      "+--------+--------+\n",
      "|     800|    5000|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(min('sal'), max('sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a8a062ef-bd10-48d3-8f52-b91fbaaa7b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+----------+----------+\n",
      "|count(empno)|count(1)|max(ename)|min(ename)|\n",
      "+------------+--------+----------+----------+\n",
      "|          15|      15|      WARD|     ADAMS|\n",
      "+------------+--------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(count('empno'), count('*'), max('ename'), min('ename')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "de43be95-f07f-4d2d-ae61-efb75cacab30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|sum(sal)|\n",
      "+--------+\n",
      "|   32225|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(sum('sal')).show() #sal 컬럼의 총합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1e1dbb09-4199-4ccc-9d59-5911d12bc207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|sum(DISTINCT sal)|\n",
      "+-----------------+\n",
      "|            27975|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 36:=============================================>        (169 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#sal 컬럼값의 중복을 제거하고 합산\n",
    "#df.select().distinct().sum()\n",
    "df.selectExpr( 'sum( distinct sal )' ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5493a352-7dd9-40de-b118-9b44963dd853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+------------------+------------------+\n",
      "|total_tx|total_salary|        avg_salary|       mean_salary|\n",
      "+--------+------------+------------------+------------------+\n",
      "|      15|       32225|2148.3333333333335|2148.3333333333335|\n",
      "+--------+------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#alias\n",
    "dfs = df.select( count('sal').alias('total_tx') ,\n",
    "                    sum('sal').alias('total_salary'),\n",
    "                    avg('sal').alias('avg_salary'),\n",
    "                    expr('mean(sal)').alias('mean_salary')\n",
    "               )\n",
    "dfs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa568873-b11d-4548-a989-39d801b58428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#round(data,자릿수)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2937d96e-87d9-4822-9c0b-91e349756630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87b9abed-308c-4c4d-998e-3e76b468ae92",
   "metadata": {},
   "source": [
    "# 그룹화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0d355ba6-b99b-479c-a132-8ec65defe439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|      job|count|\n",
      "+---------+-----+\n",
      "|  ANALYST|    2|\n",
      "| SALESMAN|    4|\n",
      "|    CLERK|    5|\n",
      "|  MANAGER|    3|\n",
      "|PRESIDENT|    1|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('job').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d1d994b5-554f-4c19-bed4-741fb2ddd41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg() 집계함수 적용\n",
    "dfs = df.groupBy('job').agg( expr('avg(sal) as SAL_AVG'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9b6bf71d-8ecc-4482-80c5-2dac9c32e392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|      job|           SAL_AVG|\n",
      "+---------+------------------+\n",
      "|  ANALYST|            3000.0|\n",
      "| SALESMAN|            1400.0|\n",
      "|    CLERK|            1470.0|\n",
      "|  MANAGER|2758.3333333333335|\n",
      "|PRESIDENT|            5000.0|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cc8abd04-0db4-4354-a4ff-dae6c74369b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sal 표준편차\n",
    "#1. sql.function stddev()\n",
    "#2. sql expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8f74b25e-f7bd-4af5-a197-69dddfb42eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|      job|         SAL_STDEV|\n",
      "+---------+------------------+\n",
      "|  ANALYST|               0.0|\n",
      "| SALESMAN|154.11035007422439|\n",
      "|    CLERK| 880.6815542521599|\n",
      "|  MANAGER|223.91714737574006|\n",
      "|PRESIDENT|               0.0|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('job').agg( expr('stddev_pop(sal) as SAL_STDEV') ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e6850102-b30f-4f53-9f93-b88644421812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198cd11e-b8bb-4555-9440-d3db43752131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5fd80a0a-19ed-4dd9-aea0-a7df588aecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby 집계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e7b58e-d35d-4f8c-a957-f0f6ebd361c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fb78647-482e-4480-b3cc-872d76e253ad",
   "metadata": {},
   "source": [
    "# 윈도우함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e8ad06",
   "metadata": {},
   "source": [
    "순위, 정렬 -  rank, row_number, dense_rank  \n",
    "누계 - sum, avg, max, min + over()  \n",
    "이동평균, 이동합계 - over + rowsBetween, rangeBetween  \n",
    "시차, 선행 - lag, lead  \n",
    "\n",
    "ex) 세션 구간내 분석, 특정시간 동안 일어난 활동 그룹화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ba3fc7",
   "metadata": {},
   "source": [
    "1. partitionBy()  > 소그룹으로 나눈다.\n",
    "2. orderBy()  > 소그룹 내 정렬\n",
    "3. rowBetween(), rangeBetween()\n",
    "4. over()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3730f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import desc, rank\n",
    "\n",
    "#순위를 부여하려고 하는 데이터의 범위 > 윈도우 명세 설정\n",
    "windowspec = Window.orderBy(desc('sal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "87885655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#순위객체\n",
    "salAllRank = rank().over(windowspec)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9466f40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'RANK() OVER (ORDER BY sal DESC NULLS LAST unspecifiedframe$())'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salAllRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "de62290a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/09 13:55:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|salary_rank|\n",
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|          1|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|null|    70|          2|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|null|    20|          3|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|null|    20|          3|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|null|    20|          5|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|null|    30|          6|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|          7|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|          8|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|          9|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|         10|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|         11|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|         11|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|null|    20|         13|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|null|    30|         14|\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|null|    20|         15|\n",
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#데이터프레임에 컬럼으로 추가 > 액션\n",
    "df.withColumn(\"salary_rank\", salAllRank).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a7c71b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n",
      "|empno|salary_rank|\n",
      "+-----+-----------+\n",
      "| 7839|          1|\n",
      "| 9292|          2|\n",
      "| 7788|          3|\n",
      "| 7902|          3|\n",
      "| 7566|          5|\n",
      "| 7698|          6|\n",
      "| 7782|          7|\n",
      "| 7499|          8|\n",
      "| 7844|          9|\n",
      "| 7934|         10|\n",
      "| 7521|         11|\n",
      "| 7654|         11|\n",
      "| 7876|         13|\n",
      "| 7900|         14|\n",
      "| 7369|         15|\n",
      "+-----+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/09 13:55:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.select( 'empno', salAllRank.alias('salary_rank') ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "09356272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#windowspec = Window.orderBy(desc('sal'))\n",
    "windowspec1 = Window.partitionBy('job').orderBy(desc('sal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "14a042bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "salJobRank = rank().over(windowspec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f1985498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----+----------+\n",
      "|      job| ename| sal|salJobRank|\n",
      "+---------+------+----+----------+\n",
      "|  ANALYST| SCOTT|3000|         1|\n",
      "|  ANALYST|  FORD|3000|         1|\n",
      "| SALESMAN| ALLEN|1600|         1|\n",
      "| SALESMAN|TURNER|1500|         2|\n",
      "| SALESMAN|  WARD|1250|         3|\n",
      "| SALESMAN|MARTIN|1250|         3|\n",
      "|    CLERK|  JACK|3200|         1|\n",
      "|    CLERK|MILLER|1300|         2|\n",
      "|    CLERK| ADAMS|1100|         3|\n",
      "|    CLERK| JAMES| 950|         4|\n",
      "|    CLERK| SMITH| 800|         5|\n",
      "|  MANAGER| JONES|2975|         1|\n",
      "|  MANAGER| BLAKE|2850|         2|\n",
      "|  MANAGER| CLARK|2450|         3|\n",
      "|PRESIDENT|  KING|5000|         1|\n",
      "+---------+------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    'job', 'ename', 'sal',\n",
    "    salJobRank.alias('salJobRank')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8b9b2958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 95:===============================>                      (117 + 2) / 200]\r",
      "\r",
      "[Stage 95:===========================================>          (161 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+-----------+\n",
      "|deptno| ename| sal|salary_rank|\n",
      "+------+------+----+-----------+\n",
      "|    10| CLARK|2450|          2|\n",
      "|    10|  KING|5000|          1|\n",
      "|    10|MILLER|1300|          3|\n",
      "|    20| ADAMS|1100|          4|\n",
      "|    20|  FORD|3000|          1|\n",
      "|    20| JONES|2975|          3|\n",
      "|    20| SCOTT|3000|          1|\n",
      "|    20| SMITH| 800|          5|\n",
      "|    30| ALLEN|1600|          2|\n",
      "|    30| BLAKE|2850|          1|\n",
      "|    30| JAMES| 950|          6|\n",
      "|    30|MARTIN|1250|          4|\n",
      "|    30|TURNER|1500|          3|\n",
      "|    30|  WARD|1250|          4|\n",
      "|    70|  JACK|3200|          1|\n",
      "+------+------+----+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 부서별 급여 순위 생성\n",
    "\n",
    "# 부서별로 파티션을 나누고 급여 기준 내림차순 정렬 윈도우 명세 설정\n",
    "windowspec = Window.partitionBy('deptno').orderBy(desc('sal'))\n",
    "\n",
    "# 순위 객체 생성\n",
    "salDeptRank = rank().over(windowspec)\n",
    "\n",
    "# 데이터프레임에 컬럼으로 추가하여 순위 부여\n",
    "df_with_rank = df.withColumn(\"salary_rank\", salDeptRank)\n",
    "\n",
    "# 결과 출력 (부서별, 이름 순으로 정렬)\n",
    "df_sorted = df_with_rank.orderBy(\"deptno\", \"ename\")\n",
    "df_sorted.select(\"deptno\", \"ename\", \"sal\", \"salary_rank\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a72bf5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----------------+\n",
      "| ename|deptno| sal|dept_salary_rank|\n",
      "+------+------+----+----------------+\n",
      "| SCOTT|    20|3000|               1|\n",
      "|  FORD|    20|3000|               1|\n",
      "| JONES|    20|2975|               3|\n",
      "| ADAMS|    20|1100|               4|\n",
      "| SMITH|    20| 800|               5|\n",
      "|  KING|    10|5000|               1|\n",
      "| CLARK|    10|2450|               2|\n",
      "|MILLER|    10|1300|               3|\n",
      "|  JACK|    70|3200|               1|\n",
      "| BLAKE|    30|2850|               1|\n",
      "| ALLEN|    30|1600|               2|\n",
      "|TURNER|    30|1500|               3|\n",
      "|  WARD|    30|1250|               4|\n",
      "|MARTIN|    30|1250|               4|\n",
      "| JAMES|    30| 950|               6|\n",
      "+------+------+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 강사님 코드\n",
    "dept_window_spec = Window.partitionBy('deptno').orderBy(desc('sal'))\n",
    "new_df = df.withColumn( 'dept_salary_rank', rank().over(dept_window_spec))\n",
    "new_df.select(\n",
    "    'ename', 'deptno', 'sal', 'dept_salary_rank'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "edb7664d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----------------+\n",
      "| ename|deptno| sal|dept_salary_rank|\n",
      "+------+------+----+----------------+\n",
      "| SCOTT|    20|3000|               1|\n",
      "|  FORD|    20|3000|               2|\n",
      "| JONES|    20|2975|               3|\n",
      "| ADAMS|    20|1100|               4|\n",
      "| SMITH|    20| 800|               5|\n",
      "|  KING|    10|5000|               1|\n",
      "| CLARK|    10|2450|               2|\n",
      "|MILLER|    10|1300|               3|\n",
      "|  JACK|    70|3200|               1|\n",
      "| BLAKE|    30|2850|               1|\n",
      "| ALLEN|    30|1600|               2|\n",
      "|TURNER|    30|1500|               3|\n",
      "|  WARD|    30|1250|               4|\n",
      "|MARTIN|    30|1250|               5|\n",
      "| JAMES|    30| 950|               6|\n",
      "+------+------+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import row_number\n",
    "new_df = df.withColumn( 'dept_salary_rank', row_number().over(dept_window_spec))\n",
    "new_df.select(\n",
    "    'ename', 'deptno', 'sal', 'dept_salary_rank'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3c814bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----------------+\n",
      "| ename|deptno| sal|dept_salary_rank|\n",
      "+------+------+----+----------------+\n",
      "| SCOTT|    20|3000|               1|\n",
      "|  FORD|    20|3000|               1|\n",
      "| JONES|    20|2975|               2|\n",
      "| ADAMS|    20|1100|               3|\n",
      "| SMITH|    20| 800|               4|\n",
      "|  KING|    10|5000|               1|\n",
      "| CLARK|    10|2450|               2|\n",
      "|MILLER|    10|1300|               3|\n",
      "|  JACK|    70|3200|               1|\n",
      "| BLAKE|    30|2850|               1|\n",
      "| ALLEN|    30|1600|               2|\n",
      "|TURNER|    30|1500|               3|\n",
      "|  WARD|    30|1250|               4|\n",
      "|MARTIN|    30|1250|               4|\n",
      "| JAMES|    30| 950|               5|\n",
      "+------+------+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import dense_rank\n",
    "new_df = df.withColumn( 'dept_salary_rank', dense_rank().over(dept_window_spec))\n",
    "new_df.select(\n",
    "    'ename', 'deptno', 'sal', 'dept_salary_rank'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e9828e",
   "metadata": {},
   "source": [
    "# ➕세 가지 함수의 차이점 요약\n",
    "\n",
    "* rank(): 동일한 값이 있을 경우 동일한 순위를 부여하고, 다음 순위는 그 값의 수만큼 건너뜁니다.\n",
    "\n",
    "* row_number(): 각 행에 고유한 순위를 부여합니다.\n",
    "\n",
    "* dense_rank(): 동일한 값이 있을 경우 동일한 순위를 부여하지만, 다음 순위는 건너뛰지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a4919f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#누적 급여 계산\n",
    "from pyspark.sql.functions import dense_rank\n",
    "sum_window_spec = Window.partitionBy('deptno').orderBy('emp_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3597160a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----------+\n",
      "| ename|deptno| sal|cum_salary|\n",
      "+------+------+----+----------+\n",
      "| SMITH|    20| 800|       800|\n",
      "| ADAMS|    20|1100|      1900|\n",
      "| JONES|    20|2975|      4875|\n",
      "| SCOTT|    20|3000|      7875|\n",
      "|  FORD|    20|3000|     10875|\n",
      "|MILLER|    10|1300|      1300|\n",
      "| CLARK|    10|2450|      3750|\n",
      "|  KING|    10|5000|      8750|\n",
      "|  JACK|    70|3200|      3200|\n",
      "| JAMES|    30| 950|       950|\n",
      "|  WARD|    30|1250|      2200|\n",
      "|MARTIN|    30|1250|      3450|\n",
      "|TURNER|    30|1500|      4950|\n",
      "| ALLEN|    30|1600|      6550|\n",
      "| BLAKE|    30|2850|      9400|\n",
      "+------+------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 윈도우 명세 설정\n",
    "sum_window_spec = Window.partitionBy('deptno').orderBy('sal').rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "# 누적 급여 컬럼 추가\n",
    "new_df = df.withColumn('cum_salary', sum('sal').over(sum_window_spec))\n",
    "\n",
    "# 결과 출력\n",
    "new_df.select('ename', 'deptno', 'sal', 'cum_salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3e63e3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----------+\n",
      "| ename|deptno| sal|cum_salary|\n",
      "+------+------+----+----------+\n",
      "| SMITH|    20| 800|       800|\n",
      "| ADAMS|    20|1100|      1900|\n",
      "| JONES|    20|2975|      4875|\n",
      "| SCOTT|    20|3000|      7875|\n",
      "|  FORD|    20|3000|     10875|\n",
      "|MILLER|    10|1300|      1300|\n",
      "| CLARK|    10|2450|      3750|\n",
      "|  KING|    10|5000|      8750|\n",
      "|  JACK|    70|3200|      3200|\n",
      "| JAMES|    30| 950|       950|\n",
      "|  WARD|    30|1250|      2200|\n",
      "|MARTIN|    30|1250|      3450|\n",
      "|TURNER|    30|1500|      4950|\n",
      "| ALLEN|    30|1600|      6550|\n",
      "| BLAKE|    30|2850|      9400|\n",
      "+------+------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 강사님 코드(에러남.)\n",
    "\n",
    "new_df = df.withColumn( 'cum_salary', sum('sal').over(sum_window_spec))\n",
    "new_df.select(\n",
    "    'ename', 'deptno', 'sal', 'cum_salary'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a3f9d6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|deptno|   dept_avg_salary|\n",
      "+------+------------------+\n",
      "|    20|            2175.0|\n",
      "|    20|            2175.0|\n",
      "|    20|            2175.0|\n",
      "|    20|            2175.0|\n",
      "|    20|            2175.0|\n",
      "|    10|2916.6666666666665|\n",
      "|    10|2916.6666666666665|\n",
      "|    10|2916.6666666666665|\n",
      "|    70|            3200.0|\n",
      "|    30|1566.6666666666667|\n",
      "|    30|1566.6666666666667|\n",
      "|    30|1566.6666666666667|\n",
      "|    30|1566.6666666666667|\n",
      "|    30|1566.6666666666667|\n",
      "|    30|1566.6666666666667|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 부서별 평균 급여 avg('sal')\n",
    "from pyspark.sql.functions import dense_rank\n",
    "avg_window_spec = Window.partitionBy('deptno')\n",
    "new_avg_df = df.withColumn('dept_avg_salary', avg('sal').over(avg_window_spec))\n",
    "new_avg_df.select('deptno', 'dept_avg_salary',).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5145160",
   "metadata": {},
   "source": [
    "#sql select문\n",
    "```\n",
    "SELECT  #projection\n",
    "ename, deptno, sal,\n",
    "avg('sal').over(partition by deptno) as dept_avg_salary\n",
    "from emp;  #filter\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e86338e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+-----------+-----------+\n",
      "| ename|deptno| sal|prev_salary|next_salary|\n",
      "+------+------+----+-----------+-----------+\n",
      "| SMITH|    20| 800|       null|       2975|\n",
      "| JONES|    20|2975|        800|       3000|\n",
      "| SCOTT|    20|3000|       2975|       1100|\n",
      "| ADAMS|    20|1100|       3000|       3000|\n",
      "|  FORD|    20|3000|       1100|       null|\n",
      "| CLARK|    10|2450|       null|       5000|\n",
      "|  KING|    10|5000|       2450|       1300|\n",
      "|MILLER|    10|1300|       5000|       null|\n",
      "|  JACK|    70|3200|       null|       null|\n",
      "| ALLEN|    30|1600|       null|       1250|\n",
      "|  WARD|    30|1250|       1600|       1250|\n",
      "|MARTIN|    30|1250|       1250|       2850|\n",
      "| BLAKE|    30|2850|       1250|       1500|\n",
      "|TURNER|    30|1500|       2850|        950|\n",
      "| JAMES|    30| 950|       1500|       null|\n",
      "+------+------+----+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lead, lag 이전 급여 , 이후 급여\n",
    "\n",
    "from pyspark.sql.functions import lag, lead\n",
    "\n",
    "row_window_spec = Window.partitionBy('deptno').orderBy('empno')\n",
    "\n",
    "#이전급여 컬럼, 이후급여 컬럼 2개 추가\n",
    "lead_lagg_sal_df = df.withColumn('prev_salary', lag('sal').over(row_window_spec))\\\n",
    "            .withColumn('next_salary', lead('sal').over(row_window_spec))\n",
    "\n",
    "lead_lagg_sal_df.select('ename', 'deptno', 'sal',  'prev_salary', 'next_salary').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d41b9d4",
   "metadata": {},
   "source": [
    "```\n",
    "select \n",
    "ename, deptno, sal,\n",
    "LAG(sal)  OVER( partition by deptno order by empno ) as prev_salary\n",
    "LEAD(sal) OVER( partition by deptno order by empno ) as next_salary\n",
    "from emp;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01efa1bc",
   "metadata": {},
   "source": [
    "# rollup, cube\n",
    "\n",
    "over(), groupby()\n",
    "rollup : 계층적집계, 부분합(subtotal), 총합(grandtotal)\n",
    "cube : 모든 값으로 부분합 , 결합 가능합 모든 값의 부분합을 구한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681d709f",
   "metadata": {},
   "source": [
    "![이미지 설명](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fp9c2J%2Fbtrb1c2Ueeu%2FzcK1NtXCOGskC4ha6N5Jek%2Fimg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa04a0a",
   "metadata": {},
   "source": [
    "![이미지 설명](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbnZqja%2FbtrbV1uygXO%2FsDSQBLXRbfaCniIcTgQZgk%2Fimg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "af03f0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[empno: int, ename: string, job: string, mgr: int, hiredate: string, sal: int, comm: int, deptno: int]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "268b2798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------+\n",
      "|deptno|      job|count(1)|sum(sal)|\n",
      "+------+---------+--------+--------+\n",
      "|    10|    CLERK|       1|    1300|\n",
      "|    10|  MANAGER|       1|    2450|\n",
      "|    10|PRESIDENT|       1|    5000|\n",
      "|    20|  ANALYST|       2|    6000|\n",
      "|    20|    CLERK|       2|    1900|\n",
      "|    20|  MANAGER|       1|    2975|\n",
      "|    30|    CLERK|       1|     950|\n",
      "|    30|  MANAGER|       1|    2850|\n",
      "|    30| SALESMAN|       4|    5600|\n",
      "|    70|    CLERK|       1|    3200|\n",
      "+------+---------+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 177:==========================================>          (159 + 3) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#그룹화 > 소계\n",
    "\n",
    "df.groupBy('deptno', 'job').agg(count('*'),sum('sal')).orderBy('deptno', 'job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "230443a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 179:==================================>                  (131 + 2) / 200]\r",
      "\r",
      "[Stage 179:===================================================> (194 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------+\n",
      "|deptno|      job|count(1)|sum(sal)|\n",
      "+------+---------+--------+--------+\n",
      "|  null|     null|      15|   32225|\n",
      "|    10|     null|       3|    8750|\n",
      "|    10|    CLERK|       1|    1300|\n",
      "|    10|  MANAGER|       1|    2450|\n",
      "|    10|PRESIDENT|       1|    5000|\n",
      "|    20|     null|       5|   10875|\n",
      "|    20|  ANALYST|       2|    6000|\n",
      "|    20|    CLERK|       2|    1900|\n",
      "|    20|  MANAGER|       1|    2975|\n",
      "|    30|     null|       6|    9400|\n",
      "|    30|    CLERK|       1|     950|\n",
      "|    30|  MANAGER|       1|    2850|\n",
      "|    30| SALESMAN|       4|    5600|\n",
      "|    70|     null|       1|    3200|\n",
      "|    70|    CLERK|       1|    3200|\n",
      "+------+---------+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.rollup('deptno', 'job').agg(count('*'), sum('sal')).orderBy('deptno', 'job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "eb238738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------+\n",
      "|deptno|      job|count(1)|sum(sal)|\n",
      "+------+---------+--------+--------+\n",
      "|  null|     null|      15|   32225|\n",
      "|  null|  ANALYST|       2|    6000|\n",
      "|  null|    CLERK|       5|    7350|\n",
      "|  null|  MANAGER|       3|    8275|\n",
      "|  null|PRESIDENT|       1|    5000|\n",
      "|  null| SALESMAN|       4|    5600|\n",
      "|    10|     null|       3|    8750|\n",
      "|    10|    CLERK|       1|    1300|\n",
      "|    10|  MANAGER|       1|    2450|\n",
      "|    10|PRESIDENT|       1|    5000|\n",
      "|    20|     null|       5|   10875|\n",
      "|    20|  ANALYST|       2|    6000|\n",
      "|    20|    CLERK|       2|    1900|\n",
      "|    20|  MANAGER|       1|    2975|\n",
      "|    30|     null|       6|    9400|\n",
      "|    30|    CLERK|       1|     950|\n",
      "|    30|  MANAGER|       1|    2850|\n",
      "|    30| SALESMAN|       4|    5600|\n",
      "|    70|     null|       1|    3200|\n",
      "|    70|    CLERK|       1|    3200|\n",
      "+------+---------+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 181:================================================>    (183 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.cube('deptno', 'job').agg(count('*'), sum('sal')).orderBy('deptno', 'job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ae613dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+----------+\n",
      "|deptno|      job|max_salary|min_salary|\n",
      "+------+---------+----------+----------+\n",
      "|  null|     null|      5000|       800|\n",
      "|    10|     null|      5000|      1300|\n",
      "|    10|    CLERK|      1300|      1300|\n",
      "|    10|  MANAGER|      2450|      2450|\n",
      "|    10|PRESIDENT|      5000|      5000|\n",
      "|    20|     null|      3000|       800|\n",
      "|    20|  ANALYST|      3000|      3000|\n",
      "|    20|    CLERK|      1100|       800|\n",
      "|    20|  MANAGER|      2975|      2975|\n",
      "|    30|     null|      2850|       950|\n",
      "|    30|    CLERK|       950|       950|\n",
      "|    30|  MANAGER|      2850|      2850|\n",
      "|    30| SALESMAN|      1600|      1250|\n",
      "|    70|     null|      3200|      3200|\n",
      "|    70|    CLERK|      3200|      3200|\n",
      "+------+---------+----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 187:==================================================>  (190 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#롤업 -> 대,중분류 최대/최소값\n",
    "\n",
    "# 롤업 및 집계\n",
    "result_df = df.rollup('deptno', 'job').agg(\n",
    "    max('sal').alias('max_salary'),\n",
    "    min('sal').alias('min_salary')\n",
    ").orderBy('deptno', 'job')\n",
    "\n",
    "# 결과 출력\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb4340",
   "metadata": {},
   "source": [
    "```\n",
    "select\n",
    "    deptno, job,\n",
    "    max(sal) as max_sal,\n",
    "    min(sal) as min_sal,\n",
    "from emp\n",
    "group by rollup(deptno, job)\n",
    "order by deptno, job;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e713093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+------------+\n",
      "|      job|        avg_salary|total_salary|\n",
      "+---------+------------------+------------+\n",
      "|  ANALYST|            3000.0|        6000|\n",
      "| SALESMAN|            1400.0|        5600|\n",
      "|    CLERK|            1470.0|        7350|\n",
      "|  MANAGER|2758.3333333333335|        8275|\n",
      "|PRESIDENT|            5000.0|        5000|\n",
      "+---------+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 직무별 평균 급여 및 총 급여 계산\n",
    "job_salary_df = df.groupBy('job').agg(\n",
    "    avg('sal').alias('avg_salary'),\n",
    "    sum('sal').alias('total_salary')\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "job_salary_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "33e0c505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 211:================================>                    (122 + 2) / 200]\r",
      "\r",
      "[Stage 211:===============================================>     (179 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+----------+\n",
      "|deptno|      job|avg_salary|max_salary|\n",
      "+------+---------+----------+----------+\n",
      "|  null|     null|   2148.33|      5000|\n",
      "|  null|  ANALYST|    3000.0|      3000|\n",
      "|  null|    CLERK|    1470.0|      3200|\n",
      "|  null|  MANAGER|   2758.33|      2975|\n",
      "|  null|PRESIDENT|    5000.0|      5000|\n",
      "|  null| SALESMAN|    1400.0|      1600|\n",
      "|    10|     null|   2916.67|      5000|\n",
      "|    10|    CLERK|    1300.0|      1300|\n",
      "|    10|  MANAGER|    2450.0|      2450|\n",
      "|    10|PRESIDENT|    5000.0|      5000|\n",
      "|    20|     null|    2175.0|      3000|\n",
      "|    20|  ANALYST|    3000.0|      3000|\n",
      "|    20|    CLERK|     950.0|      1100|\n",
      "|    20|  MANAGER|    2975.0|      2975|\n",
      "|    30|     null|   1566.67|      2850|\n",
      "|    30|    CLERK|     950.0|       950|\n",
      "|    30|  MANAGER|    2850.0|      2850|\n",
      "|    30| SALESMAN|    1400.0|      1600|\n",
      "|    70|     null|    3200.0|      3200|\n",
      "|    70|    CLERK|    3200.0|      3200|\n",
      "+------+---------+----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import round\n",
    "\n",
    "# 부서별 및 직무별 평균 급여, 최대 급여 계산 및 소계 (소수점 둘째 자리까지)\n",
    "dept_job_salary_df = df.cube('deptno', 'job').agg(\n",
    "    round(avg('sal'), 2).alias('avg_salary'),\n",
    "    max('sal').alias('max_salary')\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "dept_job_salary_df.orderBy('deptno', 'job').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d31be8a",
   "metadata": {},
   "source": [
    "```\n",
    "select\n",
    "    deptno, job,\n",
    "    max(sal) as max_sal,\n",
    "    min(sal) as min_sal,\n",
    "from emp\n",
    "group by rollup(deptno, job)\n",
    "order by deptno, job;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9d807630",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b958c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
