{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b1a2cdd-912e-4f3e-a4dd-b822b9e1d6da",
   "metadata": {},
   "source": [
    "# 전체 과정\n",
    "- 데이터 준비 > 전처리 >  피처선택 > 모델 학습 > 모델의 성능, 결과 평가 > 예측값 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c5a881-9647-4fa5-a742-ee75a160ed5b",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c6a9f2-4e69-4051-b093-0aee93892362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/13 13:42:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"241212_01_MLlib_clustering\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b570793-19c9-4acb-be1f-c7705c8916ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성\n",
    "data = [\n",
    "    (0, 0, 4.0),  # user 0 rated item 0 with 4.0\n",
    "    (0, 1, 2.0),\n",
    "    (1, 1, 3.0),\n",
    "    (1, 2, 1.0),\n",
    "    (2, 0, 5.0),\n",
    "    (2, 2, 4.0)\n",
    "]\n",
    "\n",
    "columns = [\"user_id\", \"item_id\", \"rating\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc0d574-cdf9-4c04-9af4-c14d881db0ed",
   "metadata": {},
   "source": [
    "## 피처선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cef93927-5377-4840-a6c1-4cdf2ec14319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|user_id|item_id|rating|\n",
      "+-------+-------+------+\n",
      "|      0|      0|   4.0|\n",
      "|      0|      1|   2.0|\n",
      "|      1|      1|   3.0|\n",
      "|      1|      2|   1.0|\n",
      "|      2|      0|   5.0|\n",
      "|      2|      2|   4.0|\n",
      "+-------+-------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "rating_df = spark.createDataFrame(data, columns)\n",
    "rating_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "190597f2-a7bd-4be7-b939-fec7bedda50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user, item - rating 정보를 >> 사용자 그룹을 만든다. > 모델 > 예측 결과 - 그룹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65885e40-7ab3-4b53-a3bb-7278b8535df1",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e9f025a-8c7f-4048-a360-d9fc4d9c9d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "user_item_matrix = rating_df.groupBy(\"user_id\").pivot(\"item_id\").avg(\"rating\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2e4add5-fea7-4ce3-bf46-de9239964901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+---+\n",
      "|user_id|  0|  1|  2|\n",
      "+-------+---+---+---+\n",
      "|      0|4.0|2.0|0.0|\n",
      "|      1|0.0|3.0|1.0|\n",
      "|      2|5.0|0.0|4.0|\n",
      "+-------+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_item_matrix.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96809bd9-5af9-4b36-a64d-893be29016fc",
   "metadata": {},
   "source": [
    "## 피처 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43bbed9b-a15f-473d-b803-deb444d46fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88cbb934-6435-427a-8831-ae29c58a5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[\"0\",\"1\",\"2\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "837821b3-2f80-418e-a063-afb9eb962f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+---+-------------+\n",
      "|user_id|  0|  1|  2|     features|\n",
      "+-------+---+---+---+-------------+\n",
      "|      0|4.0|2.0|0.0|[4.0,2.0,0.0]|\n",
      "|      1|0.0|3.0|1.0|[0.0,3.0,1.0]|\n",
      "|      2|5.0|0.0|4.0|[5.0,0.0,4.0]|\n",
      "+-------+---+---+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_features = assembler.transform(user_item_matrix)\n",
    "user_features.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0766b0dd-a165-413b-80b4-529d78ee6517",
   "metadata": {},
   "source": [
    "## 모델 생성 > 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7268425-d173-4d9d-970e-896ee8e6bba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans_6fa051fe0ab8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "#모델 생성\n",
    "kmeans = KMeans(k=2, seed=1, featuresCol=\"features\", predictionCol=\"cluster\")\n",
    "kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59768240-ad6d-4299-9130-fd3a1996f0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/13 14:13:36 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "24/12/13 14:13:36 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeansModel: uid=KMeans_6fa051fe0ab8, k=2, distanceMeasure=euclidean, numFeatures=3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 학습\n",
    "model = kmeans.fit(user_features)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "067eda65-26de-4c96-b1fb-c62060686dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델을 이용한 예측\n",
    "clusters = model.transform(user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c93f4ffe-5e09-4ef7-b20f-3502811f6ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+---+-------------+-------+\n",
      "|user_id|  0|  1|  2|     features|cluster|\n",
      "+-------+---+---+---+-------------+-------+\n",
      "|      0|4.0|2.0|0.0|[4.0,2.0,0.0]|      0|\n",
      "|      1|0.0|3.0|1.0|[0.0,3.0,1.0]|      0|\n",
      "|      2|5.0|0.0|4.0|[5.0,0.0,4.0]|      1|\n",
      "+-------+---+---+---+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 유저의 클러스터링 결과\n",
    "clusters.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9d7762-3abf-46be-8414-aab4124cd6e4",
   "metadata": {},
   "source": [
    "## 클러스터링 과정 요약\n",
    "> 사용자 그룹화 : 유사한 취향의 사용자끼리 그룹으로 묶어주는 것.  \n",
    "> 아이템 그룹화 : 아이템 간의 군집화를 통해 사용자에게 추천해 줄 수 있음.\n",
    "\n",
    "➕ 요약\n",
    "\n",
    "1. **데이터 프레임 생성**\n",
    "주어진 데이터와 열 이름을 사용하여 데이터프레임을 생성하고 출력함.\n",
    "\n",
    "2. **유저-아이템 매트릭스 생성**\n",
    "평점 데이터를 피벗 테이블 형태로 변환하여 사용자별 아이템 평균 평점을 매트릭스로 만듦.\n",
    "\n",
    "3. **피처 벡터 생성**\n",
    "각 사용자의 평점 데이터를 피처 벡터로 변환함.\n",
    "\n",
    "4. **KMeans 클러스터링 모델 생성**\n",
    "KMeans 클러스터링 모델을 생성하고 학습시킴.\n",
    "\n",
    "5. **모델을 이용한 예측**\n",
    "학습된 모델을 사용해 사용자 데이터를 클러스터링함.\n",
    "\n",
    "6. **추가 학습 정보**\n",
    "- 평균 점수를 매트릭스로 만든다:\n",
    "사용자가 동일한 아이템에 여러 번 평가했을 때, 그 평가 점수의 평균 값을 사용하는 것임.\n",
    "\n",
    "- 클러스터의 기준:\n",
    "KMeans 클러스터링에서 각 데이터 포인트는 임의로 선택된 초기 중심에 할당되고, 그 후 데이터와 중심 사이의 거리를 계산하여 중심을 반복적으로 조정함. 이렇게 중심을 조정하는 과정에서 데이터가 속한 클러스터도 변할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5dda6d0-3f15-4bae-b091-09f122982600",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
