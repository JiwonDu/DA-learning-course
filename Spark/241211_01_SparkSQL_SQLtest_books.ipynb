{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecb489c9-0377-42d1-90b7-dc43fdb1d217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/11 10:28:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# SparkSession 생성\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"241211_01_SparkSQL_SQLtest\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb6d3db-cc73-4e7c-a5b0-ce93930c2e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "user_data = [\n",
    "    Row(user_id=1, username='A', address='서울'),\n",
    "    Row(user_id=2, username='B', address='대전'),\n",
    "    Row(user_id=3, username='C', address='경기도'),\n",
    "    Row(user_id=4, username='D', address=None),\n",
    "    Row(user_id=5, username='E', address=None),\n",
    "    Row(user_id=6, username='F', address='서울'),\n",
    "    Row(user_id=7, username='G', address='경기도'),\n",
    "    Row(user_id=8, username='H', address='대구'),\n",
    "    Row(user_id=9, username='I', address='부산'),\n",
    "    Row(user_id=10, username='J', address='전주'),\n",
    "    Row(user_id=11, username='K', address='광주')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0269e5f-46ea-450d-a07b-91cc1cbf95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = spark.createDataFrame(user_data)\n",
    "user_df.createOrReplaceTempView('users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b670172-afc0-42fd-98be-ad279f15ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data = [\n",
    "    Row(book_id=1, title=\"Book A\", author_fname=\"John\", author_lname=\"Doe\", pages=300, released_year=2005, stock_quantity=55),\n",
    "    Row(book_id=2, title=\"Book B\", author_fname=\"Jane\", author_lname=\"Smith\", pages=250, released_year=2010, stock_quantity=40),\n",
    "    Row(book_id=3, title=\"Book C\", author_fname=\"Emily\", author_lname=\"Jones\", pages=180, released_year=2015, stock_quantity=20),\n",
    "    Row(book_id=4, title=\"Book D\", author_fname=\"Chris\", author_lname=\"Brown\", pages=320, released_year=2012, stock_quantity=75),\n",
    "    Row(book_id=5, title=\"Book E\", author_fname=\"Anna\", author_lname=\"Davis\", pages=270, released_year=2008, stock_quantity=35)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d61b8788-8f47-4eb4-b6e8-5d55dabcd929",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = spark.createDataFrame(books_data)\n",
    "books_df.createOrReplaceTempView('books')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90c9be84-4a63-43dd-93b2-38342e2f51f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+\n",
      "|user_id|username|address|\n",
      "+-------+--------+-------+\n",
      "|      1|       A|   서울|\n",
      "|      2|       B|   대전|\n",
      "|      3|       C| 경기도|\n",
      "|      4|       D|   null|\n",
      "|      5|       E|   null|\n",
      "|      6|       F|   서울|\n",
      "|      7|       G| 경기도|\n",
      "|      8|       H|   대구|\n",
      "|      9|       I|   부산|\n",
      "|     10|       J|   전주|\n",
      "|     11|       K|   광주|\n",
      "+-------+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "query_users = '''\n",
    "select * from users;\n",
    "'''\n",
    "spark.sql(query_users).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b626bf7-ee38-4cea-b864-2c7757c3f37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|username| address|\n",
      "+--------+--------+\n",
      "|       A|    서울|\n",
      "|       B|    대전|\n",
      "|       C|  경기도|\n",
      "|       D|주소없음|\n",
      "|       E|주소없음|\n",
      "|       F|    서울|\n",
      "|       G|  경기도|\n",
      "|       H|    대구|\n",
      "|       I|    부산|\n",
      "|       J|    전주|\n",
      "|       K|    광주|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_users = '''\n",
    "SELECT username, \n",
    "\tIF(address IS NULL, '주소없음', address) AS address \n",
    "FROM users;\n",
    "'''\n",
    "spark.sql(query_users).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b942071c-804b-4fd2-9928-2f78c951e3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|address|region|\n",
      "+-------+------+\n",
      "|   서울|수도권|\n",
      "|   대전|  지방|\n",
      "| 경기도|수도권|\n",
      "|   null|  지방|\n",
      "|   null|  지방|\n",
      "|   서울|수도권|\n",
      "| 경기도|수도권|\n",
      "|   대구|  지방|\n",
      "|   부산|  지방|\n",
      "|   전주|  지방|\n",
      "|   광주|  지방|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_users = '''\n",
    "SELECT address, \n",
    "\t   IF(address IN ('경기도', '서울'), '수도권', '지방') AS region \n",
    "FROM users;\n",
    "'''\n",
    "spark.sql(query_users).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cafc9c36-8a90-4e24-b72e-a130fb3c7cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|stock_quantity|quantity_level|\n",
      "+--------------+--------------+\n",
      "|            55|     재고 많음|\n",
      "|            40|     재고 중간|\n",
      "|            20|     재고 없음|\n",
      "|            75|     재고 많음|\n",
      "|            35|     재고 중간|\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# books table\n",
    "# stock_quantity >=50 '재고 많음', >= 30 '재고 중간', '재고 없음'\n",
    "books_sql = '''\n",
    "SELECT stock_quantity, \n",
    "\t   IF(stock_quantity >= 50, '재고 많음',\n",
    "\t\t  IF(stock_quantity >= 30, '재고 중간', '재고 없음')) AS quantity_level\n",
    "FROM books;\n",
    "'''\n",
    "spark.sql(books_sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be49efc2-1649-48d5-8b42-af45183c54de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|stock_quantity|quantity_level|\n",
      "+--------------+--------------+\n",
      "|            55|     재고 많음|\n",
      "|            40|     재고 중간|\n",
      "|            20|     재고 부족|\n",
      "|            75|     재고 많음|\n",
      "|            35|     재고 중간|\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_sql_1= '''\n",
    "SELECT stock_quantity, \n",
    "\t   CASE \n",
    "\t\t   WHEN stock_quantity >= 50 THEN '재고 많음'\n",
    "\t\t   WHEN stock_quantity >= 30 THEN '재고 중간'\n",
    "\t\t   ELSE '재고 부족'\n",
    "\t   END AS quantity_level\n",
    "FROM books;\n",
    "'''\n",
    "spark.sql(books_sql_1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4775965-171f-451f-9ba9-fe4b8be04b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [stock_quantity#12L, if ((stock_quantity#12L >= 50)) 재고 많음 else if ((stock_quantity#12L >= 30)) 재고 중간 else 재고 없음 AS quantity_level#96]\n",
      "+- *(1) Scan ExistingRDD[book_id#6L,title#7,author_fname#8,author_lname#9,pages#10L,released_year#11L,stock_quantity#12L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행계획 비교\n",
    "spark.sql(books_sql).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "193d4f07-ece4-4ce1-8dfa-ac28669e92c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [stock_quantity#12L, CASE WHEN (stock_quantity#12L >= 50) THEN 재고 많음 WHEN (stock_quantity#12L >= 30) THEN 재고 중간 ELSE 재고 부족 END AS quantity_level#99]\n",
      "+- *(1) Scan ExistingRDD[book_id#6L,title#7,author_fname#8,author_lname#9,pages#10L,released_year#11L,stock_quantity#12L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(books_sql_1).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4122281-c11a-4c92-88d0-7e464299dcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[author_lname#9], functions=[])\n",
      "+- Exchange hashpartitioning(author_lname#9, 200), ENSURE_REQUIREMENTS, [id=#111]\n",
      "   +- *(1) HashAggregate(keys=[author_lname#9], functions=[])\n",
      "      +- *(1) Project [author_lname#9]\n",
      "         +- *(1) Scan ExistingRDD[book_id#6L,title#7,author_fname#8,author_lname#9,pages#10L,released_year#11L,stock_quantity#12L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_sql_2 = '''\n",
    "select distinct author_lname from books;\n",
    "'''\n",
    "spark.sql(books_sql_2).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34c77c00-0942-4291-b099-cbc516adee4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[author_lname#9], functions=[count(1)])\n",
      "+- Exchange hashpartitioning(author_lname#9, 200), ENSURE_REQUIREMENTS, [id=#132]\n",
      "   +- *(1) HashAggregate(keys=[author_lname#9], functions=[partial_count(1)])\n",
      "      +- *(1) Project [author_lname#9]\n",
      "         +- *(1) Scan ExistingRDD[book_id#6L,title#7,author_fname#8,author_lname#9,pages#10L,released_year#11L,stock_quantity#12L]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|author_lname|count(1)|\n",
      "+------------+--------+\n",
      "|       Jones|       1|\n",
      "|       Davis|       1|\n",
      "|       Smith|       1|\n",
      "|         Doe|       1|\n",
      "|       Brown|       1|\n",
      "+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_sql_3 = '''\n",
    "select author_lname, count(*)\n",
    "from books\n",
    "group by author_lname;\n",
    "'''\n",
    "spark.sql(books_sql_3).explain()\n",
    "spark.sql(books_sql_3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94ba8bb-221d-499b-a387-768255e76bf3",
   "metadata": {},
   "source": [
    "# 데이터 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b67892c-8246-401e-a3ef-b96ab6de1d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# books 테이블 데이터에 borrowed_by 추가\n",
    "books_data_with_user = [\n",
    "    Row(book_id=1, title=\"Book A\", author_fname=\"John\", author_lname=\"Doe\", pages=300, released_year=2005, stock_quantity=55, borrowed_by=1),\n",
    "    Row(book_id=2, title=\"Book B\", author_fname=\"Jane\", author_lname=\"Smith\", pages=250, released_year=2010, stock_quantity=40, borrowed_by=2),\n",
    "    Row(book_id=3, title=\"Book C\", author_fname=\"Emily\", author_lname=\"Jones\", pages=180, released_year=2015, stock_quantity=20, borrowed_by=3),\n",
    "    Row(book_id=4, title=\"Book D\", author_fname=\"Chris\", author_lname=\"Brown\", pages=320, released_year=2012, stock_quantity=75, borrowed_by=None),\n",
    "    Row(book_id=5, title=\"Book E\", author_fname=\"Anna\", author_lname=\"Davis\", pages=270, released_year=2008, stock_quantity=35, borrowed_by=6)\n",
    "]\n",
    "\n",
    "# DataFrame 생성\n",
    "books_df_with_user = spark.createDataFrame(books_data_with_user)\n",
    "\n",
    "# Temp View 등록\n",
    "books_df_with_user.createOrReplaceTempView(\"books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476d44a-8cc9-4a6f-b098-41fbba8ed9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrowed_by 컬럼 추가 및 데이터 입력\n",
    "updated_books_df = books_df.withColumn(\n",
    "    \"borrowed_by\",\n",
    "    when(books_df.book_id == 1, 1)\n",
    "    .when(books_df.book_id == 2, 2)\n",
    "    .when(books_df.book_id == 3, 3)\n",
    "    .when(books_df.book_id == 4, lit(None))\n",
    "    .when(books_df.book_id == 5, 6)\n",
    "    .otherwise(None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b13f49a5-c68b-4b7d-b10d-3863d158be3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|book_id| title|author_fname|author_lname|pages|released_year|stock_quantity|borrowed_by|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|      1|Book A|        John|         Doe|  300|         2005|            55|          1|\n",
      "|      2|Book B|        Jane|       Smith|  250|         2010|            40|          2|\n",
      "|      3|Book C|       Emily|       Jones|  180|         2015|            20|          3|\n",
      "|      4|Book D|       Chris|       Brown|  320|         2012|            75|       null|\n",
      "|      5|Book E|        Anna|       Davis|  270|         2008|            35|          6|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_sql = '''\n",
    "SELECT *\n",
    "FROM books;\n",
    "'''\n",
    "spark.sql(books_sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5542084-f31f-40f0-b6e9-00de4fe3eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75ef86cf-bcff-49a0-afa7-aa41f5b30642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|book_id| title|author_fname|author_lname|pages|released_year|stock_quantity|borrowed_by|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|      1|Book A|        John|         Doe|  300|         2005|            55|          1|\n",
      "|      2|Book B|        Jane|       Smith|  250|         2010|            40|          2|\n",
      "|      3|Book C|       Emily|       Jones|  180|         2015|            50|          3|\n",
      "|      4|Book D|       Chris|       Brown|  320|         2012|            75|       null|\n",
      "|      5|Book E|        Anna|       Davis|  270|         2008|            35|          6|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#book_id = 3, stock_quantity=50으로 바꾼다. > 전처리 과정\n",
    "\n",
    "updated_books_df = books_df_with_user.withColumn(\n",
    "    \"stock_quantity\",\n",
    "    when(books_df_with_user.book_id == 3, 50).otherwise(books_df_with_user.stock_quantity)\n",
    ")\n",
    "updated_books_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b1d18a5-69ac-4098-b20a-bcc97cc8708d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|book_id| title|author_fname|author_lname|pages|released_year|stock_quantity|borrowed_by|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|      1|Book A|        John|         Doe|  300|         2005|          60.5|          1|\n",
      "|      2|Book B|        Jane|       Smith|  250|         2010|          44.0|          2|\n",
      "|      3|Book C|       Emily|       Jones|  180|         2015|          22.0|          3|\n",
      "|      4|Book D|       Chris|       Brown|  320|         2012|          82.5|       null|\n",
      "|      5|Book E|        Anna|       Davis|  270|         2008|          38.5|          6|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stock_quantity * 10% 증가\n",
    "updated_books_df = books_df_with_user.withColumn(\n",
    "    \"stock_quantity\",\n",
    "    round(col(\"stock_quantity\") * 1.10, 2)\n",
    ")\n",
    "\n",
    "#뷰로 등록\n",
    "updated_books_df.createOrReplaceTempView(\"books\")\n",
    "spark.sql(\"select * from books\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c31f6d4-34bd-4aeb-8367-89720333301d",
   "metadata": {},
   "source": [
    "# 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f360ad5-2ecb-4e1f-b37b-7c9a8dbc72f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write 의 저장 mode : overwrite, append, ignore, error\n",
    "\n",
    "updated_books_df.write.csv(\"data/output/sqltest_updated_books.csv\", header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7255c50f-976c-4b54-8981-1782d144e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.write.csv(\"data/output/sqltest_updated_users.csv\", header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b456155b-768c-47b5-80a4-5b3cfb635ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_books_df1 = spark.read.csv(\"data/output/sqltest_updated_books.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72f7ffa5-2e3f-403b-8b9b-8a72ac12f0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df1 = spark.read.csv(\"data/output/sqltest_updated_users.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "027ca5ae-2f65-4f7a-95ba-08e23e6a7ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|book_id| title|author_fname|author_lname|pages|released_year|stock_quantity|borrowed_by|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|      3|Book C|       Emily|       Jones|  180|         2015|          22.0|          3|\n",
      "|      4|Book D|       Chris|       Brown|  320|         2012|          82.5|       null|\n",
      "|      5|Book E|        Anna|       Davis|  270|         2008|          38.5|          6|\n",
      "|      1|Book A|        John|         Doe|  300|         2005|          60.5|          1|\n",
      "|      2|Book B|        Jane|       Smith|  250|         2010|          44.0|          2|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "updated_books_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c08dab6-919d-446c-8d8c-5a9bebd83a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+\n",
      "|user_id|username|address|\n",
      "+-------+--------+-------+\n",
      "|      6|       F|   서울|\n",
      "|      7|       G| 경기도|\n",
      "|      8|       H|   대구|\n",
      "|      9|       I|   부산|\n",
      "|     10|       J|   전주|\n",
      "|     11|       K|   광주|\n",
      "|      1|       A|   서울|\n",
      "|      2|       B|   대전|\n",
      "|      3|       C| 경기도|\n",
      "|      4|       D|   null|\n",
      "|      5|       E|   null|\n",
      "+-------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a67237a-3233-48c2-8098-ab1f22625d1b",
   "metadata": {},
   "source": [
    "# 조인 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7d01344-ddc6-43f1-a7cf-e53764c5fa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+--------+-------+\n",
      "|book_id| title|author_fname|author_lname|username|address|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "|      5|Book E|        Anna|       Davis|       F|   서울|\n",
      "|      1|Book A|        John|         Doe|       A|   서울|\n",
      "|      3|Book C|       Emily|       Jones|       C| 경기도|\n",
      "|      2|Book B|        Jane|       Smith|       B|   대전|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#book_id, title, author_fname, author_lname, username, address\n",
    "join_query = '''\n",
    "SELECT book_id, title, author_fname, author_lname, username, address\n",
    "FROM books b INNER JOIN users u ON b.borrowed_by = u.user_id;\n",
    "'''\n",
    "spark.sql(join_query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "191845ac-26ce-4569-9318-5196508e5d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+--------+-------+\n",
      "|book_id| title|author_fname|author_lname|username|address|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "|      4|Book D|       Chris|       Brown|    null|   null|\n",
      "|      5|Book E|        Anna|       Davis|       F|   서울|\n",
      "|      1|Book A|        John|         Doe|       A|   서울|\n",
      "|      3|Book C|       Emily|       Jones|       C| 경기도|\n",
      "|      2|Book B|        Jane|       Smith|       B|   대전|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# books LEFT JOIN users\n",
    "join_query2 = '''\n",
    "SELECT book_id, title, author_fname, author_lname, username, address\n",
    "FROM books b LEFT JOIN users u ON b.borrowed_by = u.user_id;\n",
    "'''\n",
    "spark.sql(join_query2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5eed360b-352a-4e80-9971-655bee1111bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+--------+-------+\n",
      "|book_id| title|author_fname|author_lname|username|address|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "|   null|  null|        null|        null|       G| 경기도|\n",
      "|      5|Book E|        Anna|       Davis|       F|   서울|\n",
      "|   null|  null|        null|        null|       I|   부산|\n",
      "|   null|  null|        null|        null|       E|   null|\n",
      "|      1|Book A|        John|         Doe|       A|   서울|\n",
      "|   null|  null|        null|        null|       J|   전주|\n",
      "|      3|Book C|       Emily|       Jones|       C| 경기도|\n",
      "|   null|  null|        null|        null|       H|   대구|\n",
      "|   null|  null|        null|        null|       K|   광주|\n",
      "|      2|Book B|        Jane|       Smith|       B|   대전|\n",
      "|   null|  null|        null|        null|       D|   null|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 사용자의 책 대여 목록 > 전체 사용자 > 대여한 정보가 있으면 나오면, 없으면 NULL\n",
    "# books RIGHT JOIN users\n",
    "join_query3 = '''\n",
    "SELECT book_id, title, author_fname, author_lname, username, address\n",
    "FROM books b RIGHT JOIN users u ON b.borrowed_by = u.user_id;\n",
    "'''\n",
    "spark.sql(join_query3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466b1103-296a-4aad-a84a-870b97b52ad8",
   "metadata": {},
   "source": [
    "## ➕ 추가\n",
    "| JOIN 유형     | 설명                                                             | 예시                                                 |\n",
    "|---------------|------------------------------------------------------------------|------------------------------------------------------|\n",
    "| `INNER JOIN`  | 두 테이블 모두에 존재하는 공통 데이터만 가져옴                  | `INNER JOIN users u ON b.borrowed_by = u.user_id`    |\n",
    "| `LEFT JOIN`   | 왼쪽 테이블의 모든 데이터를 가져오고, 일치하는 오른쪽 데이터를 포함 | `LEFT JOIN users u ON b.borrowed_by = u.user_id`     |\n",
    "| `RIGHT JOIN`  | 오른쪽 테이블의 모든 데이터를 가져오고, 일치하는 왼쪽 데이터를 포함 | `RIGHT JOIN users u ON b.borrowed_by = u.user_id`    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8298b907-72d2-49b1-891a-95a4939faea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+--------+-------+\n",
      "|book_id| title|author_fname|author_lname|username|address|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "|      5|Book E|        Anna|       Davis|       F|   서울|\n",
      "|      1|Book A|        John|         Doe|       A|   서울|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 특정지역=서울에 거주하는 사용자가 대여한 책 목록\n",
    "join_query4 = '''\n",
    "SELECT book_id, title, author_fname, author_lname, username, address\n",
    "FROM books b LEFT JOIN users u ON b.borrowed_by = u.user_id\n",
    "WHERE u.address = '서울';\n",
    "'''\n",
    "\n",
    "spark.sql(join_query4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8069a18-44f1-418c-aec9-1d7144d9b856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------+\n",
      "|user_id|username|count(book_id)|\n",
      "+-------+--------+--------------+\n",
      "|      7|       G|             0|\n",
      "|      6|       F|             1|\n",
      "|      9|       I|             0|\n",
      "|      5|       E|             0|\n",
      "|      1|       A|             1|\n",
      "|     10|       J|             0|\n",
      "|      3|       C|             1|\n",
      "|      8|       H|             0|\n",
      "|     11|       K|             0|\n",
      "|      2|       B|             1|\n",
      "|      4|       D|             0|\n",
      "+-------+--------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#사용자별로 대여한 책 수\n",
    "join_query5 = '''\n",
    "SELECT user_id, username, count(book_id)\n",
    "FROM users u LEFT JOIN books b ON u.user_id = b.borrowed_by\n",
    "GROUP BY u.user_id, u.username;\n",
    "'''\n",
    "spark.sql(join_query5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2390ffe-c796-464d-8a8b-ac2cb4ad3ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------+\n",
      "|user_id|username|count(book_id)|\n",
      "+-------+--------+--------------+\n",
      "|      7|       G|             0|\n",
      "|      6|       F|             1|\n",
      "|      9|       I|             0|\n",
      "|      5|       E|             0|\n",
      "|      1|       A|             1|\n",
      "|     10|       J|             0|\n",
      "|      3|       C|             1|\n",
      "|      8|       H|             0|\n",
      "|     11|       K|             0|\n",
      "|      2|       B|             1|\n",
      "|      4|       D|             0|\n",
      "+-------+--------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#book_category > 300 이상이면 Long, Short\n",
    "join_query6 = '''\n",
    "SELECT book_id,title, pages, CASE \n",
    "                        WHEN pages>=300 THEN 'Long' ELSE 'Short'\n",
    "                        END AS book_category\n",
    "FROM books;\n",
    "'''\n",
    "spark.sql(join_query5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd62f93c-1bea-45c7-b7ac-ef113fd81f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------------+------------+\n",
      "|book_id| title|stock_quantity|stock_status|\n",
      "+-------+------+--------------+------------+\n",
      "|      1|Book A|          60.5|        충분|\n",
      "|      2|Book B|          44.0|        보통|\n",
      "|      3|Book C|          22.0|        부족|\n",
      "|      4|Book D|          82.5|        충분|\n",
      "|      5|Book E|          38.5|        보통|\n",
      "+-------+------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#stock_quantity > 50 이상 '충분', 30 이상 '보통', 미만 '부족'\n",
    "join_query7 = '''\n",
    "SELECT book_id, title, stock_quantity, CASE\n",
    "                        WHEN stock_quantity >= 50 THEN '충분'\n",
    "                        WHEN stock_quantity >= 30 THEN '보통'\n",
    "                        ELSE '부족'\n",
    "                        END AS stock_status\n",
    "FROM books;\n",
    "'''\n",
    "spark.sql(join_query7).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5622aaf-660d-41a1-a455-b16525e36067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 책 제목에 특정 키워드가 포함되어 있는지 확인할 때\n",
    "''WHERE title LIKE '%A%'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d50a4928-2127-46e2-9764-81ee610cb8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+\n",
      "|author_fname|author_lname|borrow_count|\n",
      "+------------+------------+------------+\n",
      "|        Anna|       Davis|           1|\n",
      "+------------+------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 대여가 가장 많이 된 책의 작가를 조회\n",
    "join_query8 = '''\n",
    "SELECT author_fname, author_lname, count(book_id) as borrow_count\n",
    "FROM books \n",
    "GROUP BY author_fname, author_lname\n",
    "ORDER BY borrow_count DESC\n",
    "LIMIT 1\n",
    "'''\n",
    "spark.sql(join_query8).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb4bcf21-84fb-46b8-96ad-bd0884e46d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 157:====================================================>(198 + 2) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|released_year|borrowed_count|\n",
      "+-------------+--------------+\n",
      "|         2005|             1|\n",
      "|         2008|             1|\n",
      "|         2010|             1|\n",
      "|         2015|             1|\n",
      "+-------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#책의 발행 연도별 대여 현황: 발행 연도별로 대여된 책의 수를 확인합니다.\n",
    "query1 = '''\n",
    "SELECT released_year, COUNT(*) AS borrowed_count\n",
    "FROM books\n",
    "WHERE borrowed_by IS NOT NULL\n",
    "GROUP BY released_year\n",
    "ORDER BY released_year;\n",
    "'''\n",
    "spark.sql(query1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f9b6c2e-6025-4ad5-be65-7d0055e1bce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 164:==================================================>  (192 + 2) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|address|borrowed_count|\n",
      "+-------+--------------+\n",
      "|   서울|             2|\n",
      "| 경기도|             1|\n",
      "|   대전|             1|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 사용자의 지역별 대여된 책 수: 사용자 지역별로 대여된 책의 수를 계산합니다.\n",
    "query2 = '''\n",
    "SELECT u.address, COUNT(*) AS borrowed_count\n",
    "FROM books b\n",
    "INNER JOIN users u ON b.borrowed_by = u.user_id\n",
    "GROUP BY u.address\n",
    "ORDER BY borrowed_count DESC;\n",
    "'''\n",
    "spark.sql(query2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d177ea0-7c47-46d5-952d-8bb63f19a17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+\n",
      "|book_id| title|pages|\n",
      "+-------+------+-----+\n",
      "|      4|Book D|  320|\n",
      "+-------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 대여되지 않은 책 중 가장 페이지 수가 많은 책: 대여되지 않은 책 중에서 페이지 수가 가장 많은 책을 조회합니다.\n",
    "query3 = '''\n",
    "SELECT book_id, title, pages\n",
    "FROM books\n",
    "WHERE borrowed_by IS NULL\n",
    "ORDER BY pages DESC\n",
    "LIMIT 1;\n",
    "'''\n",
    "spark.sql(query3).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc546c9e-d824-4934-98c4-278cfaa86f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------------+-------------+\n",
      "|book_id| title|stock_quantity|borrow_status|\n",
      "+-------+------+--------------+-------------+\n",
      "|      3|Book C|          22.0|       대여중|\n",
      "+-------+------+--------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 재고가 부족한 책과 대여 상태: 재고가 30개 미만인 책과 해당 책이 대여된 상태인지 확인합니다.\n",
    "query4 = '''\n",
    "SELECT book_id, title, stock_quantity, \n",
    "       CASE WHEN borrowed_by IS NOT NULL THEN '대여중' ELSE '대여 가능' END AS borrow_status\n",
    "FROM books\n",
    "WHERE stock_quantity < 30;\n",
    "'''\n",
    "spark.sql(query4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a08521a6-d359-43ce-a4e2-66cc024e5b0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Sort [released_year#129L ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(released_year#129L ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#1027]\n",
      "   +- *(2) HashAggregate(keys=[released_year#129L], functions=[count(1)])\n",
      "      +- Exchange hashpartitioning(released_year#129L, 200), ENSURE_REQUIREMENTS, [id=#1023]\n",
      "         +- *(1) HashAggregate(keys=[released_year#129L], functions=[partial_count(1)])\n",
      "            +- *(1) Project [released_year#129L]\n",
      "               +- *(1) Filter isnotnull(borrowed_by#131L)\n",
      "                  +- *(1) Scan ExistingRDD[book_id#124L,title#125,author_fname#126,author_lname#127,pages#128L,released_year#129L,stock_quantity#130L,borrowed_by#131L]\n",
      "\n",
      "\n",
      "== Physical Plan ==\n",
      "*(7) Sort [borrowed_count#934L DESC NULLS LAST], true, 0\n",
      "+- Exchange rangepartitioning(borrowed_count#934L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [id=#1107]\n",
      "   +- *(6) HashAggregate(keys=[address#2], functions=[count(1)])\n",
      "      +- Exchange hashpartitioning(address#2, 200), ENSURE_REQUIREMENTS, [id=#1103]\n",
      "         +- *(5) HashAggregate(keys=[address#2], functions=[partial_count(1)])\n",
      "            +- *(5) Project [address#2]\n",
      "               +- *(5) SortMergeJoin [borrowed_by#131L], [user_id#0L], Inner\n",
      "                  :- *(2) Sort [borrowed_by#131L ASC NULLS FIRST], false, 0\n",
      "                  :  +- Exchange hashpartitioning(borrowed_by#131L, 200), ENSURE_REQUIREMENTS, [id=#1088]\n",
      "                  :     +- *(1) Project [borrowed_by#131L]\n",
      "                  :        +- *(1) Filter isnotnull(borrowed_by#131L)\n",
      "                  :           +- *(1) Scan ExistingRDD[book_id#124L,title#125,author_fname#126,author_lname#127,pages#128L,released_year#129L,stock_quantity#130L,borrowed_by#131L]\n",
      "                  +- *(4) Sort [user_id#0L ASC NULLS FIRST], false, 0\n",
      "                     +- Exchange hashpartitioning(user_id#0L, 200), ENSURE_REQUIREMENTS, [id=#1094]\n",
      "                        +- *(3) Project [user_id#0L, address#2]\n",
      "                           +- *(3) Filter isnotnull(user_id#0L)\n",
      "                              +- *(3) Scan ExistingRDD[user_id#0L,username#1,address#2]\n",
      "\n",
      "\n",
      "== Physical Plan ==\n",
      "TakeOrderedAndProject(limit=1, orderBy=[pages#128L DESC NULLS LAST], output=[book_id#124L,title#125,pages#128L])\n",
      "+- *(1) Project [book_id#124L, title#125, pages#128L]\n",
      "   +- *(1) Filter isnull(borrowed_by#131L)\n",
      "      +- *(1) Scan ExistingRDD[book_id#124L,title#125,author_fname#126,author_lname#127,pages#128L,released_year#129L,stock_quantity#130L,borrowed_by#131L]\n",
      "\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [book_id#124L, title#125, round((cast(stock_quantity#130L as double) * 1.1), 2) AS stock_quantity#379, CASE WHEN isnotnull(borrowed_by#131L) THEN 대여중 ELSE 대여 가능 END AS borrow_status#944]\n",
      "+- *(1) Filter (round((cast(stock_quantity#130L as double) * 1.1), 2) < 30.0)\n",
      "   +- *(1) Scan ExistingRDD[book_id#124L,title#125,author_fname#126,author_lname#127,pages#128L,released_year#129L,stock_quantity#130L,borrowed_by#131L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#실행계획, DAG 형태 분석\n",
    "spark.sql(query1).explain()\n",
    "spark.sql(query2).explain()\n",
    "spark.sql(query3).explain()\n",
    "spark.sql(query4).explain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "682e69e8-1fc8-49fc-9db9-e70e2345f96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# csv 로 save\n",
    "# 쿼리 결과를 데이터프레임으로 저장\n",
    "df1 = spark.sql(query1)\n",
    "df2 = spark.sql(query2)\n",
    "df3 = spark.sql(query3)\n",
    "df4 = spark.sql(query4)\n",
    "\n",
    "# 데이터프레임을 CSV 파일로 저장\n",
    "df1.write.csv(\"data/output/released_year_borrowed_count.csv\", header=True, mode=\"overwrite\")\n",
    "df2.write.csv(\"data/output/user_address_borrowed_count.csv\", header=True, mode=\"overwrite\")\n",
    "df3.write.csv(\"data/output/most_pages_not_borrowed.csv\", header=True, mode=\"overwrite\")\n",
    "df4.write.csv(\"data/output/low_stock_books.csv\", header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a7450b8c-be4f-4dd3-805b-c5663f8a906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
