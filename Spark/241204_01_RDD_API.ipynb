{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40af360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/04 11:33:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-13-94.ap-northeast-3.compute.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>21204_01_RDD_API</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=21204_01_RDD_API>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "# 스파크 환경 설정 객체 생성\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"21204_01_RDD_API\")\n",
    "spark = SparkContext(conf=conf).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0191be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foods = spark.parallelize([\"짜장면\", \"마라탕\", \"짬뽕\", \"떡볶이\", \"쌀국수\", \"짬뽕\", \"짜장면\", \"짜장면\", \"짜장면\", \"라면\", \"우동\", \"라면\"])\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53063028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['짜장면', '마라탕', '짬뽕', '떡볶이', '쌀국수', '짬뽕', '짜장면', '짜장면', '짜장면', '라면', '우동', '라면']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모두 메모리게 올리기\n",
    "foods.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca329a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'짜장면': 4,\n",
       "             '마라탕': 1,\n",
       "             '짬뽕': 2,\n",
       "             '떡볶이': 1,\n",
       "             '쌀국수': 1,\n",
       "             '라면': 2,\n",
       "             '우동': 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 값을 기준으로 카운트 : 음식별 개수 세기\n",
    "foods.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2558879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['짜장면', '마라탕', '짬뽕']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상위 3개 호출\n",
    "foods.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f065faf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'짜장면'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 처음 1개 가져오기\n",
    "foods.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8ba8cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RDD 개수\n",
    "foods.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b0796e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[11] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 제거한 목록\n",
    "# Transformation 연산\n",
    "fd_dist = foods.distinct()\n",
    "fd_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3c87a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['짜장면', '마라탕', '짬뽕', '떡볶이', '쌀국수', '라면', '우동']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# action 연산 : Result\n",
    "fd_dist.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2281cfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "짜장면\n",
      "마라탕\n",
      "짬뽕\n",
      "떡볶이\n",
      "쌀국수\n",
      "짬뽕\n",
      "짜장면\n",
      "짜장면\n",
      "짜장면\n",
      "라면\n",
      "우동\n",
      "라면\n"
     ]
    }
   ],
   "source": [
    "# 워커노드에서 실행하는 기능\n",
    "foods.foreach(lambda x : print(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd596f67",
   "metadata": {},
   "source": [
    "# Narrow Operation 1:1 연산\n",
    "\n",
    "* filter() : 데이터셋의 각 요소에 대해 주어진 조건을 만족하는 요소들만 필터링\n",
    "* map() : 데이터셋의 각 요소에 대해 주어진 함수를 적용하여 새로운 요소로 반환\n",
    "* flatMap() : 각 요소에 대해 주어진 함수를 적용하여 여러 개의 새로운 요소를 생성하고, 결과를 평면화(flatten) 함.\n",
    "* sample() : 데이터셋에서 주어진 비율만큼 임의의 요소를 샘플링\n",
    "* union() : 두 개의 RDD를 합쳐서 새로운 RDD 생성\n",
    "\n",
    "> 데이터가 변환될 때, 하나의 파티션에서 다른 파티션으로 데이터가 이동되지 않는 연산  \n",
    "> 단순하고 빠르게 처리됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d3cca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rdd = spark.parallelize([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f9fab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rdd2 = sample_rdd.map(lambda x :x+2) # transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb71972b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce2ab374",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = [\n",
    "    \"그린 북\",\n",
    "    \"매트릭스\",\n",
    "    \"토이 스토리\",\n",
    "    \"캐스트 어웨이\",\n",
    "    \"포드 V 페라리\",\n",
    "    \"보헤미안 랩소디\",\n",
    "    \"빽 투 더 퓨처\",\n",
    "    \"반지의 제왕\",\n",
    "    \"죽은 시인의 사회\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d55030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesRDD = spark.parallelize(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ca07623",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapMovies = moviesRDD.map(lambda x : x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f9d2f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['그린', '북'],\n",
       " ['매트릭스'],\n",
       " ['토이', '스토리'],\n",
       " ['캐스트', '어웨이'],\n",
       " ['포드', 'V', '페라리'],\n",
       " ['보헤미안', '랩소디'],\n",
       " ['빽', '투', '더', '퓨처'],\n",
       " ['반지의', '제왕'],\n",
       " ['죽은', '시인의', '사회']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapMovies.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26f6b984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['그린',\n",
       " '북',\n",
       " '매트릭스',\n",
       " '토이',\n",
       " '스토리',\n",
       " '캐스트',\n",
       " '어웨이',\n",
       " '포드',\n",
       " 'V',\n",
       " '페라리',\n",
       " '보헤미안',\n",
       " '랩소디',\n",
       " '빽',\n",
       " '투',\n",
       " '더',\n",
       " '퓨처',\n",
       " '반지의',\n",
       " '제왕',\n",
       " '죽은',\n",
       " '시인의',\n",
       " '사회']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 빈도 분석에서 많이 활용 (map보다 자주 활용 예정)\n",
    "flatMapMovies = moviesRDD.flatMap(lambda x:x.split(\" \"))\n",
    "flatMapMovies.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b31a578c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['그린',\n",
       " '북',\n",
       " '토이',\n",
       " '스토리',\n",
       " '캐스트',\n",
       " '어웨이',\n",
       " '포드',\n",
       " 'V',\n",
       " '페라리',\n",
       " '보헤미안',\n",
       " '랩소디',\n",
       " '빽',\n",
       " '투',\n",
       " '더',\n",
       " '퓨처',\n",
       " '반지의',\n",
       " '제왕',\n",
       " '죽은',\n",
       " '시인의',\n",
       " '사회']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filterdMovies = flatMapMovies.filter(lambda x: x!=\"매트릭스\") # 여러개 지정하려면 x not in [\"a\", \"b\", \"\"c]\n",
    "filterdMovies.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70316361",
   "metadata": {},
   "source": [
    "### ➕ 집합 연산 용어로 표현된 RDD 연산\n",
    "\n",
    "1. **합집합 (Union)**:\n",
    "   - **RDD 연산**: `union()`\n",
    "   - **설명**: 두 RDD의 모든 요소를 포함하는 새로운 RDD를 생성합니다.\n",
    "   - **예시**:\n",
    "     ```python\n",
    "     from pyspark import SparkContext\n",
    "\n",
    "     sc = SparkContext.getOrCreate()\n",
    "\n",
    "     rdd1 = sc.parallelize([1, 2, 3])\n",
    "     rdd2 = sc.parallelize([3, 4, 5])\n",
    "     union_rdd = rdd1.union(rdd2).collect()\n",
    "     print(\"Union:\", union_rdd)  # 출력: [1, 2, 3, 3, 4, 5]\n",
    "     ```\n",
    "\n",
    "2. **교집합 (Intersection)**:\n",
    "   - **RDD 연산**: `intersection()`\n",
    "   - **설명**: 두 RDD에 공통으로 포함된 요소만을 추출하여 새로운 RDD를 생성합니다.\n",
    "   - **예시**:\n",
    "     ```python\n",
    "     from pyspark import SparkContext\n",
    "\n",
    "     sc = SparkContext.getOrCreate()\n",
    "\n",
    "     rdd1 = sc.parallelize([1, 2, 3])\n",
    "     rdd2 = sc.parallelize([3, 4, 5])\n",
    "     intersection_rdd = rdd1.intersection(rdd2).collect()\n",
    "     print(\"Intersection:\", intersection_rdd)  # 출력: [3]\n",
    "     ```\n",
    "\n",
    "3. **차집합 (Difference/Subtraction)**:\n",
    "   - **RDD 연산**: `subtract()`\n",
    "   - **설명**: 첫 번째 RDD에 속하고 두 번째 RDD에는 속하지 않는 요소들을 추출하여 새로운 RDD를 생성합니다.\n",
    "   - **예시**:\n",
    "     ```python\n",
    "     from pyspark import SparkContext\n",
    "\n",
    "     sc = SparkContext.getOrCreate()\n",
    "\n",
    "     rdd1 = sc.parallelize([1, 2, 3, 4, 5])\n",
    "     rdd2 = sc.parallelize([4, 5, 6, 7, 8])\n",
    "     subtract_rdd = rdd1.subtract(rdd2).collect()\n",
    "     print(\"Subtract:\", subtract_rdd)  # 출력: [1, 2, 3]\n",
    "     ```\n",
    "\n",
    "4. **중복 제거 (Distinct)**:\n",
    "   - **RDD 연산**: `distinct()`\n",
    "   - **설명**: RDD의 중복된 요소를 제거하여 유일한 요소들만 포함하는 새로운 RDD를 생성합니다.\n",
    "   - **예시**:\n",
    "     ```python\n",
    "     from pyspark import SparkContext\n",
    "\n",
    "     sc = SparkContext.getOrCreate()\n",
    "\n",
    "     rdd = sc.parallelize([1, 2, 2, 3, 4, 4, 5])\n",
    "     distinct_rdd = rdd.distinct().collect()\n",
    "     print(\"Distinct:\", distinct_rdd)  # 출력: [1, 2, 3, 4, 5]\n",
    "     ```\n",
    "\n",
    "### 추가적인 비슷한 연산\n",
    "\n",
    "5. **데카르트 곱 (Cartesian Product)**:\n",
    "   - **RDD 연산**: `cartesian()`\n",
    "   - **설명**: 두 RDD의 모든 가능한 쌍의 조합을 생성합니다.\n",
    "   - **예시**:\n",
    "     ```python\n",
    "     from pyspark import SparkContext\n",
    "\n",
    "     sc = SparkContext.getOrCreate()\n",
    "\n",
    "     rdd1 = sc.parallelize([1, 2])\n",
    "     rdd2 = sc.parallelize([\"a\", \"b\"])\n",
    "     cartesian_rdd = rdd1.cartesian(rdd2).collect()\n",
    "     print(\"Cartesian Product:\", cartesian_rdd)  # 출력: [(1, 'a'), (1, 'b'), (2, 'a'), (2, 'b')]\n",
    "     ```\n",
    "\n",
    "6. **쌍으로 묶기 (Zip)**:\n",
    "   - **RDD 연산**: `zip()`\n",
    "   - **설명**: 두 RDD의 각 요소를 짝지어 튜플로 묶습니다. 두 RDD의 길이가 동일해야 합니다.\n",
    "   - **예시**:\n",
    "     ```python\n",
    "     from pyspark import SparkContext\n",
    "\n",
    "     sc = SparkContext.getOrCreate()\n",
    "\n",
    "     rdd1 = sc.parallelize([1, 2, 3])\n",
    "     rdd2 = sc.parallelize([\"a\", \"b\", \"c\"])\n",
    "     zip_rdd = rdd1.zip(rdd2).collect()\n",
    "     print(\"Zip:\", zip_rdd)  # 출력: [(1, 'a'), (2, 'b'), (3, 'c')]\n",
    "     ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4044fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 집합 연산\n",
    "num1 = spark.parallelize([1,2,3,4,5])\n",
    "num2 = spark.parallelize([4,5,6,7,8,9,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "797d8f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intersection : 교집합\n",
    "num1.intersection(num2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10ea3168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# union : 합집합\n",
    "num1.union(num2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c03a952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 3]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtract : 차집합\n",
    "num1.subtract(num2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c534f677",
   "metadata": {},
   "source": [
    "# sample(withRepLacement, fraction, seed)\n",
    "일부를 샘플링해서 추출함.\n",
    "\n",
    "```\n",
    "* withReplacement : 비복원, 복원 추출 (True / False)\n",
    "* fraction : 기대값 (샘플링할 비율 : 0~1 사이)\n",
    "* seed : 난수추출을 위한 시드값-재현 가능 (옵션)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4ec4760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numlist = num1.union(num2)\n",
    "numlist.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a38eb2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 6, 8, 9]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numlist.sample(True, 0.5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4e84c04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 8]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numlist.sample(True, 0.3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9c16b700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 5, 4, 5, 8, 9, 10]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numlist.sample(False, 0.7).collect() # 재현이 안되는 샘플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb4b48eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 6]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numlist.sample(True, 0.5, seed=42).collect() # 재현이 가능함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e240e37",
   "metadata": {},
   "source": [
    "### ➕ 원하는 개수만큼 샘플링하는 방법\n",
    "\n",
    "\n",
    "#### 1) 반복적으로 샘플링하여 원하는 개수에 맞출 때까지 시도\n",
    "```\n",
    "sampled_data = data.sample(withReplacement=False, fraction=fraction, seed=seed).collect()  \n",
    "while len(sampled_data) != desired_sample_size:  \n",
    "    seed += 1 # 시드 값을 변경하여 다른 샘플을 추출  \n",
    "    sampled_data = data.sample(withReplacement=False, fraction=fraction, seed=seed).collect()  \n",
    "  \n",
    "print(\"Sampled Data (Using While Loop):\", sampled_data)  \n",
    "print(\"Sampled Data Count:\", len(sampled_data))  \n",
    "```\n",
    "#### 2) takeSample 매서드 사용\n",
    "\n",
    "sampled_data_takeSample = data.takeSample(withReplacement=False, num=3, seed=42)  \n",
    "print(\"Sampled Data (Using takeSample):\", sampled_data_takeSample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e760b6",
   "metadata": {},
   "source": [
    "# wide transformation\n",
    "\n",
    "- 데이터가 여러 파티션으로 이동하여 셔플링이 발생하는 연산\n",
    " > 데이터가 여러 파티션으로 이동하면서 네트워크 통신 발생  \n",
    " > 일반적으로 비용이 많이 듦\n",
    "\n",
    "groupby,  \n",
    "reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "82631a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['짜장면', '마라탕', '짬뽕', '떡볶이', '쌀국수', '짬뽕', '짜장면', '짜장면', '짜장면', '라면', '우동', '라면']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foods.collect() # 모든 요소를 수집하여 리스트로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f9ee874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "foodsGroup = foods.groupBy(lambda x:x[0]) # 첫 글자를 기준으로 그룹화\n",
    "res = foodsGroup.collect() # 그룹화된 결과를 수집하여 키와 리스트 형태로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d5c94943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "짜 ['짜장면', '짜장면', '짜장면', '짜장면']\n",
      "마 ['마라탕']\n",
      "짬 ['짬뽕', '짬뽕']\n",
      "떡 ['떡볶이']\n",
      "쌀 ['쌀국수']\n",
      "라 ['라면', '라면']\n",
      "우 ['우동']\n"
     ]
    }
   ],
   "source": [
    "for (k,v) in res:\n",
    "    print(k, list(v)) # 각 그룹의 키와 값을 반복문으로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2f41d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57fb583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
